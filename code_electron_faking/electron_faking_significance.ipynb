{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "\n",
    "# import config functions\n",
    "from jet_faking_plot_config import getWeight, zbi, sample_dict, getVarDict\n",
    "from plot_var import variables, variables_data, ntuple_names, ntuple_names_BDT\n",
    "\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high\n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"]  # Legend\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file:  /data/tmathew/ntups/mc23d/ggHyyd_y.root\n",
      "Unweighted Events before cut:  195671\n",
      "Weighted Events before cut:  19979.121\n",
      "Unweighted Events after basic cut:  3729\n",
      "Weighted Events after basic cut:  375.93835\n",
      "Number of none values:  0\n",
      "Reading Time for ggHyyd: 2.382730007171631 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Zjets_y.root\n",
      "Unweighted Events before cut:  3242488\n"
     ]
    }
   ],
   "source": [
    "tot = []\n",
    "data = pd.DataFrame()\n",
    "unweighted_bcut, weighted_bcut, unweighted_acut, weighted_acut = [], [], [], []\n",
    "ntuple_names = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct', 'data23']\n",
    "\n",
    "def test(fb):\n",
    "    # checking if there are any none values\n",
    "    mask = ak.is_none(fb['met_tst_et'])\n",
    "    n_none = ak.sum(mask)\n",
    "    print(\"Number of none values: \", n_none)\n",
    "    # if n_none > 0:\n",
    "    #     fb = fb[~mask]\n",
    "    # print(\"Events after removing none values: \", len(fb), ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "\n",
    "def print_cut(ntuple_name, fb, label):\n",
    "    print(f\"Unweighted Events {label}: \", len(fb))\n",
    "    if ntuple_name == 'data23':\n",
    "        print(f\"Weighted Events {label}: \", sum(getWeight(fb, ntuple_name, jet_faking=True)))\n",
    "    else: \n",
    "        print(f\"Weighted Events {label}: \", sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "for i in range(len(ntuple_names)):\n",
    "    ucut, wcut = [], []\n",
    "    start_time = time.time()\n",
    "    ntuple_name = ntuple_names[i]\n",
    "    if ntuple_name == 'data23': # data\n",
    "        path = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/data23_y_BDT_score.root\" \n",
    "        print('processing file: ', path)\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables_data, library=\"ak\")\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "                \n",
    "        mask1 = (ak.firsts(fb['ph_topoetcone40'])-2450.)/ak.firsts(fb['ph_pt']) < 0.1   # jet_faking_photon cut\n",
    "        fb = fb[mask1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 1]\n",
    "\n",
    "    else: # MC\n",
    "        path = f\"/data/tmathew/ntups/mc23d/{ntuple_name}_y.root\" \n",
    "        path_BDT = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/mc23d_{ntuple_name}_y_BDT_score.root\" \n",
    "        print('processing file: ', path)\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables, library=\"ak\")\n",
    "\n",
    "        # add BDT score to fb\n",
    "        f_BDT = uproot.open(path_BDT)['nominal']\n",
    "        fb_BDT = f_BDT.arrays([\"event\", \"BDTScore\"], library=\"ak\")\n",
    "        tmp = fb[\"event\"] == fb_BDT[\"event\"]\n",
    "        if np.all(tmp) == True:\n",
    "            fb[\"BDTScore\"] = fb_BDT[\"BDTScore\"]\n",
    "        else: \n",
    "            print(\"Something is wrong, need arranging\")\n",
    "\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "        fb = fb[fb['n_ph'] == 1]\n",
    "\n",
    "    \n",
    "\n",
    "    # Zjets and Wjets (rule out everything except for e->gamma)\n",
    "    if ntuple_name == 'Zjets' or ntuple_name == 'Wjets':\n",
    "        mask1 = ak.firsts(fb['ph_truth_type']) == 2\n",
    "        mask2 = ak.firsts(fb['ph_truth_type']) == 2\n",
    "        fb = fb[mask1 & mask2]\n",
    "    \n",
    "    print_cut(ntuple_name, fb, 'before cut')\n",
    "\n",
    "\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    fb = fb[fb['n_el_baseline'] == 0]\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M']==1]\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0] # prevent none values in Tbranch\n",
    "    fb = fb[fb['met_tst_et'] >= 100000] # MET cut (basic cut)\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) >= 50000] # ph_pt cut (basic cut)\n",
    "    fb = fb[fb['n_jet_central'] <= 4] # n_jet_central cut (basic cut)\n",
    "    # goodPV on signal only\n",
    "    if ntuple_name == 'ggHyyd':\n",
    "        fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "        good_pv_tmp = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "        fb = fb[good_pv_tmp]\n",
    "\n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "                            (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    mask1 = mt_tmp >= 100 # trigger cut\n",
    "    fb = fb[mask1]\n",
    "\n",
    "    fb = fb[fb['BDTScore'] >= 0.1] # added cut 1\n",
    "\n",
    "    print_cut(ntuple_name, fb, 'after basic cut')\n",
    "\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # metsig_tmp = fb['met_tst_sig'] # added cut 2 \n",
    "    # mask1 = metsig_tmp >= 7\n",
    "    # fb = fb[mask1]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # dphi_met_phterm_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])) # added cut 3\n",
    "    # fb = fb[dphi_met_phterm_tmp >= 1.35]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # dmet_tmp = fb['met_tst_noJVT_et'] - fb['met_tst_et'] # added cut 4\n",
    "    # mask1 = dmet_tmp >= -20000\n",
    "    # mask2 = dmet_tmp <= 50000\n",
    "    # fb = fb[mask1 * mask2]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # dphi_met_jetterm_tmp = np.where(fb['met_jetterm_et'] != 0,   # added cut 5\n",
    "    #                         np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "    #                         -999)\n",
    "    # fb = fb[dphi_met_jetterm_tmp <= 0.7]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # ph_eta_tmp = np.abs(ak.firsts(fb['ph_eta'])) # added cut 6\n",
    "    # fb = fb[ph_eta_tmp <= 1.75]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # phi1_tmp = ak.firsts(fb['jet_central_phi']) # added cut 7\n",
    "    # phi2_tmp = ak.mask(fb['jet_central_phi'], ak.num(fb['jet_central_phi']) >= 2)[:, 1] \n",
    "    # dphi_tmp = np.arccos(np.cos(phi1_tmp - phi2_tmp))\n",
    "    # dphi_jj_tmp = ak.fill_none(dphi_tmp, -999)\n",
    "    # fb = fb[dphi_jj_tmp <= 2.5]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # jet_sum_tmp = ak.sum(fb['jet_central_pt'], axis=-1)\n",
    "    # expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "    # balance_tmp = ak.where(jet_sum_tmp != 0, expr, 999) \n",
    "    # fb = fb[balance_tmp >= 0.65]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "    # mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "    #                     (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    # mask1 = mt_tmp >= 95\n",
    "    # fb = fb[mask1]\n",
    "\n",
    "    # print_cut(ntuple_name, fb)\n",
    "    ucut.append(len(fb))\n",
    "    if ntuple_name == 'data23':\n",
    "        wcut.append(sum(getWeight(fb, ntuple_name, jet_faking=True)))\n",
    "    else: \n",
    "        wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    unweighted_acut.append(ucut)\n",
    "    weighted_acut.append(wcut)\n",
    "    test(fb) # check for none value\n",
    "\n",
    "    print(f\"Reading Time for {ntuple_name}: {(time.time()-start_time)} seconds\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    tot.append(fb)\n",
    "\n",
    "    fb = 0\n",
    "    fb_BDT = 0\n",
    "    tmp = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_BDTScore_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_balance_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_balance_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_dmet_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_dmet_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_dphi_jj_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_dphi_met_jetterm_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_dphi_met_jetterm_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_dphi_met_phterm_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_dphi_met_phterm_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_dphi_ph_centraljet1_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_dphi_ph_centraljet1_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_dphi_phterm_jetterm_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_dphi_phterm_jetterm_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_met_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_met_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_metsig_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_metsig_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_mt_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_mt_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_n_jet_central_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_ph_eta_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_ph_pt_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_metsigcut/significance_ph_pt_uppercut.png\n"
     ]
    }
   ],
   "source": [
    "def sel(tot):\n",
    "    tot2 = []\n",
    "    for i in range(len(tot)):\n",
    "        fb2 = tot[i]\n",
    "\n",
    "        # jet_sum_tmp = ak.sum(fb2['jet_central_pt'], axis=-1)\n",
    "        # expr = (fb2['met_tst_et'] + ak.firsts(fb2['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "        # balance_tmp = ak.where(jet_sum_tmp != 0, expr, -999)\n",
    "        # mask1 = balance_tmp >= 0.65\n",
    "        # mask2 = balance_tmp == -999\n",
    "        # fb2 = fb2[mask1 | mask2]\n",
    "        \n",
    "        metsig_tmp = fb2['met_tst_sig'] \n",
    "        mask1 = metsig_tmp >= 7\n",
    "        fb2 = fb2[mask1]\n",
    "        # mask2 = metsig_tmp <= 13\n",
    "        # fb2 = fb2[mask1 * mask2]\n",
    "        \n",
    "        # ph_eta_tmp = np.abs(ak.firsts(fb2['ph_eta']))\n",
    "        # fb2 = fb2[ph_eta_tmp <= 1.75]\n",
    "\n",
    "        dphi_met_phterm_tmp = np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_phterm_phi'])) # added cut 3\n",
    "        fb2 = fb2[dphi_met_phterm_tmp >= 1.55]\n",
    "\n",
    "        # dmet_tmp = fb2['met_tst_noJVT_et'] - fb2['met_tst_et']\n",
    "        # mask1 = dmet_tmp >= -20000\n",
    "        # mask2 = dmet_tmp <= 50000\n",
    "        # fb2 = fb2[mask1 * mask2]\n",
    "\n",
    "        # phi1_tmp = ak.firsts(fb2['jet_central_phi']) # added cut 7\n",
    "        # phi2_tmp = ak.mask(fb2['jet_central_phi'], ak.num(fb2['jet_central_phi']) >= 2)[:, 1] \n",
    "        # dphi_tmp = np.arccos(np.cos(phi1_tmp - phi2_tmp))\n",
    "        # dphi_jj_tmp = ak.fill_none(dphi_tmp, -999)\n",
    "        # fb2 = fb2[dphi_jj_tmp <= 2.5]\n",
    "\n",
    "        # dphi_met_jetterm_tmp = np.where(fb2['met_jetterm_et'] != 0,   # added cut 5\n",
    "        #                     np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_jetterm_phi'])),\n",
    "        #                     -999)\n",
    "        # fb2 = fb2[dphi_met_jetterm_tmp <= 0.70]\n",
    "        \n",
    "        tot2.append(fb2)\n",
    "    return tot2\n",
    "\n",
    "tot2 = sel(tot)\n",
    "# tot2 = tot\n",
    "\n",
    "signal_name = 'ggHyyd'  # Define signal dataset\n",
    "cut_name = 'metsig'\n",
    "\n",
    "def getCutDict():\n",
    "    cut_dict = {}\n",
    "\n",
    "    cut_dict['BDTScore'] = {\n",
    "        'lowercut': np.arange(0, 0.4+0.1, 0.1) # BDTScore > cut\n",
    "    }\n",
    "    cut_dict['balance'] = {\n",
    "        'lowercut': np.arange(0, 1.5 + 0.05, 0.05), # balance > cut\n",
    "        'uppercut': np.arange(5, 8 + 0.2, 0.2) # balance < cut\n",
    "    }\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 0 + 5000, 5000), # dmet > cut\n",
    "        'uppercut': np.arange(10000, 100000 + 5000, 5000), # -10000 < dmet < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.1 + 0.1, 0.1) # dphi_jj < cut\n",
    "    }\n",
    "    # cut_dict['dphi_met_phterm_minus_dphi_met_jetterm'] = {\n",
    "    #     'lowercut': np.arange(0, 1.5+0.05, 0.05),\n",
    "    #     'uppercut': np.arange(1.5, 3.1+0.05, 0.05)\n",
    "    # }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'lowercut': np.arange(0, 1 + 0.05, 0.05), # dphi_met_jetterm > cut \n",
    "        'uppercut': np.arange(0.5, 2 + 0.05, 0.05), # dphi_met_jetterm < cut \n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(1, 2 + 0.05, 0.05), # dphi_met_phterm > cut\n",
    "        'uppercut': np.arange(2, 3.1 + 0.1, 0.1), # dphi_met_phterm < cut\n",
    "    }\n",
    "    cut_dict['dphi_ph_centraljet1'] = {\n",
    "        'lowercut': np.arange(0, 2.5 + 0.1, 0.1), # dphi_ph_centraljet1 > cut\n",
    "        'uppercut': np.arange(1.5, 3.1 + 0.1, 0.1) # dphi_ph_centraljet1 < cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.05, 0.05), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['met'] = {\n",
    "        'lowercut': np.arange(100000, 140000 + 5000, 5000),  # met > cut\n",
    "        'uppercut': np.arange(140000, 300000 + 5000, 5000),  # met < cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "    }\n",
    "    cut_dict['mt'] = {\n",
    "        'lowercut': np.arange(80, 130+5, 5), # mt > cut\n",
    "        'uppercut': np.arange(120, 230+5, 5) # mt < cut\n",
    "    }\n",
    "    cut_dict['n_jet_central'] = {\n",
    "        'uppercut': np.arange(0, 8+1, 1) # njet < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.05, 0.05), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['ph_pt'] = {\n",
    "        'lowercut': np.arange(50000, 100000 + 5000, 5000),  # ph_pt > cut\n",
    "        'uppercut': np.arange(100000, 300000 + 10000, 10000),  # ph_pt > cut\n",
    "    }\n",
    "\n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "\n",
    "def calculate_significance(cut_var, cut_type, cut_values):\n",
    "    sig_simple_list = []\n",
    "    sig_s_plus_b_list = []\n",
    "    sig_s_plus_1p3b_list = []\n",
    "    sig_binomial_list = []\n",
    "\n",
    "    sigacc_simple_list = []\n",
    "    sigacc_s_plus_b_list = []\n",
    "    sigacc_s_plus_1p3b_list = []\n",
    "    sigacc_binomial_list = []\n",
    "\n",
    "    acceptance_values = []  # Store acceptance percentages\n",
    "\n",
    "    for cut in cut_values:\n",
    "        sig_after_cut = 0\n",
    "        bkg_after_cut = []\n",
    "        sig_events = 0\n",
    "        \n",
    "        for i in range(len(ntuple_names)):\n",
    "            fb = tot2[i]\n",
    "            process = ntuple_names[i]\n",
    "            var_config = getVarDict(fb, process, var_name=cut_var)\n",
    "            x = var_config[cut_var]['var']\n",
    "            mask = x != -999 # Apply cut: Remove -999 values \n",
    "            x = x[mask]\n",
    "\n",
    "            if process == signal_name:\n",
    "                sig_events = getWeight(fb, process)\n",
    "                sig_events = sig_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                sig_after_cut = ak.sum(sig_events[mask])\n",
    "            \n",
    "            else:\n",
    "                bkg_events = getWeight(fb, process)\n",
    "                bkg_events = bkg_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                bkg_after_cut.append(ak.sum(bkg_events[mask]))\n",
    "\n",
    "       # Now compute different types of significance\n",
    "        total_bkg = sum(bkg_after_cut)\n",
    "        total_signal = sig_after_cut\n",
    "\n",
    "        # Avoid zero division carefully\n",
    "        if total_bkg > 0:\n",
    "            sig_simple = total_signal / np.sqrt(total_bkg)\n",
    "            sig_s_plus_b = total_signal / np.sqrt(total_signal + total_bkg) if (total_signal + total_bkg) > 0 else 0\n",
    "            sig_s_plus_1p3b = total_signal / np.sqrt(total_signal + 1.3 * total_bkg) if (total_signal + 1.3*total_bkg) > 0 else 0\n",
    "            sig_binomial = zbi(total_signal, total_bkg, sigma_b_frac=0.3)\n",
    "        else:\n",
    "            sig_simple = sig_s_plus_b = sig_s_plus_1p3b = sig_binomial = 0\n",
    "\n",
    "        # Acceptance\n",
    "        acceptance = total_signal / sum(sig_events) if sum(sig_events) > 0 else 0\n",
    "        acceptance_values.append(acceptance * 100)  # percentage\n",
    "\n",
    "        # Save significance\n",
    "        sig_simple_list.append(sig_simple)\n",
    "        sig_s_plus_b_list.append(sig_s_plus_b)\n",
    "        sig_s_plus_1p3b_list.append(sig_s_plus_1p3b)\n",
    "        sig_binomial_list.append(sig_binomial)\n",
    "\n",
    "        # Save significance × acceptance\n",
    "        sigacc_simple_list.append(sig_simple * acceptance)\n",
    "        sigacc_s_plus_b_list.append(sig_s_plus_b * acceptance)\n",
    "        sigacc_s_plus_1p3b_list.append(sig_s_plus_1p3b * acceptance)\n",
    "        sigacc_binomial_list.append(sig_binomial * acceptance)\n",
    "\n",
    "    return (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "            sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "            acceptance_values)\n",
    "\n",
    "# Compute significance for each variable dynamically\n",
    "for cut_var, cut_types in cut_config.items():\n",
    "    for cut_type, cut_values in cut_types.items():\n",
    "        (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "         sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "         acceptance_values) = calculate_significance(cut_var, cut_type, cut_values)\n",
    "\n",
    "        # Plot results\n",
    "        fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "\n",
    "        # Top plot: Significance vs. Cut\n",
    "        ax_top.plot(cut_values, sig_simple_list, marker='o', label='S/√B')\n",
    "        ax_top.plot(cut_values, sig_s_plus_b_list, marker='s', label='S/√(S+B)')\n",
    "        ax_top.plot(cut_values, sig_s_plus_1p3b_list, marker='^', label='S/√(S+1.3B)')\n",
    "        ax_top.plot(cut_values, sig_binomial_list, marker='x', label='BinomialExpZ')\n",
    "        ax_top.set_ylabel('Significance')\n",
    "        ax_top.set_title(f'Significance vs. {cut_var} ({cut_type})')\n",
    "        ax_top.legend()\n",
    "        ax_top.grid(True)\n",
    "\n",
    "        # Bottom plot: Significance * Acceptance vs. Cut\n",
    "        ax_bot.plot(cut_values, sigacc_simple_list, marker='o', label='(S/√B) × Acceptance')\n",
    "        ax_bot.plot(cut_values, sigacc_s_plus_b_list, marker='s', label='(S/√(S+B)) × Acceptance')\n",
    "        ax_bot.plot(cut_values, sigacc_s_plus_1p3b_list, marker='^', label='(S/√(S+1.3B)) × Acceptance')\n",
    "        ax_bot.plot(cut_values, sigacc_binomial_list, marker='x', label='BinomialExpZ × Acceptance')\n",
    "\n",
    "        for i, txt in enumerate(acceptance_values):\n",
    "            ax_bot.text(cut_values[i], sigacc_simple_list[i], f'{txt:.1f}%', \n",
    "                        fontsize=10, ha='right', va='bottom', color='purple')\n",
    "            \n",
    "        ax_bot.set_xlabel(f'{cut_var} Cut')\n",
    "        ax_bot.set_ylabel('Significance × Acceptance')\n",
    "        ax_bot.set_title(f'Significance × Acceptance vs. {cut_var} ({cut_type})')\n",
    "        \n",
    "        ax_bot.set_xticks(cut_values)\n",
    "        ax_bot.set_xticklabels(ax_bot.get_xticks(), rotation=45, ha='right')\n",
    "        ax_bot.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "        # ax_bot.xaxis.set_major_locator(ticker.MaxNLocator(nbins=15))  # Show at most 10 x-ticks\n",
    "        \n",
    "        var_configs_tmp = getVarDict(tot2[0], signal_name, cut_var)\n",
    "        ax_bot.set_xlabel(var_configs_tmp[cut_var]['title'])\n",
    "        ax_bot.legend()\n",
    "        ax_bot.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../jets_faking_photons/lumi135/mc23d_{cut_name}cut/significance_{cut_var}_{cut_type}.png\")\n",
    "        print(f\"Successfully saved to ../jets_faking_photons/lumi135/mc23d_{cut_name}cut/significance_{cut_var}_{cut_type}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'mc23d_balancecut/vtx_sumPt_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/vtx_sumPt_absWeightSelection.png',\n",
      "'mc23d_balancecut/n_ph_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/n_ph_absWeightSelection.png',\n",
      "'mc23d_balancecut/n_ph_baseline_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/n_ph_baseline_absWeightSelection.png',\n",
      "'mc23d_balancecut/n_el_baseline_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/n_el_baseline_absWeightSelection.png',\n",
      "'mc23d_balancecut/n_mu_baseline_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/n_mu_baseline_absWeightSelection.png',\n",
      "'mc23d_balancecut/n_tau_baseline_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/n_tau_baseline_absWeightSelection.png',\n",
      "'mc23d_balancecut/puWeight_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/puWeight_absWeightSelection.png',\n",
      "'mc23d_balancecut/actualIntPerXing_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/actualIntPerXing_absWeightSelection.png',\n",
      "'mc23d_balancecut/mt_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/mt_absWeightSelection.png',\n",
      "'mc23d_balancecut/metsig_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/metsig_absWeightSelection.png',\n",
      "'mc23d_balancecut/metsigres_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/metsigres_absWeightSelection.png',\n",
      "'mc23d_balancecut/met_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/met_absWeightSelection.png',\n",
      "'mc23d_balancecut/met_noJVT_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/met_noJVT_absWeightSelection.png',\n",
      "'mc23d_balancecut/met_cst_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/met_cst_absWeightSelection.png',\n",
      "'mc23d_balancecut/met_track_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/met_track_absWeightSelection.png',\n",
      "'mc23d_balancecut/dmet_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/dmet_absWeightSelection.png',\n",
      "'mc23d_balancecut/ph_pt_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/ph_pt_absWeightSelection.png',\n",
      "'mc23d_balancecut/ph_eta_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/ph_eta_absWeightSelection.png',\n",
      "'mc23d_balancecut/ph_phi_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/ph_phi_absWeightSelection.png',\n",
      "'mc23d_balancecut/jet_central_eta_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/jet_central_eta_absWeightSelection.png',\n",
      "'mc23d_balancecut/jet_central_pt1_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/jet_central_pt1_absWeightSelection.png',\n",
      "'mc23d_balancecut/jet_central_pt2_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/jet_central_pt2_absWeightSelection.png',\n",
      "'mc23d_balancecut/jet_central_pt_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/jet_central_pt_absWeightSelection.png',\n",
      "'mc23d_balancecut/dphi_met_phterm_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/dphi_met_phterm_absWeightSelection.png',\n",
      "'mc23d_balancecut/dphi_met_ph_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/dphi_met_ph_absWeightSelection.png',\n",
      "'mc23d_balancecut/dphi_met_jetterm_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/dphi_met_jetterm_absWeightSelection.png',\n",
      "'mc23d_balancecut/dphi_phterm_jetterm_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/dphi_phterm_jetterm_absWeightSelection.png',\n",
      "'mc23d_balancecut/dphi_ph_centraljet1_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/dphi_ph_centraljet1_absWeightSelection.png',\n",
      "'mc23d_balancecut/dphi_ph_jet1_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/dphi_ph_jet1_absWeightSelection.png',\n",
      "'mc23d_balancecut/metplusph_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/metplusph_absWeightSelection.png',\n",
      "'mc23d_balancecut/failJVT_jet_pt_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/failJVT_jet_pt_absWeightSelection.png',\n",
      "'mc23d_balancecut/failJVT_jet_pt1_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/failJVT_jet_pt1_absWeightSelection.png',\n",
      "'mc23d_balancecut/softerm_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/softerm_absWeightSelection.png',\n",
      "'mc23d_balancecut/jetterm_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/jetterm_absWeightSelection.png',\n",
      "'mc23d_balancecut/jetterm_sumet_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/jetterm_sumet_absWeightSelection.png',\n",
      "'mc23d_balancecut/n_jet_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/n_jet_absWeightSelection.png',\n",
      "'mc23d_balancecut/n_jet_central_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/n_jet_central_absWeightSelection.png',\n",
      "'mc23d_balancecut/n_jet_fwd_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/n_jet_fwd_absWeightSelection.png',\n",
      "'mc23d_balancecut/goodPV_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/goodPV_absWeightSelection.png',\n",
      "'mc23d_balancecut/dphi_met_central_jet_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/dphi_met_central_jet_absWeightSelection.png',\n",
      "'mc23d_balancecut/jet_central_timing1_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/jet_central_timing1_absWeightSelection.png',\n",
      "'mc23d_balancecut/jet_central_timing_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/jet_central_timing_absWeightSelection.png',\n",
      "'mc23d_balancecut/jet_central_emfrac_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/jet_central_emfrac_absWeightSelection.png',\n",
      "'mc23d_balancecut/balance_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/balance_absWeightSelection.png',\n",
      "'mc23d_balancecut/balance_sumet_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/balance_sumet_absWeightSelection.png',\n",
      "'mc23d_balancecut/central_jets_fraction_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/central_jets_fraction_absWeightSelection.png',\n",
      "'mc23d_balancecut/trigger_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/trigger_absWeightSelection.png',\n",
      "'mc23d_balancecut/dphi_jj_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/dphi_jj_absWeightSelection.png',\n",
      "'mc23d_balancecut/BDTScore_nodijet.png',\n",
      "'mc23d_abs_weight_selectioncut/BDTScore_absWeightSelection.png',\n"
     ]
    }
   ],
   "source": [
    "# print out the image list in common_config.js\n",
    "var_config = getVarDict(tot2[0], 'ggHyyd')\n",
    "\n",
    "for var in var_config:\n",
    "\n",
    "    print(f\"'mc23d_balancecut/{var}_nodijet.png',\")\n",
    "    print(f\"'mc23d_abs_weight_selectioncut/{var}_absWeightSelection.png',\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    var = {\n",
    "        'vtx_sumPt': ak.flatten(fb['vtx_sumPt']),\n",
    "        'n_ph': fb['n_ph'],\n",
    "        'n_ph_baseline': fb['n_ph_baseline'],\n",
    "        'n_el_baseline': fb['n_el_baseline'],\n",
    "        'n_mu_baseline': fb['n_mu_baseline'],\n",
    "        'n_tau_baseline': fb['n_tau_baseline'],\n",
    "        'puWeight': fb['pu_weight'],\n",
    "        'actualIntPerXing': fb['actualIntPerXing'],\n",
    "        'mt': np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000,\n",
    "        'metsig': fb['met_tst_sig'],\n",
    "        'metsigres': fb['met_tst_et'] / fb['met_tst_sig'],\n",
    "        'met': fb['met_tst_et'],  # applying the '+50000' shift\n",
    "        'met_noJVT': fb['met_tst_noJVT_et'],\n",
    "        'met_cst': fb['met_cst_et'],\n",
    "        'met_track': fb['met_track_et'],\n",
    "        'dmet': fb['met_tst_noJVT_et'] - fb['met_tst_et'],\n",
    "        'ph_pt': ak.firsts(fb['ph_pt']),  # applying the '-150000' shift\n",
    "        'ph_eta': np.abs(ak.firsts(fb['ph_eta'])),\n",
    "        'ph_phi': ak.firsts(fb['ph_phi']),\n",
    "        # 'jet_central_eta': ak.firsts(fb['jet_central_eta']),\n",
    "        # 'jet_central_pt1': ak.firsts(fb['jet_central_pt']),\n",
    "        # 'jet_central_pt2': fb['jet_central_pt'][ak.num(fb['jet_central_pt']) >= 2][:, 1],\n",
    "        # 'jet_central_pt': fb['jet_central_pt'],\n",
    "        'dphi_met_phterm': np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])),\n",
    "        'dphi_met_ph': np.arccos(np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi']))),\n",
    "        'dphi_met_jetterm': np.where(fb['met_jetterm_et'] != 0,\n",
    "                                    np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                                    0),\n",
    "        'dphi_phterm_jetterm': np.where(fb['met_jetterm_et'] > 0,\n",
    "                                        np.arccos(np.cos(fb['met_phterm_phi'] - fb['met_jetterm_phi'])),\n",
    "                                        4),\n",
    "        # 'dphi_ph_centraljet1': np.arccos(np.cos(ak.firsts(fb['ph_phi']) - ak.firsts(fb['jet_central_phi']))),\n",
    "        # 'dphi_ph_jet1': np.arccos(np.cos(ak.firsts(fb['ph_phi']) - ak.firsts(fb['jet_central_phi']))),\n",
    "        # 'dphi_central_jet1_jet2': np.arccos(np.cos(fb['jet_central_phi'][ak.num(fb['jet_central_phi']) >= 2][:, 0] - fb['jet_central_phi'][ak.num(fb['jet_central_phi']) >= 2][:, 1])),\n",
    "        'metplusph': fb['met_tst_et'] + ak.firsts(fb['ph_pt']),\n",
    "        # 'failJVT_jet_pt': fb['failJVT_jet_pt'],\n",
    "        # 'failJVT_jet_pt1': ak.firsts(fb['failJVT_jet_pt']),\n",
    "        'softerm': fb['met_softerm_tst_et'],\n",
    "        'jetterm': fb['met_jetterm_et'],\n",
    "        'jetterm_sumet': fb['met_jetterm_sumet'],\n",
    "        'n_jet': fb['n_jet'],\n",
    "        'n_jet_central': fb['n_jet_central'],\n",
    "        'n_jet_fwd': fb['n_jet'] - fb['n_jet_central'],\n",
    "        'vertex': np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) == np.min(np.abs(ak.firsts(fb['pv_truth_z']) - fb['pv_z'])),\n",
    "        'goodPV': np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5,\n",
    "        # 'dphi_met_central_jet': np.arccos(np.cos(fb['met_tst_phi'] - ak.firsts(fb['jet_central_phi']))),\n",
    "        # 'counts': 0.5,\n",
    "        # 'jet_central_timing1': ak.firsts(fb['jet_central_timing']),\n",
    "        # 'jet_central_timing': fb['jet_central_timing'],\n",
    "        # 'jet_central_emfrac': fb['jet_central_emfrac'],\n",
    "        # 'jet_central_emfrac1': ak.firsts(fb['jet_central_emfrac']),\n",
    "        'balance': (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / np.sum(fb['jet_central_pt']), # need fixing \n",
    "        'balance_sumet': (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / fb['met_jetterm_sumet'],\n",
    "        'central_jets_fraction': np.where(fb['n_jet'] > 0, fb['n_jet_central'] / fb['n_jet'], -1),\n",
    "        'trigger': fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M'],\n",
    "        # 'dphi_jj': ak.Array([np.arccos(np.cos(phi[1] - phi[0])) if len(phi) > 1 else -1 for phi in fb['jet_central_phi']])\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(var)\n",
    "\n",
    "    data = pd.concat([data, df], ignore_index=True)\n",
    "\n",
    "\n",
    "    # for key, value in var.items():\n",
    "    #     try:\n",
    "    #         print(f\"{key:30s}: {len(value)}\")\n",
    "    #         print(f\"{key:30s}: {value[:5]}\")\n",
    "\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"{key:30s}: error getting length ({e})\")\n",
    "\n",
    "print(data.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
