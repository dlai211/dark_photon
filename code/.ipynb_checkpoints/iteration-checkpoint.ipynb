{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd91d671-f884-4af4-88f1-975e1e3caeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mc23d_ggHyyd_y Unweighted Events before cut:  17999\n",
      "mc23d_ggHyyd_y Weighted Events before cut:  1786.539416255438\n",
      "mc23d_ggHyyd_y Unweighted Events after basic:  2627\n",
      "mc23d_ggHyyd_y Weighted Events after basic:  266.43555898887837\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_ggHyyd_y: 0.7762739658355713 seconds\n",
      "\n",
      "mc23d_Zgamma_y Unweighted Events before cut:  2520609\n",
      "mc23d_Zgamma_y Weighted Events before cut:  15697.116266766878\n",
      "mc23d_Zgamma_y Unweighted Events after basic:  19478\n",
      "mc23d_Zgamma_y Weighted Events after basic:  191.54357598716345\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_Zgamma_y: 17.110783100128174 seconds\n",
      "\n",
      "mc23d_Wgamma_y Unweighted Events before cut:  685525\n",
      "mc23d_Wgamma_y Weighted Events before cut:  16946.649253377054\n",
      "mc23d_Wgamma_y Unweighted Events after basic:  13933\n",
      "mc23d_Wgamma_y Weighted Events after basic:  386.78848750579306\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_Wgamma_y: 4.599167346954346 seconds\n",
      "\n",
      "mc23d_gammajet_direct_y Unweighted Events before cut:  1872548\n",
      "mc23d_gammajet_direct_y Weighted Events before cut:  1103184.1585944626\n",
      "mc23d_gammajet_direct_y Unweighted Events after basic:  30515\n",
      "mc23d_gammajet_direct_y Weighted Events after basic:  703.4841099714558\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_gammajet_direct_y: 11.345064640045166 seconds\n",
      "\n",
      "data23_y Unweighted Events before cut:  1489084\n",
      "data23_y Weighted Events before cut:  3042472.9429998905\n",
      "data23_y Unweighted Events after basic:  1397\n",
      "data23_y Weighted Events after basic:  2867.3850000000084\n",
      "Number of none values:  0\n",
      "Reading Time for data23_y: 13.1631178855896 seconds\n",
      "\n",
      "data23_eprobe Unweighted Events before cut:  991882\n",
      "data23_eprobe Weighted Events before cut:  35278.89142854558\n",
      "data23_eprobe Unweighted Events after basic:  24949\n",
      "data23_eprobe Weighted Events after basic:  1127.4378565699576\n",
      "Number of none values:  0\n",
      "Reading Time for data23_eprobe: 5.829420804977417 seconds\n",
      "\n",
      "mc23e_Zgamma_y Unweighted Events before cut:  8622736\n",
      "mc23e_Zgamma_y Weighted Events before cut:  66651.54542882358\n",
      "mc23e_Zgamma_y Unweighted Events after basic:  68044\n",
      "mc23e_Zgamma_y Weighted Events after basic:  798.1511253245422\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_Zgamma_y: 52.14466619491577 seconds\n",
      "\n",
      "mc23e_Wgamma_y Unweighted Events before cut:  2162708\n",
      "mc23e_Wgamma_y Weighted Events before cut:  74823.05389455653\n",
      "mc23e_Wgamma_y Unweighted Events after basic:  44545\n",
      "mc23e_Wgamma_y Weighted Events after basic:  1592.4189527449048\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_Wgamma_y: 13.521259307861328 seconds\n",
      "\n",
      "mc23e_gammajet_direct_y Unweighted Events before cut:  2268382\n",
      "mc23e_gammajet_direct_y Weighted Events before cut:  6522209.851531688\n",
      "mc23e_gammajet_direct_y Unweighted Events after basic:  29591\n",
      "mc23e_gammajet_direct_y Weighted Events after basic:  3672.988737405649\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_gammajet_direct_y: 12.703354835510254 seconds\n",
      "\n",
      "data24_y Unweighted Events before cut:  7913491\n",
      "data24_y Weighted Events before cut:  13781338.51483133\n",
      "data24_y Unweighted Events after basic:  6993\n",
      "data24_y Weighted Events after basic:  12121.628000000157\n",
      "Number of none values:  0\n",
      "Reading Time for data24_y: 63.35127592086792 seconds\n",
      "\n",
      "data24_eprobe Unweighted Events before cut:  4452447\n",
      "data24_eprobe Weighted Events before cut:  168317.91138638573\n",
      "data24_eprobe Unweighted Events after basic:  110499\n",
      "data24_eprobe Weighted Events after basic:  5371.424155399616\n",
      "Number of none values:  0\n",
      "Reading Time for data24_eprobe: 23.609214544296265 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math, pickle, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "from pathlib import Path\n",
    "\n",
    "# import config functions\n",
    "sys.path.append('/home/jlai/dark_photon/code/config')\n",
    "from plot_config import getWeight, zbi, sample_dict, getVarDict\n",
    "from plot_var import variables, variables_mc, ntuple_names\n",
    "from n_1_iteration_functions import get_best_cut, calculate_significance, apply_cut_to_fb, apply_all_cuts, compute_total_significance, n_minus_1_optimizer\n",
    "from perf_sig_plot import plot_performance, plot_significance, plot_n_1, calculate_significance2\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high  \n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14,\n",
    "    \"title\": 20\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"],  # Legend\n",
    "    \"axes.titlesize\": font_size[\"title\"] # Title\n",
    "})\n",
    "\n",
    "\n",
    "tot = []\n",
    "signal_name = 'ggHyyd'\n",
    "data = pd.DataFrame()\n",
    "\n",
    "def test(fb):\n",
    "    # checking if there are any none values\n",
    "    mask = ak.is_none(fb['met_tst_et'])\n",
    "    n_none = ak.sum(mask)\n",
    "    print(\"Number of none values: \", n_none)\n",
    "    # if n_none > 0:\n",
    "    #     fb = fb[~mask]\n",
    "    # print(\"Events after removing none values: \", len(fb), ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "\n",
    "def print_cut(ntuple_name, fb, label):\n",
    "    print(f\"{ntuple_name} Unweighted Events {label}: \", len(fb))\n",
    "    print(f\"{ntuple_name} Weighted Events {label}: \", sum(getWeight(fb, ntuple_name)))\n",
    "        \n",
    "for i in range(len(ntuple_names)):\n",
    "    start_time = time.time()\n",
    "    ntuple_name = ntuple_names[i]\n",
    "    path = f\"/data/fpiazza/ggHyyd/NtuplesWithBDTSkim/{ntuple_name}_nominal_bdt.root\"\n",
    "    f = uproot.open(path)['nominal']\n",
    "    if ntuple_name.startswith(\"mc\"):\n",
    "        fb = f.arrays(variables+variables_mc, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "        \n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "        fb = fb[fb['n_ph'] == 1]\n",
    "        fb = fb[fb['n_el_baseline'] == 0]\n",
    "\n",
    "        # goodPV on signal only\n",
    "        if ntuple_name == 'ggHyyd':\n",
    "            fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "            good_pv_tmp = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "            fb = fb[good_pv_tmp]\n",
    "            \n",
    "        \n",
    "    if (ntuple_name == \"data23_y\") or (ntuple_name == \"data24_y\"):  # jet-faking \n",
    "        fb = f.arrays(variables, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]\n",
    "        mask1 = (ak.firsts(fb['ph_topoetcone40'])-2450.)/ak.firsts(fb['ph_pt']) > 0.1   # jet_faking_photon cut\n",
    "        fb = fb[mask1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 1]\n",
    "        fb = fb[fb['n_el_baseline'] == 0]\n",
    "\n",
    "\n",
    "    if (ntuple_name == \"data23_eprobe\") or (ntuple_name == \"data24_eprobe\"): # electron-faking\n",
    "        fb = f.arrays(variables, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "        \n",
    "        fb = fb[fb['n_el'] == 1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 0]\n",
    "\n",
    "        # using electron info for photon info\n",
    "        fb['ph_pt'] = fb['el_pt']\n",
    "        fb['ph_eta'] = fb['el_eta']\n",
    "        fb['ph_phi'] = fb['el_phi']\n",
    "        fb['dphi_met_phterm'] = fb['dphi_met_eleterm']  \n",
    "\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0] # prevent none values in Tbranch\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) >= 50000] # ph_pt cut (basic cut)\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M']==1]\n",
    "    fb = fb[fb['met_tst_et'] >= 100000] # MET cut (basic cut)\n",
    "    fb = fb[fb['n_jet_central'] <= 3] # n_jet_central cut (basic cut)\n",
    "    \n",
    "    fb['VertexBDTScore'] = fb['BDTScore'] # renaming BDTScore to ensure this is recognized as Vertex BDT Score\n",
    "    fb = fb[fb['VertexBDTScore'] > 0.1]\n",
    "    \n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "                    (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    mask1 = mt_tmp > 100\n",
    "    mask2 = mt_tmp < 140\n",
    "    fb = fb[mask1 * mask2]\n",
    "\n",
    "    # ------ Adjustment --------\n",
    "    fb['weights'] = getWeight(fb, ntuple_name)\n",
    "    \n",
    "    dphi_met_jetterm_tmp = fb['dphi_met_jetterm']\n",
    "    cond = ak.fill_none(dphi_met_jetterm_tmp == -10, False)\n",
    "    fb['dphi_met_jetterm'] = ak.where(cond, -999, dphi_met_jetterm_tmp)\n",
    "\n",
    "    fb['dphi_met_phterm'] = np.arccos(np.cos(fb['dphi_met_phterm']))\n",
    "\n",
    "    print_cut(ntuple_name, fb, 'after basic')\n",
    "\n",
    "    test(fb) # check for none value\n",
    "\n",
    "    print(f\"Reading Time for {ntuple_name}: {(time.time()-start_time)} seconds\\n\")\n",
    "\n",
    "    tot.append(fb)\n",
    "\n",
    "    del fb \n",
    "\n",
    "# combining 23d + 23e {Zgamma (1, 6), Wgamma (2, 7), gammajet_direct (3, 8)}\n",
    "# combining 2023 + 2024 {data_y (4, 9), data_eprobe (5, 10)}\n",
    "tot_tmp = tot\n",
    "tot = [tot_tmp[0]]\n",
    "for i in tqdm(range(5)):\n",
    "    tot.append(ak.concatenate([tot_tmp[i+1], tot_tmp[i+6]]))\n",
    "ntuple_names = [\"ggHyyd\", \"Zgamma\", \"Wgamma\", \"gammajet_direct\", \"data_y\", \"data_eprobe\"]\n",
    "del tot_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06348be4-eee2-48c8-84ea-dbac12362388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance:  1.5690984893427113\n"
     ]
    }
   ],
   "source": [
    "def compute_total_significance(tot2, ntuple_names, signal_name, getVarDict):\n",
    "    signal_sum = 0\n",
    "    bkg_sum = 0\n",
    "    for i in range(len(ntuple_names)):\n",
    "        fb = tot2[i]\n",
    "        process = ntuple_names[i]\n",
    "        weights = fb['weights']\n",
    "        if process == signal_name:\n",
    "            signal_sum += ak.sum(weights)\n",
    "        else:\n",
    "            bkg_sum += ak.sum(weights)\n",
    "    return signal_sum / np.sqrt(bkg_sum) if bkg_sum > 0 else 0\n",
    "\n",
    "sig_tmp = compute_total_significance(tot, ntuple_names, signal_name, getVarDict)\n",
    "print(\"significance: \", sig_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c18b4ab6-b995-4a7b-bc6d-ecdacf70ef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance:  2.665468845273705\n"
     ]
    }
   ],
   "source": [
    "cuts1 = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -20000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "]\n",
    "\n",
    "tot2 = apply_all_cuts(tot, ntuple_names, cuts1, getVarDict)\n",
    "sig_tmp = compute_total_significance(tot2, ntuple_names, signal_name, getVarDict)\n",
    "print(\"significance: \", sig_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c921cc33-64a7-48a2-93b3-94c021c50513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VertexBDTScore > 0.1\n",
      "metsig > 6\n",
      "ph_eta < 1.75\n",
      "dphi_met_phterm > 1.25\n",
      "dmet > -10000\n",
      "dphi_jj < 2.5\n",
      "dphi_met_jetterm < 0.75\n",
      "significance:  2.5812533339885784\n"
     ]
    }
   ],
   "source": [
    "cuts1 = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -10000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "]\n",
    "\n",
    "tot2 = apply_all_cuts(tot, ntuple_names, cuts1, getVarDict)\n",
    "sig_tmp = compute_total_significance(tot2, ntuple_names, signal_name, getVarDict)\n",
    "\n",
    "\n",
    "for cut in cuts1:\n",
    "    var = cut['cut_var']\n",
    "    val = cut['best_cut']\n",
    "    if cut['cut_type'] == 'uppercut':\n",
    "        print(f\"{var} < {val}\")\n",
    "    elif cut['cut_type'] == 'lowercut':\n",
    "        print(f\"{var} > {val}\")\n",
    "        \n",
    "# print('after optimized cutting, signficance: ', final_significance)\n",
    "\n",
    "\n",
    "print(\"significance: \", sig_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74c03e9d-e0cb-433d-b90e-329e02d887af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef getCutDict():\\n    cut_dict = {}\\n    # Selection 1: same variables as in the internal note\\n    cut_dict['dmet'] = {\\n        'lowercut': np.arange(-30000, 10000 + 100, 100), # dmet > cut\\n        'uppercut': np.arange(10000, 100000 + 100, 100), # -10000 < dmet < cut\\n    }\\n    cut_dict['metsig'] = {\\n        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\\n        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \\n    }\\n    cut_dict['dphi_met_phterm'] = {\\n        'lowercut': np.arange(1, 2 + 0.01, 0.01), # dphi_met_phterm > cut\\n    }\\n    cut_dict['dphi_met_jetterm'] = {\\n        'uppercut': np.arange(0.5, 1, 0.01), # dphi_met_jetterm < cut\\n    }\\n    cut_dict['ph_eta'] = {\\n        'uppercut': np.arange(1, 2.5 + 0.01, 0.01), # ph_eta < cut\\n    }\\n    cut_dict['dphi_jj'] = {\\n        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\\n    }\\n\\n    # Selection 2\\n    cut_dict['balance'] = {\\n        'lowercut': np.arange(0.3, 1.5 + 0.05, 0.05), # balance > cut\\n    }\\n    cut_dict['jetterm'] = {\\n        'lowercut': np.arange(0, 150000+10000, 10000) # jetterm > cut\\n    }\\n    cut_dict['dphi_phterm_jetterm'] = {\\n        'lowercut': np.arange(1, 2.5 + 0.1, 0.1), # dphi_phterm_jetterm > cut\\n        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\\n    }\\n    cut_dict['metsigres'] = {\\n        'uppercut': np.arange(12000, 60000, 10000)\\n    }\\n    cut_dict['met_noJVT'] = {\\n        'lowercut': np.arange(50000, 120000, 10000),\\n    }\\n    \\n    return cut_dict\\ncut_config = getCutDict()\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getCutDict(): # same cut as the internal note\n",
    "    cut_dict = {}\n",
    "    \n",
    "    cut_dict['VertexBDTScore'] = {\n",
    "        'lowercut': np.arange(0.1, 0.36, 0.02),  # VertexBDTScore > cut\n",
    "    }\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 10000 + 5000, 5000), # dmet > cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(0, 2 + 0.05, 0.05), # dphi_met_phterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'uppercut': np.arange(0.5, 1, 0.05), # dphi_met_jetterm < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.05, 0.05), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.1 + 0.05, 0.05) # dphi_jj < cut\n",
    "    }\n",
    "    cut_dict['balance'] = {\n",
    "        'lowercut': np.arange(0.3, 1.5 + 0.05, 0.05), # balance > cut\n",
    "    }\n",
    "    cut_dict['jetterm'] = {\n",
    "        'lowercut': np.arange(0, 150000+10000, 10000) # jetterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.1, 0.1), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['metsigres'] = {\n",
    "        'uppercut': np.arange(12000, 60000, 10000)\n",
    "    }\n",
    "    cut_dict['met_noJVT'] = {\n",
    "        'lowercut': np.arange(50000, 120000, 10000),\n",
    "    }\n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "\n",
    "'''\n",
    "def getCutDict():\n",
    "    cut_dict = {}\n",
    "    # Selection 1: same variables as in the internal note\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 10000 + 100, 100), # dmet > cut\n",
    "        'uppercut': np.arange(10000, 100000 + 100, 100), # -10000 < dmet < cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(1, 2 + 0.01, 0.01), # dphi_met_phterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'uppercut': np.arange(0.5, 1, 0.01), # dphi_met_jetterm < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.01, 0.01), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\n",
    "    }\n",
    "\n",
    "    # Selection 2\n",
    "    cut_dict['balance'] = {\n",
    "        'lowercut': np.arange(0.3, 1.5 + 0.05, 0.05), # balance > cut\n",
    "    }\n",
    "    cut_dict['jetterm'] = {\n",
    "        'lowercut': np.arange(0, 150000+10000, 10000) # jetterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.1, 0.1), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['metsigres'] = {\n",
    "        'uppercut': np.arange(12000, 60000, 10000)\n",
    "    }\n",
    "    cut_dict['met_noJVT'] = {\n",
    "        'lowercut': np.arange(50000, 120000, 10000),\n",
    "    }\n",
    "    \n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "701aeca3-838d-4d2b-b707-8dde8b8c0f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VertexBDTScore 0 13\n",
      "{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -20000, 'best_sig_x_acc': 1.6198364927642324, 'significance': 1.6342900266183504, 'acceptance': 99.11560777960415}\n",
      "{'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6, 'best_sig_x_acc': 2.0972604819261904, 'significance': 2.2788018308797002, 'acceptance': 92.03347362225752}\n",
      "{'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.05, 'best_sig_x_acc': 1.6135286667758535, 'significance': 1.6401586619859487, 'acceptance': 98.37637688186514}\n",
      "{'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.8500000000000003, 'best_sig_x_acc': 1.5696778160158058, 'significance': 1.5696768086370052, 'acceptance': 100.00006417746603}\n",
      "{'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 2.4000000000000012, 'best_sig_x_acc': 1.5690994963503613, 'significance': 1.5690984893427113, 'acceptance': 100.00006417746603}\n",
      "dphi_jj 42 43\n",
      "{'cut_var': 'balance', 'cut_type': 'lowercut', 'best_cut': 0.8999999999999999, 'best_sig_x_acc': 1.6077654078674426, 'significance': 1.616985783358995, 'acceptance': 99.42978005209181}\n",
      "{'cut_var': 'jetterm', 'cut_type': 'lowercut', 'best_cut': 80000, 'best_sig_x_acc': 1.6005985148616129, 'significance': 1.6072016826433382, 'acceptance': 99.58915126501951}\n",
      "dphi_phterm_jetterm 0 16\n",
      "dphi_phterm_jetterm 0 21\n",
      "{'cut_var': 'metsigres', 'cut_type': 'uppercut', 'best_cut': 22000, 'best_sig_x_acc': 1.8635474542492794, 'significance': 2.089414158145706, 'acceptance': 89.18995054111835}\n",
      "{'cut_var': 'met_noJVT', 'cut_type': 'lowercut', 'best_cut': 100000, 'best_sig_x_acc': 1.6331710144342013, 'significance': 1.6492545394049012, 'acceptance': 99.02480032121038}\n"
     ]
    }
   ],
   "source": [
    "signal_name='ggHyyd'\n",
    "initial_cut = []\n",
    "# tot2 = tot  # return the initial cut\n",
    "\n",
    "# < -- Initial Cut on all variables (maximize the significance * acceptance) -- > \n",
    "for cut_var, cut_types in cut_config.items():\n",
    "    for cut_type, cut_values in cut_types.items():\n",
    "        sig_simple_list, sigacc_simple_list, acceptance_values = calculate_significance(\n",
    "            tot, ntuple_names, getVarDict, cut_var, cut_type, cut_values\n",
    "        )\n",
    "\n",
    "        best_cut, best_sig, idx = get_best_cut(cut_values, sigacc_simple_list) \n",
    "        \n",
    "        if idx == 0 or idx == len(sigacc_simple_list) - 1: # I chose to use index to indicate not to make unnecessary cut (for initial cut)\n",
    "            print(cut_var, idx, len(sigacc_simple_list))\n",
    "            continue\n",
    "            \n",
    "        result = {\n",
    "            \"cut_var\": cut_var,\n",
    "            \"cut_type\": cut_type,\n",
    "            \"best_cut\": best_cut,\n",
    "            \"best_sig_x_acc\": best_sig,\n",
    "            \"significance\": sig_simple_list[idx],\n",
    "            \"acceptance\": acceptance_values[idx]\n",
    "        }\n",
    "\n",
    "        print(result)\n",
    "        initial_cut.append(dict(list(result.items())[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bc79152-5490-422b-9c24-9578daa08249",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_cut.append({'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7d15f70-27f9-4ad7-82ee-4cb9c93f0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my cut\n",
    "initial_cuts = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -10000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "]\n",
    "\n",
    "\n",
    "# internal note cut (just in case)\n",
    "# initial_cuts = [\n",
    "#     {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "#     {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6},\n",
    "#     {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "#     {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "#     {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -20000},\n",
    "#     {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "#     {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f6e9d45-ced3-4179-ac43-65aa2394e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after initial cutting, signficance:  2.390334094119089\n"
     ]
    }
   ],
   "source": [
    "tot2_initial_cut = apply_all_cuts(tot, ntuple_names, initial_cut, getVarDict)\n",
    "final_significance = compute_total_significance(tot2_initial_cut, ntuple_names, signal_name, getVarDict)\n",
    "print('after initial cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "435c829b-a8dd-45eb-a394-b3fb350ebacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "Updating dmet (lowercut): -20000 → -25000  (N-1 2.387 → with-cut 2.393)\n",
      "Updating metsig (lowercut): 6 → 8  (N-1 2.290 → with-cut 2.482)\n",
      "Updating dphi_met_phterm (lowercut): 1.05 → 1.25  (N-1 2.466 → with-cut 2.503)\n",
      "Updating ph_eta (uppercut): 2.4000000000000012 → 1.7500000000000007  (N-1 2.503 → with-cut 2.603)\n",
      "Updating balance (lowercut): 0.8999999999999999 → 0.9999999999999998  (N-1 2.540 → with-cut 2.662)\n",
      "Updating metsigres (uppercut): 22000 → 42000  (N-1 2.747 → with-cut 2.747)\n",
      "Updating met_noJVT (lowercut): 100000 → 90000  (N-1 2.745 → with-cut 2.751)\n",
      "Updating VertexBDTScore (lowercut): 0.1 → 0.22000000000000003  (N-1 2.751 → with-cut 2.829)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Updating dphi_met_phterm (lowercut): 1.25 → 1.35  (N-1 2.771 → with-cut 2.830)\n",
      "Updating jetterm (lowercut): 80000 → 90000  (N-1 2.830 → with-cut 2.830)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "optimized cuts, end of iteration\n",
      "after optimized cutting, signficance:  2.830240585331781\n",
      "CPU times: user 36 s, sys: 116 ms, total: 36.1 s\n",
      "Wall time: 36.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# < -- n-1 iterations until no further improvement (max significance) -- >\n",
    "optimized_cuts, final_significance = n_minus_1_optimizer(\n",
    "    initial_cut, cut_config, tot, ntuple_names, signal_name, getVarDict, final_significance, allow_drop=False\n",
    ")\n",
    "print('after optimized cutting, signficance: ', final_significance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "046f0a65-fada-4152-9fdb-b68f5222ede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " < -- Final Optimized Cuts -- > \n",
      "dmet > -25000.0\n",
      "metsig > 8.0\n",
      "dphi_met_phterm > 1.35\n",
      "dphi_met_jetterm < 0.8500000000000003\n",
      "ph_eta < 1.7500000000000007\n",
      "balance > 0.9999999999999998\n",
      "jetterm > 90000.0\n",
      "metsigres < 42000.0\n",
      "met_noJVT > 90000.0\n",
      "VertexBDTScore > 0.22000000000000003\n",
      "after optimized cutting, signficance:  2.830240585331781\n"
     ]
    }
   ],
   "source": [
    "print( ' < -- Final Optimized Cuts -- > ')\n",
    "# print(optimized_cuts)\n",
    "\n",
    "for cut in optimized_cuts:\n",
    "    var = cut['cut_var']\n",
    "    val = cut['best_cut']\n",
    "    if cut['cut_type'] == 'uppercut':\n",
    "        print(f\"{var} < {val}\")\n",
    "    elif cut['cut_type'] == 'lowercut':\n",
    "        print(f\"{var} > {val}\")\n",
    "        \n",
    "print('after optimized cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28d576eb-eb6f-473c-8214-977c6c58c46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 cut       S         B  S/sqrt(B)  ZBi(30%)\n",
      "      (no extra cut) 180.522 4,496.285      2.692    -0.065\n",
      "           balance>1 177.398 3,956.804      2.820    -0.050\n",
      "met_jetterm_et>80GeV 180.522 4,491.873      2.693    -0.065\n",
      "     metsigres<42GeV 180.522 4,488.710      2.694    -0.065\n",
      "    met_noJVT>100GeV 180.011 4,456.464      2.697    -0.065\n"
     ]
    }
   ],
   "source": [
    "signal_name = 'ggHyyd'\n",
    "\n",
    "# --- helpers ---\n",
    "def weight_sum(fb, ntuple_name):\n",
    "    return ak.sum(fb['weights'])\n",
    "\n",
    "def s_over_sqrt_b(S, B):\n",
    "    return S/np.sqrt(B) if B > 0 else 0.0\n",
    "\n",
    "def zbi(S, B, sigma_b_frac=0.30):\n",
    "    # Binomial significance with background uncertainty\n",
    "    if B <= 0:\n",
    "        return 0.0\n",
    "    tau   = 1.0 / (B * sigma_b_frac * sigma_b_frac)\n",
    "    n_on  = S + B\n",
    "    n_off = B * tau\n",
    "    P_Bi  = betainc(n_on, n_off + 1, 1.0 / (1.0 + tau))\n",
    "    if P_Bi <= 0:\n",
    "        return 0.0\n",
    "    return float(norm.ppf(1.0 - P_Bi))\n",
    "\n",
    "# Minimal, branchless Δφ in [0, π]\n",
    "def dphi(a, b):\n",
    "    return np.abs((a - b + np.pi) % (2*np.pi) - np.pi)\n",
    "\n",
    "# --- define the \"further selection\" cuts as functions that return a boolean mask ---\n",
    "def cut_balance_gt_0p91(fb):\n",
    "    sumet_tmp = fb['jet_central_vecSumPt']\n",
    "    expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(sumet_tmp != 0, sumet_tmp, 1)\n",
    "    balance = ak.where(sumet_tmp != 0, expr, -999) \n",
    "    return (balance == -999) | (balance > 1)\n",
    "\n",
    "def cut_met_jetterm_et_gt_92GeV(fb):\n",
    "    return fb['met_jetterm_et'] > 80_000\n",
    "\n",
    "def cut_dphi_phterm_jetterm_window(fb, low=1.6, high=3.1):\n",
    "    # angle defined only if met_jetterm_et>0; missing → pass\n",
    "    cond  = fb['met_jetterm_et'] > 0\n",
    "    angle = ak.where(cond, dphi(fb['met_phterm_phi'], fb['met_jetterm_phi']), 0.0)\n",
    "    return (~cond) | ((angle > low) & (angle < high))\n",
    "\n",
    "def cut_metsigres_lt_36GeV(fb):\n",
    "    # metsigres = MET / METsig  (in MeV; 36 GeV = 36000 MeV)\n",
    "    # Guard against nonpositive sig; if sig<=0, we conservatively fail the cut.\n",
    "    sig_ok = fb['met_tst_sig'] > 0\n",
    "    ratio  = ak.where(sig_ok, fb['met_tst_et'] / fb['met_tst_sig'], np.inf)\n",
    "    return ratio < 42_000\n",
    "\n",
    "def cut_met_noJVT_gt_90GeV(fb):\n",
    "    return fb['met_tst_noJVT_et'] > 100_000\n",
    "\n",
    "# Bundle all the single-cut masks you want to test\n",
    "CUTS = [\n",
    "    (\"balance>1\",              cut_balance_gt_0p91),\n",
    "    (\"met_jetterm_et>80GeV\",      cut_met_jetterm_et_gt_92GeV),\n",
    "    # (\"1.6<dphi(phterm,jetterm)<3.1\", cut_dphi_phterm_jetterm_window),\n",
    "    (\"metsigres<42GeV\",           cut_metsigres_lt_36GeV),\n",
    "    (\"met_noJVT>100GeV\",           cut_met_noJVT_gt_90GeV),\n",
    "]\n",
    "\n",
    "def significance_by_single_cuts(tot, ntuple_names, signal_name=\"ggHyyd\", sigma_b_frac=0.30, include_zbi=True):\n",
    "    \"\"\"\n",
    "    For each cut in CUTS: apply only that cut on top of the baseline 'tot',\n",
    "    then compute S, B, S/sqrt(B) (and ZBi).\n",
    "    Returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Precompute per-sample weights once (so we don't rebuild weights inside each cut)\n",
    "    weights = []\n",
    "    for i, fb in enumerate(tot):\n",
    "        name = ntuple_names[i]\n",
    "        w = fb['weights']\n",
    "        weights.append(w)\n",
    "\n",
    "    rows = []\n",
    "    # Also compute baseline (no extra cut) significance for reference\n",
    "    S0 = 0.0\n",
    "    B0 = 0.0\n",
    "    for i, fb in enumerate(tot):\n",
    "        name = ntuple_names[i]\n",
    "        wsum = float(ak.sum(weights[i]))\n",
    "        if name == signal_name:\n",
    "            S0 += wsum\n",
    "        else:      # exclude data from B\n",
    "            B0 += wsum\n",
    "    base = {\n",
    "        \"cut\": \"(no extra cut)\",\n",
    "        \"S\": S0,\n",
    "        \"B\": B0,\n",
    "        \"S/sqrt(B)\": s_over_sqrt_b(S0, B0)\n",
    "    }\n",
    "    if include_zbi:\n",
    "        base[\"ZBi(30%)\"] = zbi(S0, B0, sigma_b_frac)\n",
    "    rows.append(base)\n",
    "\n",
    "    # Now evaluate each single cut\n",
    "    for label, cut_fn in CUTS:\n",
    "        S = 0.0\n",
    "        B = 0.0\n",
    "        for i, fb in enumerate(tot):\n",
    "            name = ntuple_names[i]\n",
    "            m = cut_fn(fb)                      # boolean mask (Awkward-friendly)\n",
    "            w = weights[i][m]                   # apply mask to precomputed event weights\n",
    "            wsum = float(ak.sum(w))\n",
    "            if name == signal_name:\n",
    "                S += wsum\n",
    "            else:\n",
    "                B += wsum\n",
    "\n",
    "        row = {\n",
    "            \"cut\": label,\n",
    "            \"S\": S,\n",
    "            \"B\": B,\n",
    "            \"S/sqrt(B)\": s_over_sqrt_b(S, B)\n",
    "        }\n",
    "        if include_zbi:\n",
    "            row[\"ZBi(30%)\"] = zbi(S, B, sigma_b_frac)\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Nicely formatted view (optional)\n",
    "    with pd.option_context('display.float_format', '{:,.3f}'.format):\n",
    "        print(df.to_string(index=False))\n",
    "    return df\n",
    "\n",
    "\n",
    "initial_cuts = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.2},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -15000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.35},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.85},\n",
    "]\n",
    "tot2_initial_cut = apply_all_cuts(tot, ntuple_names, initial_cuts, getVarDict)\n",
    "\n",
    "# --- RUN IT ---\n",
    "sig_table = significance_by_single_cuts(tot2_initial_cut, ntuple_names, signal_name='ggHyyd', sigma_b_frac=0.30, include_zbi=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44940971-f170-422f-b73d-01f3843655cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -25000.0},\n",
       " {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 8.0},\n",
       " {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.35},\n",
       " {'cut_var': 'dphi_met_jetterm',\n",
       "  'cut_type': 'uppercut',\n",
       "  'best_cut': 0.8500000000000003},\n",
       " {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.7500000000000007},\n",
       " {'cut_var': 'balance',\n",
       "  'cut_type': 'lowercut',\n",
       "  'best_cut': 0.9999999999999998},\n",
       " {'cut_var': 'jetterm', 'cut_type': 'lowercut', 'best_cut': 90000.0},\n",
       " {'cut_var': 'metsigres', 'cut_type': 'uppercut', 'best_cut': 42000.0},\n",
       " {'cut_var': 'met_noJVT', 'cut_type': 'lowercut', 'best_cut': 90000.0},\n",
       " {'cut_var': 'VertexBDTScore',\n",
       "  'cut_type': 'lowercut',\n",
       "  'best_cut': 0.22000000000000003}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9ef0a29-fe76-4614-ba44-4a87cb9c2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_cuts2 = [{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -15000.0},\n",
    " {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7.0},\n",
    " {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.20},\n",
    " {'cut_var': 'dphi_met_jetterm',\n",
    "  'cut_type': 'uppercut',\n",
    "  'best_cut': 0.8500000000000003},\n",
    " {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.7500000000000007},\n",
    " {'cut_var': 'balance',\n",
    "  'cut_type': 'lowercut',\n",
    "  'best_cut': 0.9999999999999998},\n",
    " {'cut_var': 'jetterm', 'cut_type': 'lowercut', 'best_cut': 80000.0},\n",
    " {'cut_var': 'metsigres', 'cut_type': 'uppercut', 'best_cut': 42000.0},\n",
    " {'cut_var': 'met_noJVT', 'cut_type': 'lowercut', 'best_cut': 100000.0},\n",
    " {'cut_var': 'VertexBDTScore',\n",
    "  'cut_type': 'lowercut',\n",
    "  'best_cut': 0.1000000000000003}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a5df7e9-0dbd-4b83-9c54-3e3fb9ef2184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< -- Sum of weight each process -- >\n",
      "ggHyyd 186.12543\n",
      "Zgamma 527.19464\n",
      "Wgamma 1009.02875\n",
      "gammajet_direct 42.67856\n",
      "data_y 1054.260999999995\n",
      "data_eprobe 1854.7567422406833\n"
     ]
    }
   ],
   "source": [
    "tot2_optimized_cuts = apply_all_cuts(tot, ntuple_names, optimized_cuts2, getVarDict)\n",
    "\n",
    "print('< -- Sum of weight each process -- >')\n",
    "\n",
    "for i in range(len(tot2_optimized_cuts)):\n",
    "    print(ntuple_names[i], ak.sum(tot2_optimized_cuts[i]['weights']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "617519cd-9838-4142-a601-9a0d47ecee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< -- Sum of weight each process -- >\n",
      "ggHyyd 188.84154\n",
      "Zgamma 497.98044\n",
      "Wgamma 980.3159\n",
      "gammajet_direct 109.93676\n",
      "data_y 1708.3380000000134\n",
      "data_eprobe 2055.646897520867\n",
      "significance : 2.5812533339885784\n"
     ]
    }
   ],
   "source": [
    "initial_cuts = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -10000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "]\n",
    "print('< -- Sum of weight each process -- >')\n",
    "tot_tmp = apply_all_cuts(tot, ntuple_names, initial_cuts, getVarDict)\n",
    "for i in range(len(tot)):\n",
    "    print(ntuple_names[i], ak.sum(tot_tmp[i]['weights']))\n",
    "print(f'significance : {compute_total_significance(tot_tmp, ntuple_names, signal_name, getVarDict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18651011-5823-4d99-8fee-4dc1aa450193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< -- Sum of weight each process -- >\n",
      "ggHyyd 186.12543\n",
      "Zgamma 527.19464\n",
      "Wgamma 1009.02875\n",
      "gammajet_direct 42.67856\n",
      "data_y 1054.260999999995\n",
      "data_eprobe 1854.7567422406833\n",
      "significance : 2.7783257837777087\n"
     ]
    }
   ],
   "source": [
    "# cuts = [\n",
    "#     {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "#     {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7},\n",
    "#     {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "#     {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.20},\n",
    "#     {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -15000},\n",
    "#     {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.35},\n",
    "#     {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.85},\n",
    "# ]\n",
    "cuts = [{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -15000.0},\n",
    " {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7.0},\n",
    " {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.20},\n",
    " {'cut_var': 'dphi_met_jetterm',\n",
    "  'cut_type': 'uppercut',\n",
    "  'best_cut': 0.8500000000000003},\n",
    " {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.7500000000000007},\n",
    " {'cut_var': 'balance',\n",
    "  'cut_type': 'lowercut',\n",
    "  'best_cut': 0.9999999999999998},\n",
    " {'cut_var': 'jetterm', 'cut_type': 'lowercut', 'best_cut': 80000.0},\n",
    " {'cut_var': 'metsigres', 'cut_type': 'uppercut', 'best_cut': 42000.0},\n",
    " {'cut_var': 'met_noJVT', 'cut_type': 'lowercut', 'best_cut': 100000.0},\n",
    " {'cut_var': 'VertexBDTScore',\n",
    "  'cut_type': 'lowercut',\n",
    "  'best_cut': 0.1000000000000003}]\n",
    "print('< -- Sum of weight each process -- >')\n",
    "tot_tmp = apply_all_cuts(tot, ntuple_names, cuts, getVarDict)\n",
    "for i in range(len(tot)):\n",
    "    print(ntuple_names[i], ak.sum(tot_tmp[i]['weights']))\n",
    "print(f'significance : {compute_total_significance(tot_tmp, ntuple_names, signal_name, getVarDict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84d051b6-b485-4ec5-a815-ff440ac67d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_ph.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_ph_baseline.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_el.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_el_baseline.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_mu_baseline.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_tau_baseline.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/mt.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/metsig.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/metsigres.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/met.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/met_noJVT.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/dmet.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/ph_pt.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/ph_eta.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/ph_phi.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/pv_ntracks.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jet_central_eta.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jet_central_vecSumPt.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jet_central_pt1.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jet_central_pt2.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/dphi_met_phterm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/dphi_met_jetterm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/dphi_phterm_jetterm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/failJVT_jet_pt1.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/failJVT_jet_vecSumPt.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/softerm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jetterm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jetterm_sumet.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_jet.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_jet_central.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_jet_fwd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/central_jets_fraction.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/balance.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/dphi_jj.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/VertexBDTScore.png\n"
     ]
    }
   ],
   "source": [
    "# path for plot storage\n",
    "mt_val_dir = 'mt100_140'\n",
    "\n",
    "# cut_name = 'basic'\n",
    "# plot_performance(tot, ntuple_names, sample_dict, getVarDict, zbi, mt_val_dir, cut_name) # basic\n",
    "\n",
    "cut_name = 'selection2'\n",
    "plot_performance(tot_tmp, ntuple_names, sample_dict, getVarDict, zbi, mt_val_dir, cut_name) # selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04ae786-3c3f-4590-bc86-2e4eec534155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_VertexBDTScore_lowercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1974/2488400607.py:294: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:295: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:296: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/VertexBDTScore.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_VertexBDTScore.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_metsig_lowercut.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/metsig.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_metsig.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_ph_eta_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1974/2488400607.py:294: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:295: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:296: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/ph_eta.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_ph_eta.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dmet_lowercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1974/2488400607.py:294: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:295: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:296: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dmet.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dmet.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dphi_jj_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1974/2488400607.py:294: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:295: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:296: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dphi_jj.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dphi_jj.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dphi_met_phterm_lowercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1974/2488400607.py:294: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:295: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:296: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dphi_met_phterm.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dphi_met_phterm.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dphi_met_jetterm_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1974/2488400607.py:294: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:295: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_1974/2488400607.py:296: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dphi_met_jetterm.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dphi_met_jetterm.png\n"
     ]
    }
   ],
   "source": [
    "def sel(tot, n_1_name=None):\n",
    "    \"\"\"\n",
    "    Apply baseline cuts to all fb in tot except the variable named by n_1_name.\n",
    "    \"\"\"\n",
    "    import awkward as ak\n",
    "    out = []\n",
    "    for i in range(len(tot)):\n",
    "        fb2 = tot[i]\n",
    "\n",
    "        if n_1_name != \"VertexBDTScore\":\n",
    "            VertexBDTScore_tmp = fb2['VertexBDTScore']\n",
    "            fb2 = fb2[VertexBDTScore_tmp > 0.10]\n",
    "\n",
    "        if n_1_name != \"metsig\":\n",
    "            metsig_tmp = fb2['met_tst_sig']\n",
    "            fb2 = fb2[(metsig_tmp > 7)]\n",
    "\n",
    "        if n_1_name != \"ph_eta\":\n",
    "            ph_eta_tmp = np.abs(ak.firsts(fb2['ph_eta']))\n",
    "            fb2 = fb2[ph_eta_tmp < 1.75]\n",
    "\n",
    "        if n_1_name != \"dphi_met_phterm\":\n",
    "            dphi_met_phterm_tmp = fb2['dphi_met_phterm']\n",
    "            fb2 = fb2[dphi_met_phterm_tmp > 1.20]\n",
    "            \n",
    "        if n_1_name != \"dmet\":\n",
    "            dmet_tmp = fb2['dmet']\n",
    "            fb2 = fb2[(dmet_tmp > -15000)]\n",
    "\n",
    "        if n_1_name != \"dphi_met_jetterm\":\n",
    "            dphi_met_jetterm_tmp = fb2['dphi_met_jetterm']\n",
    "            fb2 = fb2[dphi_met_jetterm_tmp <= 0.85]\n",
    "\n",
    "        if n_1_name != \"dphi_jj\":\n",
    "            dphi_jj_tmp = fb2['dphi_central_jj']\n",
    "            dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "            dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "            dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "            fb2 = fb2[dphi_jj_tmp < 2.35]\n",
    "\n",
    "        if n_1_name != \"balance\":\n",
    "            sumet_tmp = fb['jet_central_vecSumPt']\n",
    "            expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(sumet_tmp != 0, sumet_tmp, 1)\n",
    "            balance_tmp = ak.where(sumet_tmp != 0, expr, -999) \n",
    "            mask_nan = balance_tmp == -999\n",
    "            mask = mask_nan | (balance_tmp > 0.1)\n",
    "            fb2 = fb2[mask]\n",
    "            \n",
    "        if n_1_name != \"jetterm\":\n",
    "            fb2 = fb2[fb2['met_jetterm_et'] > 80_000]\n",
    "            \n",
    "        if n_1_name != \"metsigres\":\n",
    "            sig_ok = fb2['met_tst_sig'] > 0\n",
    "            ratio  = ak.where(sig_ok, fb2['met_tst_et'] / fb2['met_tst_sig'], np.inf)\n",
    "            fb2 = fb2[ratio < 42_000]\n",
    "            \n",
    "        if n_1_name != \"met_noJVT\":\n",
    "            fb2 = fb2[fb2['met_tst_noJVT_et'] > 90_000]\n",
    "\n",
    "        out.append(fb2)\n",
    "    return out\n",
    "\n",
    "def getCutDict(n_1_name=None):\n",
    "    cut_dict = {}\n",
    "    if n_1_name is None or n_1_name == \"VertexBDTScore\":\n",
    "        cut_dict['VertexBDTScore'] = {'lowercut': np.arange(0.10, 0.24, 0.02)}\n",
    "    if n_1_name is None or n_1_name == \"dmet\":\n",
    "        cut_dict['dmet'] = {'lowercut': np.arange(-30000, 10000 + 5000, 5000)}\n",
    "    if n_1_name is None or n_1_name == \"metsig\":\n",
    "        cut_dict['metsig'] = {'lowercut': np.arange(0, 10 + 1, 1)}\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_phterm\":\n",
    "        cut_dict['dphi_met_phterm'] = {'lowercut': np.arange(1, 2 + 0.05, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_jetterm\":\n",
    "        cut_dict['dphi_met_jetterm'] = {'uppercut': np.arange(0.5, 1.00, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"ph_eta\":\n",
    "        cut_dict['ph_eta'] = {'uppercut': np.arange(1.0, 2.50 + 0.05, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"dphi_jj\":\n",
    "        cut_dict['dphi_jj'] = {'uppercut': np.arange(1.0, 3.10 + 0.05, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"balance\":\n",
    "        cut_dict['balance'] = {'lowercut': np.arange(0.3, 1.5 + 0.05, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"jetterm\":\n",
    "        cut_dict['jetterm'] = {'lowercut': np.arange(0, 150000+10000, 10000)}\n",
    "    if n_1_name is None or n_1_name == \"metsigres\":\n",
    "        cut_dict['metsigres'] = {'uppercut': np.arange(12000, 60000, 10000)}\n",
    "    if n_1_name is None or n_1_name == \"met_noJVT\":\n",
    "        cut_dict['met_noJVT'] = {'lowercut': np.arange(50000, 120000, 10000)}\n",
    "    return cut_dict\n",
    "\n",
    "\n",
    "def calculate_significance2(tot, ntuple_names, getVarDict, zbi, cut_var, cut_type, cut_values, signal_name=\"ggHyyd\"):\n",
    "    \n",
    "    sig_simple_list = []\n",
    "    sig_s_plus_b_list = []\n",
    "    sig_s_plus_1p3b_list = []\n",
    "    sig_binomial_list = []\n",
    "\n",
    "    sigacc_simple_list = []\n",
    "    sigacc_s_plus_b_list = []\n",
    "    sigacc_s_plus_1p3b_list = []\n",
    "    sigacc_binomial_list = []\n",
    "\n",
    "    acceptance_values = []  # Store acceptance percentages\n",
    "\n",
    "    for cut in cut_values:\n",
    "        sig_after_cut = 0\n",
    "        bkg_after_cut = []\n",
    "        sig_events = 0\n",
    "        \n",
    "        for i in range(len(ntuple_names)):\n",
    "            fb = tot[i]\n",
    "            process = ntuple_names[i]\n",
    "            var_config = getVarDict(fb, process, var_name=cut_var)\n",
    "            x = var_config[cut_var]['var']\n",
    "            mask_nan = x == -999\n",
    "            \n",
    "            if process == signal_name:\n",
    "                sig_events = fb['weights']\n",
    "                mask_cut = x > cut if cut_type == 'lowercut' else x < cut\n",
    "                mask = mask_nan | mask_cut\n",
    "                sig_after_cut = ak.sum(sig_events[mask])\n",
    "            else:\n",
    "                bkg_events = fb['weights']\n",
    "                mask_cut = x > cut if cut_type == 'lowercut' else x < cut\n",
    "                mask = mask_nan | mask_cut\n",
    "                bkg_after_cut.append(ak.sum(bkg_events[mask]))\n",
    "\n",
    "       # Now compute different types of significance\n",
    "        total_bkg = sum(bkg_after_cut)\n",
    "        total_signal = sig_after_cut\n",
    "\n",
    "        # Avoid zero division carefully\n",
    "        if total_bkg > 0:\n",
    "            sig_simple = total_signal / np.sqrt(total_bkg)\n",
    "            sig_s_plus_b = total_signal / np.sqrt(total_signal + total_bkg) if (total_signal + total_bkg) > 0 else 0\n",
    "            sig_s_plus_1p3b = total_signal / np.sqrt(total_signal + 1.3 * total_bkg) if (total_signal + 1.3*total_bkg) > 0 else 0\n",
    "            sig_binomial = zbi(total_signal, total_bkg, sigma_b_frac=0.3)\n",
    "        else:\n",
    "            sig_simple = sig_s_plus_b = sig_s_plus_1p3b = sig_binomial = 0\n",
    "\n",
    "        # Acceptance\n",
    "        acceptance = total_signal / sum(sig_events) if sum(sig_events) > 0 else 0\n",
    "        acceptance_values.append(acceptance * 100)  # percentage\n",
    "\n",
    "        # Save significance\n",
    "        sig_simple_list.append(sig_simple)\n",
    "        sig_s_plus_b_list.append(sig_s_plus_b)\n",
    "        sig_s_plus_1p3b_list.append(sig_s_plus_1p3b)\n",
    "        sig_binomial_list.append(sig_binomial)\n",
    "\n",
    "        # Save significance × acceptance\n",
    "        sigacc_simple_list.append(sig_simple * acceptance)\n",
    "        sigacc_s_plus_b_list.append(sig_s_plus_b * acceptance)\n",
    "        sigacc_s_plus_1p3b_list.append(sig_s_plus_1p3b * acceptance)\n",
    "        sigacc_binomial_list.append(sig_binomial * acceptance)\n",
    "\n",
    "    return (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "            sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "            acceptance_values)\n",
    "\n",
    "\n",
    "# --- config ---\n",
    "mt_val_dir = 'mt100_140'\n",
    "n_1_config = [\"VertexBDTScore\", \"metsig\", \"ph_eta\", \"dmet\", \"dphi_jj\", \"dphi_met_phterm\", \"dphi_met_jetterm\", \"balance\", \"jetterm\", \"metsigres\", \"met_noJVT\"]\n",
    "signal_name = 'ggHyyd'\n",
    "cut_name = 'n-1' \n",
    "\n",
    "\n",
    "def plot_n_1(tot, ntuple_names, sample_dict, getVarDict, zbi, getCutDict, sel, mt_val_dir, n_1_config, cut_name='n-1', signal_name=\"ggHyyd\"):\n",
    "\n",
    "    def ensure_dir(path_str):\n",
    "        Path(path_str).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def to_np(a):\n",
    "        \"\"\"Flatten awkward/numpy to 1D numpy array; empty-safe.\"\"\"\n",
    "        if a is None:\n",
    "            return np.array([])\n",
    "        try:\n",
    "            import awkward as ak\n",
    "            if hasattr(ak, \"to_numpy\"):\n",
    "                return ak.to_numpy(ak.flatten(a, axis=None))\n",
    "        except Exception:\n",
    "            pass\n",
    "        return np.asarray(a).ravel()\n",
    "    \n",
    "    def safe_concat(list_of_arrays):\n",
    "        \"\"\"Concatenate list of arrays safely (possibly empty).\"\"\"\n",
    "        if len(list_of_arrays) == 0:\n",
    "            return np.array([])\n",
    "        arrs = [to_np(x) for x in list_of_arrays if x is not None]\n",
    "        return np.concatenate(arrs) if len(arrs) else np.array([])\n",
    "    \n",
    "    def safe_hist(x, bins, w=None):\n",
    "        if x.size == 0:\n",
    "            return np.zeros(len(bins)-1, dtype=float), bins\n",
    "        return np.histogram(x, bins=bins, weights=w)\n",
    "    \n",
    "    # ---------- N-1 scan + plots ----------\n",
    "    \n",
    "    out_base = f\"/home/jlai/dark_photon/main/{mt_val_dir}/{cut_name}cut\"\n",
    "    ensure_dir(out_base)\n",
    "    \n",
    "    for cut_var_tmp in n_1_config:\n",
    "        cut_config = getCutDict(n_1_name=cut_var_tmp)\n",
    "        tot2 = sel(tot, n_1_name=cut_var_tmp)\n",
    "    \n",
    "        # --- Significance vs cut scans for this n-1 variable ---\n",
    "        for cut_var, cut_types in cut_config.items():\n",
    "            for cut_type, cut_values in cut_types.items():\n",
    "                (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "                 sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "                 acceptance_values) = calculate_significance2(tot, ntuple_names, getVarDict, zbi, cut_var, cut_type, cut_values)\n",
    "    \n",
    "                fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "    \n",
    "                # Top: S/sqrt(B) and vertical line at max\n",
    "                i_max = int(np.argmax(sig_simple_list)) if len(sig_simple_list) else 0\n",
    "                max_tmp = float(cut_values[i_max]) if len(cut_values) else np.nan\n",
    "                if len(cut_values):\n",
    "                    ax_top.axvline(x=max_tmp, color='r', linestyle='--', label=f'Max S/√B at {max_tmp:.2f}')\n",
    "                ax_top.plot(cut_values, sig_simple_list, marker='o', label='S/√B')\n",
    "                # Uncomment if you want the other metrics on same plot:\n",
    "                # ax_top.plot(cut_values, sig_s_plus_b_list, marker='s', label='S/√(S+B)')\n",
    "                # ax_top.plot(cut_values, sig_s_plus_1p3b_list, marker='^', label='S/√(S+1.3B)')\n",
    "                # ax_top.plot(cut_values, sig_binomial_list, marker='x', label='BinomialExpZ')\n",
    "                ax_top.set_ylabel('Significance')\n",
    "                ax_top.set_title(f'N-1: Significance vs. {cut_var} ({cut_type})')\n",
    "                ax_top.grid(True)\n",
    "                ax_top.legend()\n",
    "    \n",
    "                # Bottom: (S/√B) × Acceptance\n",
    "                if len(cut_values):\n",
    "                    ax_bot.axvline(x=max_tmp, color='r', linestyle='--')\n",
    "                ax_bot.plot(cut_values, sigacc_simple_list, marker='o', label='(S/√B) × Acceptance')\n",
    "    \n",
    "                for i, acc in enumerate(acceptance_values):\n",
    "                    ax_bot.text(cut_values[i], sigacc_simple_list[i], f'{acc:.1f}%',\n",
    "                                fontsize=9, ha='right', va='bottom', color='purple')\n",
    "    \n",
    "                # Label with pretty var title\n",
    "                var_cfg_for_label = getVarDict(tot2[0], signal_name, cut_var)\n",
    "                ax_bot.set_xlabel(var_cfg_for_label[cut_var]['title'])\n",
    "                ax_bot.set_ylabel('Significance × Acceptance')\n",
    "                ax_bot.grid(True)\n",
    "                ax_bot.legend()\n",
    "    \n",
    "                plt.tight_layout()\n",
    "                out_path = f\"{out_base}/significance_{cut_var}_{cut_type}.png\"\n",
    "                ensure_dir(Path(out_path).parent.as_posix())\n",
    "                plt.savefig(out_path)\n",
    "                print(f\"Saved: {out_path}\")\n",
    "                plt.close()\n",
    "    \n",
    "        # --- N-1 distributions + per-bin significance & ROC for THIS variable ---\n",
    "        var_cfg_sig = getVarDict(tot2[0], signal_name, var_name=cut_var_tmp)  # only request this var\n",
    "        for var in var_cfg_sig:\n",
    "            bg_vals, bg_wts, bg_cols, bg_labs = [], [], [], []\n",
    "            sig_vals, sig_wts = [], []\n",
    "            sig_col = None\n",
    "            sig_lab = None\n",
    "    \n",
    "            # Build stacks\n",
    "            for j in range(len(ntuple_names)):\n",
    "                process = ntuple_names[j]\n",
    "                fb2 = tot2[j]\n",
    "                var_cfg = getVarDict(fb2, process, var_name=var)\n",
    "                x = var_cfg[var]['var']\n",
    "                bins = var_cfg[var]['bins']\n",
    "                weights = fb2['weights']\n",
    "    \n",
    "                info = sample_dict[process]\n",
    "                if process == signal_name:\n",
    "                    sig_vals.append(x)\n",
    "                    sig_wts.append(weights)\n",
    "                    sig_col = info['color']; sig_lab = info['legend']\n",
    "                else:\n",
    "                    bg_vals.append(x); bg_wts.append(weights)\n",
    "                    bg_cols.append(info['color']); bg_labs.append(info['legend'])\n",
    "    \n",
    "            # Convert/concat\n",
    "            sig_all = safe_concat(sig_vals)\n",
    "            sig_w_all = safe_concat(sig_wts)\n",
    "            bg_all = safe_concat(bg_vals)\n",
    "            bg_w_all = safe_concat(bg_wts)\n",
    "    \n",
    "            # Figure / axes\n",
    "            fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(12, 13), gridspec_kw={'height_ratios':[9,4]})\n",
    "    \n",
    "            # Stacked BG + signal outline\n",
    "            if len(bg_vals):\n",
    "                ax_top.hist([to_np(v) for v in bg_vals], bins=bins,\n",
    "                            weights=[to_np(w) for w in bg_wts], color=bg_cols,\n",
    "                            label=bg_labs, stacked=True)\n",
    "            if sig_all.size:\n",
    "                ax_top.hist(sig_all, bins=bins, weights=sig_w_all, color=sig_col,\n",
    "                            label=sig_lab, histtype='step', linewidth=2)\n",
    "    \n",
    "                # Signal error bars\n",
    "                s_counts, s_edges = safe_hist(sig_all, bins=bins, w=sig_w_all)\n",
    "                s2, _ = safe_hist(sig_all, bins=bins, w=sig_w_all**2 if sig_w_all.size else None)\n",
    "                bin_centers = 0.5*(s_edges[:-1] + s_edges[1:])\n",
    "                s_err = np.sqrt(s2)\n",
    "                ax_top.errorbar(bin_centers, s_counts, yerr=s_err, fmt='.', linewidth=2,\n",
    "                                color=sig_col, capsize=0)\n",
    "    \n",
    "            ax_top.set_yscale('log')\n",
    "            ax_top.set_ylim(max(1e-4, 1e-6), 1e11)\n",
    "            ax_top.set_xlim(bins[0], bins[-1])\n",
    "            ax_top.minorticks_on()\n",
    "            ax_top.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "            ax_top.set_ylabel(\"Events\")\n",
    "            ax_top.legend(ncol=2)\n",
    "    \n",
    "            # Per-bin significance curves\n",
    "            S_counts, _ = safe_hist(sig_all, bins=bins, w=sig_w_all)\n",
    "            B_counts, _ = safe_hist(bg_all, bins=bins, w=bg_w_all)\n",
    "    \n",
    "            sqrt_B = np.sqrt(np.clip(B_counts, 0, None))\n",
    "            sqrt_SplusB = np.sqrt(np.clip(S_counts + B_counts, 0, None))\n",
    "            sqrt_Splus1p3B = np.sqrt(np.clip(S_counts + 1.3*B_counts, 0, None))\n",
    "    \n",
    "            sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
    "            sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
    "            sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n",
    "    \n",
    "            # Binomial ExpZ per bin\n",
    "            zbi_per_bin = np.array([zbi(S_counts[i], B_counts[i], sigma_b_frac=0.3) for i in range(len(S_counts))])\n",
    "    \n",
    "            bin_centers = 0.5*(bins[:-1] + bins[1:])\n",
    "    \n",
    "            # Totals\n",
    "            S_tot = float(np.sum(S_counts))\n",
    "            B_tot = float(np.sum(B_counts))\n",
    "            if B_tot > 0:\n",
    "                tot_SsqrtB = S_tot / np.sqrt(B_tot)\n",
    "                tot_SsqrtSB = S_tot / np.sqrt(S_tot + B_tot) if (S_tot + B_tot) > 0 else 0\n",
    "                tot_SsqrtS1p3B = S_tot / np.sqrt(S_tot + 1.3*B_tot) if (S_tot + 1.3*B_tot) > 0 else 0\n",
    "                tot_zbi = zbi(S_tot, B_tot, sigma_b_frac=0.3)\n",
    "            else:\n",
    "                tot_SsqrtB = tot_SsqrtSB = tot_SsqrtS1p3B = tot_zbi = 0.0\n",
    "    \n",
    "            ax_bot.step(bin_centers, sig_simple, where='mid', linewidth=2,\n",
    "                        label=f\"S/√B = {tot_SsqrtB:.4f}\", color='chocolate')\n",
    "            ax_bot.step(bin_centers, sig_s_plus_b, where='mid', linewidth=2,\n",
    "                        label=f\"S/√(S+B) = {tot_SsqrtSB:.4f}\", color='tomato')\n",
    "            ax_bot.step(bin_centers, sig_s_plus_1p3b, where='mid', linewidth=2,\n",
    "                        label=f\"S/√(S+1.3B) = {tot_SsqrtS1p3B:.4f}\", color='orange')\n",
    "            ax_bot.step(bin_centers, zbi_per_bin, where='mid', linewidth=2,\n",
    "                        label=f\"Binomial ExpZ = {tot_zbi:.4f}\", color='plum')\n",
    "    \n",
    "            ax_bot.set_xlabel(var_cfg_sig[var]['title'])\n",
    "            ax_bot.set_ylabel(\"Significance\")\n",
    "            ax_bot.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "            ax_bot.set_title(\"\")\n",
    "            leg = ax_bot.legend()\n",
    "            for t in leg.get_texts():\n",
    "                t.set_color('purple')\n",
    "    \n",
    "            plt.xlim(bins[0], bins[-1])\n",
    "            plt.tight_layout()\n",
    "    \n",
    "            dist_dir = f\"{out_base}\"\n",
    "            ensure_dir(dist_dir)\n",
    "            out_png = f\"{dist_dir}/{var}.png\"\n",
    "            plt.savefig(out_png)\n",
    "            print(f\"Saved: {out_png}\")\n",
    "            plt.close()\n",
    "    \n",
    "            # ROC using this single variable as score\n",
    "            y_true = np.concatenate([np.ones_like(S_counts).repeat(1)])  # placeholder to silence lints\n",
    "            # Build event-wise arrays, not binned:\n",
    "            y_true = np.concatenate([np.ones(sig_all.shape[0], dtype=int), np.zeros(bg_all.shape[0], dtype=int)])\n",
    "            y_scores = np.concatenate([sig_all, bg_all])\n",
    "            y_w = np.concatenate([sig_w_all if sig_w_all.size else np.ones(sig_all.shape[0]),\n",
    "                                  bg_w_all if bg_w_all.size else np.ones(bg_all.shape[0])])\n",
    "    \n",
    "            if y_scores.size and np.unique(y_true).size == 2:\n",
    "                fpr, tpr, thr = roc_curve(y_true, y_scores, sample_weight=y_w)\n",
    "                order = np.argsort(fpr)\n",
    "                roc_auc = auc(fpr[order], tpr[order])\n",
    "    \n",
    "                plt.figure(figsize=(8, 8))\n",
    "                plt.plot(fpr, tpr, lw=2, label=f'ROC (AUC = {roc_auc:.5f})')\n",
    "                plt.plot([0, 1], [0, 1], linestyle='--', label='Random')\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.title(f\"N-1 ROC — {var}\")\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "                plt.tight_layout()\n",
    "                out_png = f\"{dist_dir}/roc_curve_{var}.png\"\n",
    "                plt.savefig(out_png)\n",
    "                print(f\"Saved: {out_png}\")\n",
    "                plt.close()\n",
    "\n",
    "\n",
    "plot_n_1(tot, ntuple_names, sample_dict, getVarDict, zbi, getCutDict, sel, mt_val_dir, n_1_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e7aea22-56fd-4cae-8160-6c82a02d295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
