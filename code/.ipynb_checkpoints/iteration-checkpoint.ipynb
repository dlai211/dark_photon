{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd91d671-f884-4af4-88f1-975e1e3caeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mc23d_ggHyyd_y Unweighted Events before cut:  17999\n",
      "mc23d_ggHyyd_y Weighted Events before cut:  344.07425718325356\n",
      "mc23d_ggHyyd_y Unweighted Events after basic:  2998\n",
      "mc23d_ggHyyd_y Weighted Events after basic:  58.68194395390023\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_ggHyyd_y: 0.7066249847412109 seconds\n",
      "\n",
      "mc23d_Zgamma_y Unweighted Events before cut:  2520609\n",
      "mc23d_Zgamma_y Weighted Events before cut:  15697.116266766878\n",
      "mc23d_Zgamma_y Unweighted Events after basic:  21427\n",
      "mc23d_Zgamma_y Weighted Events after basic:  222.79132641446043\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_Zgamma_y: 13.801150798797607 seconds\n",
      "\n",
      "mc23d_Wgamma_y Unweighted Events before cut:  685525\n",
      "mc23d_Wgamma_y Weighted Events before cut:  16946.649253377054\n",
      "mc23d_Wgamma_y Unweighted Events after basic:  15128\n",
      "mc23d_Wgamma_y Weighted Events after basic:  451.9858106707009\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_Wgamma_y: 4.252361297607422 seconds\n",
      "\n",
      "mc23d_gammajet_direct_y Unweighted Events before cut:  1872548\n",
      "mc23d_gammajet_direct_y Weighted Events before cut:  1103184.1585944626\n",
      "mc23d_gammajet_direct_y Unweighted Events after basic:  30883\n",
      "mc23d_gammajet_direct_y Weighted Events after basic:  2060.507937749587\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_gammajet_direct_y: 9.501137495040894 seconds\n",
      "\n",
      "data23_y Unweighted Events before cut:  1489084\n",
      "data23_y Weighted Events before cut:  3042472.9429998905\n",
      "data23_y Unweighted Events after basic:  2824\n",
      "data23_y Weighted Events after basic:  5835.371999999891\n",
      "Number of none values:  0\n",
      "Reading Time for data23_y: 14.137000322341919 seconds\n",
      "\n",
      "data23_eprobe Unweighted Events before cut:  991882\n",
      "data23_eprobe Weighted Events before cut:  35278.89142854558\n",
      "data23_eprobe Unweighted Events after basic:  27879\n",
      "data23_eprobe Weighted Events after basic:  1294.2005848399797\n",
      "Number of none values:  0\n",
      "Reading Time for data23_eprobe: 5.874635457992554 seconds\n",
      "\n",
      "mc23e_ggHyyd_y Unweighted Events before cut:  76211\n",
      "mc23e_ggHyyd_y Weighted Events before cut:  1587.993363345974\n",
      "mc23e_ggHyyd_y Unweighted Events after basic:  12613\n",
      "mc23e_ggHyyd_y Weighted Events after basic:  252.17708559353693\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_ggHyyd_y: 1.15415620803833 seconds\n",
      "\n",
      "mc23e_Zgamma_y Unweighted Events before cut:  8622736\n",
      "mc23e_Zgamma_y Weighted Events before cut:  66651.54542882358\n",
      "mc23e_Zgamma_y Unweighted Events after basic:  76955\n",
      "mc23e_Zgamma_y Weighted Events after basic:  957.849836921867\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_Zgamma_y: 40.635868310928345 seconds\n",
      "\n",
      "mc23e_Wgamma_y Unweighted Events before cut:  2162708\n",
      "mc23e_Wgamma_y Weighted Events before cut:  74823.05389455653\n",
      "mc23e_Wgamma_y Unweighted Events after basic:  49000\n",
      "mc23e_Wgamma_y Weighted Events after basic:  1918.2413800342615\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_Wgamma_y: 11.733876943588257 seconds\n",
      "\n",
      "mc23e_gammajet_direct_y Unweighted Events before cut:  2268382\n",
      "mc23e_gammajet_direct_y Weighted Events before cut:  6522209.851531688\n",
      "mc23e_gammajet_direct_y Unweighted Events after basic:  29919\n",
      "mc23e_gammajet_direct_y Weighted Events after basic:  10768.56890198974\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_gammajet_direct_y: 10.71936845779419 seconds\n",
      "\n",
      "data24_y Unweighted Events before cut:  7913491\n",
      "data24_y Weighted Events before cut:  13781338.51483133\n",
      "data24_y Unweighted Events after basic:  16048\n",
      "data24_y Weighted Events after basic:  27739.48899999795\n",
      "Number of none values:  0\n",
      "Reading Time for data24_y: 70.15277767181396 seconds\n",
      "\n",
      "data24_eprobe Unweighted Events before cut:  4452447\n",
      "data24_eprobe Weighted Events before cut:  168317.91138638573\n",
      "data24_eprobe Unweighted Events after basic:  120899\n",
      "data24_eprobe Weighted Events after basic:  5993.8657010394045\n",
      "Number of none values:  0\n",
      "Reading Time for data24_eprobe: 23.91270899772644 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math, pickle, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "from pathlib import Path\n",
    "\n",
    "# import config functions\n",
    "sys.path.append('/home/jlai/dark_photon/code/config')\n",
    "from plot_config import getWeight, zbi, sample_dict, getVarDict\n",
    "from plot_var import variables, variables_mc, ntuple_names\n",
    "from n_1_iteration_functions import get_best_cut, calculate_significance, apply_cut_to_fb, apply_all_cuts, compute_total_significance, n_minus_1_optimizer\n",
    "from perf_sig_plot import plot_performance, plot_significance, plot_n_1, calculate_significance2\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high  \n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14,\n",
    "    \"title\": 20\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"],  # Legend\n",
    "    \"axes.titlesize\": font_size[\"title\"] # Title\n",
    "})\n",
    "\n",
    "\n",
    "tot = []\n",
    "signal_name = 'ggHyyd'\n",
    "data = pd.DataFrame()\n",
    "\n",
    "def test(fb):\n",
    "    # checking if there are any none values\n",
    "    mask = ak.is_none(fb['met_tst_et'])\n",
    "    n_none = ak.sum(mask)\n",
    "    print(\"Number of none values: \", n_none)\n",
    "    # if n_none > 0:\n",
    "    #     fb = fb[~mask]\n",
    "    # print(\"Events after removing none values: \", len(fb), ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "\n",
    "def print_cut(ntuple_name, fb, label):\n",
    "    print(f\"{ntuple_name} Unweighted Events {label}: \", len(fb))\n",
    "    print(f\"{ntuple_name} Weighted Events {label}: \", sum(getWeight(fb, ntuple_name)))\n",
    "        \n",
    "for i in range(len(ntuple_names)):\n",
    "    start_time = time.time()\n",
    "    ntuple_name = ntuple_names[i]\n",
    "    path = f\"/data/fpiazza/ggHyyd/NtuplesWithBDTSkim/{ntuple_name}_nominal_bdt.root\"\n",
    "    f = uproot.open(path)['nominal']\n",
    "    if ntuple_name.startswith(\"mc\"):\n",
    "        fb = f.arrays(variables_mc, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "        \n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "        fb = fb[fb['n_ph'] == 1]\n",
    "        fb = fb[fb['n_el_baseline'] == 0]\n",
    "\n",
    "        # goodPV on signal only\n",
    "        if ntuple_name == 'ggHyyd':\n",
    "            fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "            good_pv_tmp = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "            fb = fb[good_pv_tmp]\n",
    "            \n",
    "        \n",
    "    if (ntuple_name == \"data23_y\") or (ntuple_name == \"data24_y\"):  # jet-faking \n",
    "        fb = f.arrays(variables, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]\n",
    "        mask1 = (ak.firsts(fb['ph_topoetcone40'])-2450.)/ak.firsts(fb['ph_pt']) > 0.1   # jet_faking_photon cut\n",
    "        fb = fb[mask1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 1]\n",
    "        fb = fb[fb['n_el_baseline'] == 0]\n",
    "\n",
    "\n",
    "    if (ntuple_name == \"data23_eprobe\") or (ntuple_name == \"data24_eprobe\"): # electron-faking\n",
    "        fb = f.arrays(variables, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "        \n",
    "        fb = fb[fb['n_el'] == 1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 0]\n",
    "\n",
    "        # using electron info for photon info\n",
    "        fb['ph_pt'] = fb['el_pt']\n",
    "        fb['ph_eta'] = fb['el_eta']\n",
    "        fb['ph_phi'] = fb['el_phi']\n",
    "        fb['dphi_met_phterm'] = fb['dphi_met_eleterm']  \n",
    "\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0] # prevent none values in Tbranch\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) >= 50000] # ph_pt cut (basic cut)\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M']==1]\n",
    "    fb = fb[fb['met_tst_et'] >= 100000] # MET cut (basic cut)\n",
    "    fb = fb[fb['n_jet_central'] <= 3] # n_jet_central cut (basic cut)\n",
    "    \n",
    "    fb['VertexBDTScore'] = fb['BDTScore'] # renaming BDTScore to ensure this is recognized as Vertex BDT Score\n",
    "    # fb = fb[fb['VertexBDTScore'] > 0.1]\n",
    "    \n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "                    (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    mask1 = mt_tmp > 100\n",
    "    mask2 = mt_tmp < 140\n",
    "    fb = fb[mask1 * mask2]\n",
    "\n",
    "    # ------ Adjustment --------\n",
    "    fb['weights'] = getWeight(fb, ntuple_name)\n",
    "    \n",
    "    dphi_met_jetterm_tmp = fb['dphi_met_jetterm']\n",
    "    cond = ak.fill_none(dphi_met_jetterm_tmp == -10, False)\n",
    "    fb['dphi_met_jetterm'] = ak.where(cond, -999, dphi_met_jetterm_tmp)\n",
    "\n",
    "    fb['dphi_met_phterm'] = np.arccos(np.cos(fb['dphi_met_phterm']))\n",
    "\n",
    "    print_cut(ntuple_name, fb, 'after basic')\n",
    "\n",
    "    test(fb) # check for none value\n",
    "\n",
    "    print(f\"Reading Time for {ntuple_name}: {(time.time()-start_time)} seconds\\n\")\n",
    "\n",
    "    tot.append(fb)\n",
    "\n",
    "    del fb \n",
    "\n",
    "# combining 23d + 23e {Zgamma (1, 6), Wgamma (2, 7), gammajet_direct (3, 8)}\n",
    "# combining 2023 + 2024 {data_y (4, 9), data_eprobe (5, 10)}\n",
    "tot_tmp = tot\n",
    "tot = []\n",
    "for i in tqdm(range(6)):\n",
    "    tot.append(ak.concatenate([tot_tmp[i], tot_tmp[i+6]]))\n",
    "ntuple_names = [\"ggHyyd\", \"Zgamma\", \"Wgamma\", \"gammajet_direct\", \"data_y\", \"data_eprobe\"]\n",
    "del tot_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06348be4-eee2-48c8-84ea-dbac12362388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance:  1.2992851747801484\n"
     ]
    }
   ],
   "source": [
    "def compute_total_significance(tot2, ntuple_names, signal_name, getVarDict):\n",
    "    signal_sum = 0\n",
    "    bkg_sum = 0\n",
    "    for i in range(len(ntuple_names)):\n",
    "        fb = tot2[i]\n",
    "        process = ntuple_names[i]\n",
    "        weights = fb['weights']\n",
    "        if process == signal_name:\n",
    "            signal_sum += ak.sum(weights)\n",
    "        else:\n",
    "            bkg_sum += ak.sum(weights)\n",
    "    return signal_sum / np.sqrt(bkg_sum) if bkg_sum > 0 else 0\n",
    "\n",
    "sig_tmp = compute_total_significance(tot, ntuple_names, signal_name, getVarDict)\n",
    "print(\"significance: \", sig_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c921cc33-64a7-48a2-93b3-94c021c50513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VertexBDTScore > 0.1\n",
      "metsig > 7\n",
      "ph_eta < 1.75\n",
      "dphi_met_phterm > 1.25\n",
      "dmet > -25000\n",
      "dphi_jj < 2.5\n",
      "dphi_met_jetterm < 0.75\n",
      "balance > 0.9\n",
      "significance:  2.700617529475418\n"
     ]
    }
   ],
   "source": [
    "cuts1 = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -25000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "    {'cut_var': 'balance', 'cut_type': 'lowercut', 'best_cut': 0.9},\n",
    "]\n",
    "\n",
    "tot2 = apply_all_cuts(tot, ntuple_names, cuts1, getVarDict)\n",
    "sig_tmp = compute_total_significance(tot2, ntuple_names, signal_name, getVarDict)\n",
    "\n",
    "\n",
    "for cut in cuts1:\n",
    "    var = cut['cut_var']\n",
    "    val = cut['best_cut']\n",
    "    if cut['cut_type'] == 'uppercut':\n",
    "        print(f\"{var} < {val}\")\n",
    "    elif cut['cut_type'] == 'lowercut':\n",
    "        print(f\"{var} > {val}\")\n",
    "        \n",
    "# print('after optimized cutting, signficance: ', final_significance)\n",
    "\n",
    "\n",
    "print(\"significance: \", sig_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74c03e9d-e0cb-433d-b90e-329e02d887af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef getCutDict():\\n    cut_dict = {}\\n    # Selection 1: same variables as in the internal note\\n    cut_dict['dmet'] = {\\n        'lowercut': np.arange(-30000, 10000 + 100, 100), # dmet > cut\\n        'uppercut': np.arange(10000, 100000 + 100, 100), # -10000 < dmet < cut\\n    }\\n    cut_dict['metsig'] = {\\n        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\\n        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \\n    }\\n    cut_dict['dphi_met_phterm'] = {\\n        'lowercut': np.arange(1, 2 + 0.01, 0.01), # dphi_met_phterm > cut\\n    }\\n    cut_dict['dphi_met_jetterm'] = {\\n        'uppercut': np.arange(0.5, 1, 0.01), # dphi_met_jetterm < cut\\n    }\\n    cut_dict['ph_eta'] = {\\n        'uppercut': np.arange(1, 2.5 + 0.01, 0.01), # ph_eta < cut\\n    }\\n    cut_dict['dphi_jj'] = {\\n        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\\n    }\\n\\n    # Selection 2\\n    cut_dict['balance'] = {\\n        'lowercut': np.arange(0.3, 1.5 + 0.05, 0.05), # balance > cut\\n    }\\n    cut_dict['jetterm'] = {\\n        'lowercut': np.arange(0, 150000+10000, 10000) # jetterm > cut\\n    }\\n    cut_dict['dphi_phterm_jetterm'] = {\\n        'lowercut': np.arange(1, 2.5 + 0.1, 0.1), # dphi_phterm_jetterm > cut\\n        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\\n    }\\n    cut_dict['metsigres'] = {\\n        'uppercut': np.arange(12000, 60000, 10000)\\n    }\\n    cut_dict['met_noJVT'] = {\\n        'lowercut': np.arange(50000, 120000, 10000),\\n    }\\n    \\n    return cut_dict\\ncut_config = getCutDict()\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getCutDict(): # same cut as the internal note\n",
    "    cut_dict = {}\n",
    "    \n",
    "    cut_dict['VertexBDTScore'] = {\n",
    "        'lowercut': np.arange(0.1, 0.36, 0.02),  # VertexBDTScore > cut\n",
    "    }\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 10000 + 5000, 5000), # dmet > cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(0, 2 + 0.05, 0.05), # dphi_met_phterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'uppercut': np.arange(0.5, 1, 0.05), # dphi_met_jetterm < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.05, 0.05), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.1 + 0.05, 0.05) # dphi_jj < cut\n",
    "    }\n",
    "    cut_dict['balance'] = {\n",
    "        'lowercut': np.arange(0.3, 1.5 + 0.05, 0.05), # balance > cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.1, 0.1), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['metsigres'] = {\n",
    "        'uppercut': np.arange(12000, 60000, 10000)\n",
    "    }\n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "\n",
    "'''\n",
    "def getCutDict():\n",
    "    cut_dict = {}\n",
    "    # Selection 1: same variables as in the internal note\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 10000 + 100, 100), # dmet > cut\n",
    "        'uppercut': np.arange(10000, 100000 + 100, 100), # -10000 < dmet < cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(1, 2 + 0.01, 0.01), # dphi_met_phterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'uppercut': np.arange(0.5, 1, 0.01), # dphi_met_jetterm < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.01, 0.01), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\n",
    "    }\n",
    "\n",
    "    # Selection 2\n",
    "    cut_dict['balance'] = {\n",
    "        'lowercut': np.arange(0.3, 1.5 + 0.05, 0.05), # balance > cut\n",
    "    }\n",
    "    cut_dict['jetterm'] = {\n",
    "        'lowercut': np.arange(0, 150000+10000, 10000) # jetterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.1, 0.1), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['metsigres'] = {\n",
    "        'uppercut': np.arange(12000, 60000, 10000)\n",
    "    }\n",
    "    cut_dict['met_noJVT'] = {\n",
    "        'lowercut': np.arange(50000, 120000, 10000),\n",
    "    }\n",
    "    \n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "701aeca3-838d-4d2b-b707-8dde8b8c0f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VertexBDTScore 0 13\n",
      "{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -20000, 'best_sig_x_acc': 1.3660758623414198, 'significance': 1.4004223790364942, 'acceptance': 97.54741732142946}\n",
      "{'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6, 'best_sig_x_acc': 1.8937439405556582, 'significance': 2.1362939949505284, 'acceptance': 88.64622308688898}\n",
      "{'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 0.9500000000000001, 'best_sig_x_acc': 1.353579433779524, 'significance': 1.3855551246034605, 'acceptance': 97.69221085064459}\n",
      "{'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.9000000000000004, 'best_sig_x_acc': 1.2994321813474494, 'significance': 1.2995663554624315, 'acceptance': 99.98967547025066}\n",
      "{'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 2.4000000000000012, 'best_sig_x_acc': 1.2992829196142757, 'significance': 1.2992851747801484, 'acceptance': 99.99982643026208}\n",
      "dphi_jj 42 43\n",
      "{'cut_var': 'balance', 'cut_type': 'lowercut', 'best_cut': 0.44999999999999996, 'best_sig_x_acc': 1.3091143718351097, 'significance': 1.3129214078818625, 'acceptance': 99.71003321113527}\n",
      "dphi_phterm_jetterm 0 16\n",
      "dphi_phterm_jetterm 0 21\n",
      "{'cut_var': 'metsigres', 'cut_type': 'uppercut', 'best_cut': 22000, 'best_sig_x_acc': 1.6426319664690916, 'significance': 1.8989208059975118, 'acceptance': 86.50344770993279}\n"
     ]
    }
   ],
   "source": [
    "signal_name='ggHyyd'\n",
    "initial_cut = []\n",
    "tot2 = tot  # return the initial cut\n",
    "\n",
    "# < -- Initial Cut on all variables (maximize the significance * acceptance) -- > \n",
    "for cut_var, cut_types in cut_config.items():\n",
    "    for cut_type, cut_values in cut_types.items():\n",
    "        sig_simple_list, sigacc_simple_list, acceptance_values = calculate_significance(\n",
    "            tot, ntuple_names, getVarDict, cut_var, cut_type, cut_values\n",
    "        )\n",
    "\n",
    "        best_cut, best_sig, idx = get_best_cut(cut_values, sigacc_simple_list) \n",
    "        \n",
    "        if idx == 0 or idx == len(sigacc_simple_list) - 1: # I chose to use index to indicate not to make unnecessary cut (for initial cut)\n",
    "            print(cut_var, idx, len(sigacc_simple_list))\n",
    "            continue\n",
    "            \n",
    "        result = {\n",
    "            \"cut_var\": cut_var,\n",
    "            \"cut_type\": cut_type,\n",
    "            \"best_cut\": best_cut,\n",
    "            \"best_sig_x_acc\": best_sig,\n",
    "            \"significance\": sig_simple_list[idx],\n",
    "            \"acceptance\": acceptance_values[idx]\n",
    "        }\n",
    "\n",
    "        print(result)\n",
    "        initial_cut.append(dict(list(result.items())[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0404ca53-3876-45a0-8777-c1bef78ef180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -20000},\n",
       " {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6},\n",
       " {'cut_var': 'dphi_met_phterm',\n",
       "  'cut_type': 'lowercut',\n",
       "  'best_cut': 0.9500000000000001},\n",
       " {'cut_var': 'dphi_met_jetterm',\n",
       "  'cut_type': 'uppercut',\n",
       "  'best_cut': 0.9000000000000004},\n",
       " {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 2.4000000000000012},\n",
       " {'cut_var': 'balance',\n",
       "  'cut_type': 'lowercut',\n",
       "  'best_cut': 0.44999999999999996},\n",
       " {'cut_var': 'metsigres', 'cut_type': 'uppercut', 'best_cut': 22000},\n",
       " {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_cut.append({'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1})\n",
    "initial_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "041412a8-21fa-4aad-bb9d-7aeaa8187eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance after initial cuts:  1.2992851747801484\n"
     ]
    }
   ],
   "source": [
    "tmp = apply_all_cuts(tot, ntuple_names, initial_cut, getVarDict)\n",
    "final_significance = compute_total_significance(tot, ntuple_names, signal_name, getVarDict)\n",
    "print(\"Significance after initial cuts: \", final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7d15f70-27f9-4ad7-82ee-4cb9c93f0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "## my cut\n",
    "# initial_cuts = [\n",
    "#     {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "#     {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6},\n",
    "#     {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "#     {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "#     {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -10000},\n",
    "#     {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "#     {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "435c829b-a8dd-45eb-a394-b3fb350ebacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "Updating metsig (lowercut): 6 → 8  (N-1 2.167 → with-cut 2.334)\n",
      "Updating dphi_met_phterm (lowercut): 0.9500000000000001 → 1.1  (N-1 2.282 → with-cut 2.340)\n",
      "Updating dphi_met_jetterm (uppercut): 0.9000000000000004 → 0.8500000000000003  (N-1 2.339 → with-cut 2.340)\n",
      "Updating ph_eta (uppercut): 2.4000000000000012 → 1.7500000000000007  (N-1 2.340 → with-cut 2.465)\n",
      "Updating balance (lowercut): 0.44999999999999996 → 0.8999999999999999  (N-1 2.445 → with-cut 2.573)\n",
      "Updating metsigres (uppercut): 22000 → 42000  (N-1 2.648 → with-cut 2.648)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Updating dmet (lowercut): -20000 → -25000  (N-1 2.609 → with-cut 2.651)\n",
      "Updating metsig (lowercut): 8.0 → 7  (N-1 2.126 → with-cut 2.712)\n",
      "Updating dphi_met_phterm (lowercut): 1.1 → 1.2000000000000002  (N-1 2.629 → with-cut 2.717)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "optimized cuts, end of iteration\n",
      "after optimized cutting, signficance:  2.717088574547915\n",
      "CPU times: user 1min 31s, sys: 20.6 ms, total: 1min 31s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# < -- n-1 iterations until no further improvement (max significance) -- >\n",
    "optimized_cuts, final_significance = n_minus_1_optimizer(\n",
    "    initial_cut, cut_config, tot, ntuple_names, signal_name, getVarDict, final_significance, allow_drop=False\n",
    ")\n",
    "print('after optimized cutting, signficance: ', final_significance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "046f0a65-fada-4152-9fdb-b68f5222ede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " < -- Final Optimized Cuts -- > \n",
      "dmet > -25000.0\n",
      "metsig > 7.0\n",
      "dphi_met_phterm > 1.2000000000000002\n",
      "dphi_met_jetterm < 0.8500000000000003\n",
      "ph_eta < 1.7500000000000007\n",
      "balance > 0.8999999999999999\n",
      "metsigres < 42000.0\n",
      "VertexBDTScore > 0.1\n",
      "after optimized cutting, signficance:  2.717088574547915\n"
     ]
    }
   ],
   "source": [
    "print( ' < -- Final Optimized Cuts -- > ')\n",
    "# print(optimized_cuts)\n",
    "\n",
    "for cut in optimized_cuts:\n",
    "    var = cut['cut_var']\n",
    "    val = cut['best_cut']\n",
    "    if cut['cut_type'] == 'uppercut':\n",
    "        print(f\"{var} < {val}\")\n",
    "    elif cut['cut_type'] == 'lowercut':\n",
    "        print(f\"{var} > {val}\")\n",
    "        \n",
    "print('after optimized cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "668e0643-4883-4371-9644-8af1d849e2f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apply_all_cuts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m cuts2 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcut_var\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVertexBDTScore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcut_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercut\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_cut\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.1\u001b[39m},\n\u001b[1;32m      3\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcut_var\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetsig\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcut_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercut\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_cut\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m7\u001b[39m},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \n\u001b[1;32m     11\u001b[0m ]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print('< -- Sum of weight each process -- >')\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mapply_all_cuts\u001b[49m(tot, ntuple_names, cuts2, getVarDict)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# for i in range(len(tot)):\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     print(ntuple_names[i], ak.sum(tmp[i]['weights']))\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(f'significance : {compute_total_significance(tmp, ntuple_names, signal_name, getVarDict)}')\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m < -- Final Optimized Cuts -- > \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'apply_all_cuts' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "cuts2 = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -25000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "    {'cut_var': 'balance', 'cut_type': 'lowercut', 'best_cut': 0.9},\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# print('< -- Sum of weight each process -- >')\n",
    "tmp = apply_all_cuts(tot, ntuple_names, cuts2, getVarDict)\n",
    "# for i in range(len(tot)):\n",
    "#     print(ntuple_names[i], ak.sum(tmp[i]['weights']))\n",
    "# print(f'significance : {compute_total_significance(tmp, ntuple_names, signal_name, getVarDict)}')\n",
    "\n",
    "print( ' < -- Final Optimized Cuts -- > ')\n",
    "# print(optimized_cuts)\n",
    "\n",
    "for cut in cuts2:\n",
    "    var = cut['cut_var']\n",
    "    val = cut['best_cut']\n",
    "    if cut['cut_type'] == 'uppercut':\n",
    "        print(f\"{var} < {val}\")\n",
    "    elif cut['cut_type'] == 'lowercut':\n",
    "        print(f\"{var} > {val}\")\n",
    "\n",
    "print(f'significance : {compute_total_significance(tmp, ntuple_names, signal_name, getVarDict)}')\n",
    "\n",
    "# print('after optimized cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28d576eb-eb6f-473c-8214-977c6c58c46a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FieldNotFoundError",
     "evalue": "no field 'jet_central_vecSumPt' in record with 46 fields\n\nThis error occurred while attempting to slice\n\n    <Array [{run: 602402, event: ..., ...}, ...] type='8684 * ?{run: int32,...'>\n\nwith\n\n    'jet_central_vecSumPt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFieldNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/awkward/highlevel.py:1103\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, where)\u001b[0m\n\u001b[1;32m   1101\u001b[0m NamedAxis\u001b[38;5;241m.\u001b[39mmapping \u001b[38;5;241m=\u001b[39m named_axis\n\u001b[0;32m-> 1103\u001b[0m indexed_layout \u001b[38;5;241m=\u001b[39m prepare_layout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_layout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNamedAxis\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m NamedAxis\u001b[38;5;241m.\u001b[39mmapping:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/awkward/contents/content.py:545\u001b[0m, in \u001b[0;36mContent._getitem\u001b[0;34m(self, where, named_axis)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(where, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnewaxis:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/awkward/contents/indexedoptionarray.py:337\u001b[0m, in \u001b[0;36mIndexedOptionArray._getitem_field\u001b[0;34m(self, where, only_fields)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_getitem_field\u001b[39m(\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m, where: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m SupportsIndex, only_fields: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m    334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Content:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IndexedOptionArray\u001b[38;5;241m.\u001b[39msimplified(\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index,\n\u001b[0;32m--> 337\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_content\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_fields\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    338\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    339\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/awkward/contents/recordarray.py:458\u001b[0m, in \u001b[0;36mRecordArray._getitem_field\u001b[0;34m(self, where, only_fields)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(only_fields) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/awkward/contents/recordarray.py:394\u001b[0m, in \u001b[0;36mRecordArray.content\u001b[0;34m(self, index_or_field)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontent\u001b[39m(\u001b[38;5;28mself\u001b[39m, index_or_field: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m SupportsIndex) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Content:\n\u001b[0;32m--> 394\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    396\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length \u001b[38;5;129;01mis\u001b[39;00m unknown_length\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m unknown_length\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length\n\u001b[1;32m    399\u001b[0m     ):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/awkward/_meta/recordmeta.py:136\u001b[0m, in \u001b[0;36mRecordMeta.content\u001b[0;34m(self, index_or_field)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index_or_field, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 136\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfield_to_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/awkward/_meta/recordmeta.py:117\u001b[0m, in \u001b[0;36mRecordMeta.field_to_index\u001b[0;34m(self, field)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m i\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m FieldNotFoundError(\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno field \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m in record with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fields\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m )\n",
      "\u001b[0;31mFieldNotFoundError\u001b[0m: no field 'jet_central_vecSumPt' in record with 46 fields",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFieldNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 138\u001b[0m\n\u001b[1;32m    135\u001b[0m tot2_initial_cut \u001b[38;5;241m=\u001b[39m apply_all_cuts(tot, ntuple_names, initial_cuts, getVarDict)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# --- RUN IT ---\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m sig_table \u001b[38;5;241m=\u001b[39m \u001b[43msignificance_by_single_cuts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtot2_initial_cut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntuple_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mggHyyd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_b_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_zbi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 101\u001b[0m, in \u001b[0;36msignificance_by_single_cuts\u001b[0;34m(tot, ntuple_names, signal_name, sigma_b_frac, include_zbi)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, fb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tot):\n\u001b[1;32m    100\u001b[0m     name \u001b[38;5;241m=\u001b[39m ntuple_names[i]\n\u001b[0;32m--> 101\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43mcut_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfb\u001b[49m\u001b[43m)\u001b[49m                      \u001b[38;5;66;03m# boolean mask (Awkward-friendly)\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     w \u001b[38;5;241m=\u001b[39m weights[i][m]                   \u001b[38;5;66;03m# apply mask to precomputed event weights\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     wsum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(ak\u001b[38;5;241m.\u001b[39msum(w))\n",
      "Cell \u001b[0;32mIn[24], line 28\u001b[0m, in \u001b[0;36mcut_balance_gt_0p91\u001b[0;34m(fb)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcut_balance_gt_0p91\u001b[39m(fb):\n\u001b[0;32m---> 28\u001b[0m     sumet_tmp \u001b[38;5;241m=\u001b[39m \u001b[43mfb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjet_central_vecSumPt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     29\u001b[0m     expr \u001b[38;5;241m=\u001b[39m (fb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmet_tst_et\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m ak\u001b[38;5;241m.\u001b[39mfirsts(fb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mph_pt\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;241m/\u001b[39m ak\u001b[38;5;241m.\u001b[39mwhere(sumet_tmp \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m, sumet_tmp, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m     balance \u001b[38;5;241m=\u001b[39m ak\u001b[38;5;241m.\u001b[39mwhere(sumet_tmp \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m, expr, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m999\u001b[39m) \n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/awkward/highlevel.py:1114\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, where)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ak\u001b[38;5;241m.\u001b[39moperations\u001b[38;5;241m.\u001b[39mak_with_named_axis\u001b[38;5;241m.\u001b[39m_impl(\n\u001b[1;32m   1107\u001b[0m         indexed_layout,\n\u001b[1;32m   1108\u001b[0m         named_axis\u001b[38;5;241m=\u001b[39mNamedAxis\u001b[38;5;241m.\u001b[39mmapping,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs,\n\u001b[1;32m   1112\u001b[0m     )\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap_layout(\n\u001b[1;32m   1115\u001b[0m         indexed_layout,\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_behavior,\n\u001b[1;32m   1117\u001b[0m         allow_other\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1118\u001b[0m         attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs,\n\u001b[1;32m   1119\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/awkward/_errors.py:85\u001b[0m, in \u001b[0;36mErrorContext.__exit__\u001b[0;34m(self, exception_type, exception_value, traceback)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# Handle caught exception\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     81\u001b[0m         exception_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(exception_type, \u001b[38;5;167;01mException\u001b[39;00m)\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprimary() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m     84\u001b[0m     ):\n\u001b[0;32m---> 85\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexception_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Step out of the way so that another ErrorContext can become primary.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprimary() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/awkward/_errors.py:95\u001b[0m, in \u001b[0;36mErrorContext.handle_exception\u001b[0;34m(self, cls, exception)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecorate_exception(\u001b[38;5;28mcls\u001b[39m, exception)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecorate_exception(\u001b[38;5;28mcls\u001b[39m, exception)\n",
      "\u001b[0;31mFieldNotFoundError\u001b[0m: no field 'jet_central_vecSumPt' in record with 46 fields\n\nThis error occurred while attempting to slice\n\n    <Array [{run: 602402, event: ..., ...}, ...] type='8684 * ?{run: int32,...'>\n\nwith\n\n    'jet_central_vecSumPt'"
     ]
    }
   ],
   "source": [
    "signal_name = 'ggHyyd'\n",
    "\n",
    "# --- helpers ---\n",
    "def weight_sum(fb, ntuple_name):\n",
    "    return ak.sum(fb['weights'])\n",
    "\n",
    "def s_over_sqrt_b(S, B):\n",
    "    return S/np.sqrt(B) if B > 0 else 0.0\n",
    "\n",
    "def zbi(S, B, sigma_b_frac=0.30):\n",
    "    # Binomial significance with background uncertainty\n",
    "    if B <= 0:\n",
    "        return 0.0\n",
    "    tau   = 1.0 / (B * sigma_b_frac * sigma_b_frac)\n",
    "    n_on  = S + B\n",
    "    n_off = B * tau\n",
    "    P_Bi  = betainc(n_on, n_off + 1, 1.0 / (1.0 + tau))\n",
    "    if P_Bi <= 0:\n",
    "        return 0.0\n",
    "    return float(norm.ppf(1.0 - P_Bi))\n",
    "\n",
    "# Minimal, branchless Δφ in [0, π]\n",
    "def dphi(a, b):\n",
    "    return np.abs((a - b + np.pi) % (2*np.pi) - np.pi)\n",
    "\n",
    "# --- define the \"further selection\" cuts as functions that return a boolean mask ---\n",
    "def cut_balance_gt_0p91(fb):\n",
    "    sumet_tmp = fb['jet_central_vecSumPt']\n",
    "    expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(sumet_tmp != 0, sumet_tmp, 1)\n",
    "    balance = ak.where(sumet_tmp != 0, expr, -999) \n",
    "    return (balance == -999) | (balance > 1)\n",
    "\n",
    "def cut_met_jetterm_et_gt_92GeV(fb):\n",
    "    return fb['met_jetterm_et'] > 80_000\n",
    "\n",
    "def cut_dphi_phterm_jetterm_window(fb, low=1.6, high=3.1):\n",
    "    # angle defined only if met_jetterm_et>0; missing → pass\n",
    "    cond  = fb['met_jetterm_et'] > 0\n",
    "    angle = ak.where(cond, dphi(fb['met_phterm_phi'], fb['met_jetterm_phi']), 0.0)\n",
    "    return (~cond) | ((angle > low) & (angle < high))\n",
    "\n",
    "def cut_metsigres_lt_36GeV(fb):\n",
    "    # metsigres = MET / METsig  (in MeV; 36 GeV = 36000 MeV)\n",
    "    # Guard against nonpositive sig; if sig<=0, we conservatively fail the cut.\n",
    "    sig_ok = fb['met_tst_sig'] > 0\n",
    "    ratio  = ak.where(sig_ok, fb['met_tst_et'] / fb['met_tst_sig'], np.inf)\n",
    "    return ratio < 42_000\n",
    "\n",
    "def cut_met_noJVT_gt_90GeV(fb):\n",
    "    return fb['met_tst_noJVT_et'] > 100_000\n",
    "\n",
    "# Bundle all the single-cut masks you want to test\n",
    "CUTS = [\n",
    "    (\"balance>1\",              cut_balance_gt_0p91),\n",
    "    (\"met_jetterm_et>80GeV\",      cut_met_jetterm_et_gt_92GeV),\n",
    "    # (\"1.6<dphi(phterm,jetterm)<3.1\", cut_dphi_phterm_jetterm_window),\n",
    "    (\"metsigres<42GeV\",           cut_metsigres_lt_36GeV),\n",
    "    (\"met_noJVT>100GeV\",           cut_met_noJVT_gt_90GeV),\n",
    "]\n",
    "\n",
    "def significance_by_single_cuts(tot, ntuple_names, signal_name=\"ggHyyd\", sigma_b_frac=0.30, include_zbi=True):\n",
    "    \"\"\"\n",
    "    For each cut in CUTS: apply only that cut on top of the baseline 'tot',\n",
    "    then compute S, B, S/sqrt(B) (and ZBi).\n",
    "    Returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Precompute per-sample weights once (so we don't rebuild weights inside each cut)\n",
    "    weights = []\n",
    "    for i, fb in enumerate(tot):\n",
    "        name = ntuple_names[i]\n",
    "        w = fb['weights']\n",
    "        weights.append(w)\n",
    "\n",
    "    rows = []\n",
    "    # Also compute baseline (no extra cut) significance for reference\n",
    "    S0 = 0.0\n",
    "    B0 = 0.0\n",
    "    for i, fb in enumerate(tot):\n",
    "        name = ntuple_names[i]\n",
    "        wsum = float(ak.sum(weights[i]))\n",
    "        if name == signal_name:\n",
    "            S0 += wsum\n",
    "        else:      # exclude data from B\n",
    "            B0 += wsum\n",
    "    base = {\n",
    "        \"cut\": \"(no extra cut)\",\n",
    "        \"S\": S0,\n",
    "        \"B\": B0,\n",
    "        \"S/sqrt(B)\": s_over_sqrt_b(S0, B0)\n",
    "    }\n",
    "    if include_zbi:\n",
    "        base[\"ZBi(30%)\"] = zbi(S0, B0, sigma_b_frac)\n",
    "    rows.append(base)\n",
    "\n",
    "    # Now evaluate each single cut\n",
    "    for label, cut_fn in CUTS:\n",
    "        S = 0.0\n",
    "        B = 0.0\n",
    "        for i, fb in enumerate(tot):\n",
    "            name = ntuple_names[i]\n",
    "            m = cut_fn(fb)                      # boolean mask (Awkward-friendly)\n",
    "            w = weights[i][m]                   # apply mask to precomputed event weights\n",
    "            wsum = float(ak.sum(w))\n",
    "            if name == signal_name:\n",
    "                S += wsum\n",
    "            else:\n",
    "                B += wsum\n",
    "\n",
    "        row = {\n",
    "            \"cut\": label,\n",
    "            \"S\": S,\n",
    "            \"B\": B,\n",
    "            \"S/sqrt(B)\": s_over_sqrt_b(S, B)\n",
    "        }\n",
    "        if include_zbi:\n",
    "            row[\"ZBi(30%)\"] = zbi(S, B, sigma_b_frac)\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Nicely formatted view (optional)\n",
    "    with pd.option_context('display.float_format', '{:,.3f}'.format):\n",
    "        print(df.to_string(index=False))\n",
    "    return df\n",
    "\n",
    "\n",
    "initial_cuts = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.2},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -15000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.35},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.85},\n",
    "]\n",
    "tot2_initial_cut = apply_all_cuts(tot, ntuple_names, initial_cuts, getVarDict)\n",
    "\n",
    "# --- RUN IT ---\n",
    "sig_table = significance_by_single_cuts(tot2_initial_cut, ntuple_names, signal_name='ggHyyd', sigma_b_frac=0.30, include_zbi=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44940971-f170-422f-b73d-01f3843655cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -25000.0},\n",
       " {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 8.0},\n",
       " {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.35},\n",
       " {'cut_var': 'dphi_met_jetterm',\n",
       "  'cut_type': 'uppercut',\n",
       "  'best_cut': 0.8500000000000003},\n",
       " {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.7500000000000007},\n",
       " {'cut_var': 'balance',\n",
       "  'cut_type': 'lowercut',\n",
       "  'best_cut': 0.9999999999999998},\n",
       " {'cut_var': 'jetterm', 'cut_type': 'lowercut', 'best_cut': 90000.0},\n",
       " {'cut_var': 'metsigres', 'cut_type': 'uppercut', 'best_cut': 42000.0},\n",
       " {'cut_var': 'met_noJVT', 'cut_type': 'lowercut', 'best_cut': 90000.0},\n",
       " {'cut_var': 'VertexBDTScore',\n",
       "  'cut_type': 'lowercut',\n",
       "  'best_cut': 0.22000000000000003}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9ef0a29-fe76-4614-ba44-4a87cb9c2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_cuts2 = [{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -15000.0},\n",
    " {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7.0},\n",
    " {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.20},\n",
    " {'cut_var': 'dphi_met_jetterm',\n",
    "  'cut_type': 'uppercut',\n",
    "  'best_cut': 0.8500000000000003},\n",
    " {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.7500000000000007},\n",
    " {'cut_var': 'balance',\n",
    "  'cut_type': 'lowercut',\n",
    "  'best_cut': 0.9999999999999998},\n",
    " {'cut_var': 'jetterm', 'cut_type': 'lowercut', 'best_cut': 80000.0},\n",
    " {'cut_var': 'metsigres', 'cut_type': 'uppercut', 'best_cut': 42000.0},\n",
    " {'cut_var': 'met_noJVT', 'cut_type': 'lowercut', 'best_cut': 100000.0},\n",
    " {'cut_var': 'VertexBDTScore',\n",
    "  'cut_type': 'lowercut',\n",
    "  'best_cut': 0.1000000000000003}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a5df7e9-0dbd-4b83-9c54-3e3fb9ef2184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< -- Sum of weight each process -- >\n",
      "ggHyyd 186.12543\n",
      "Zgamma 527.19464\n",
      "Wgamma 1009.02875\n",
      "gammajet_direct 42.67856\n",
      "data_y 1054.260999999995\n",
      "data_eprobe 1854.7567422406833\n"
     ]
    }
   ],
   "source": [
    "tot2_optimized_cuts = apply_all_cuts(tot, ntuple_names, optimized_cuts2, getVarDict)\n",
    "\n",
    "print('< -- Sum of weight each process -- >')\n",
    "\n",
    "for i in range(len(tot2_optimized_cuts)):\n",
    "    print(ntuple_names[i], ak.sum(tot2_optimized_cuts[i]['weights']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "617519cd-9838-4142-a601-9a0d47ecee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< -- Sum of weight each process -- >\n",
      "ggHyyd 188.84154\n",
      "Zgamma 497.98044\n",
      "Wgamma 980.3159\n",
      "gammajet_direct 109.93676\n",
      "data_y 1708.3380000000134\n",
      "data_eprobe 2055.646897520867\n",
      "significance : 2.5812533339885784\n"
     ]
    }
   ],
   "source": [
    "initial_cuts = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -10000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "]\n",
    "print('< -- Sum of weight each process -- >')\n",
    "tot_tmp = apply_all_cuts(tot, ntuple_names, initial_cuts, getVarDict)\n",
    "for i in range(len(tot)):\n",
    "    print(ntuple_names[i], ak.sum(tot_tmp[i]['weights']))\n",
    "print(f'significance : {compute_total_significance(tot_tmp, ntuple_names, signal_name, getVarDict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18651011-5823-4d99-8fee-4dc1aa450193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< -- Sum of weight each process -- >\n",
      "ggHyyd 186.12543\n",
      "Zgamma 527.19464\n",
      "Wgamma 1009.02875\n",
      "gammajet_direct 42.67856\n",
      "data_y 1054.260999999995\n",
      "data_eprobe 1854.7567422406833\n",
      "significance : 2.7783257837777087\n"
     ]
    }
   ],
   "source": [
    "# cuts = [\n",
    "#     {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "#     {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7},\n",
    "#     {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "#     {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.20},\n",
    "#     {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -15000},\n",
    "#     {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.35},\n",
    "#     {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.85},\n",
    "# ]\n",
    "cuts = [{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -15000.0},\n",
    " {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7.0},\n",
    " {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.20},\n",
    " {'cut_var': 'dphi_met_jetterm',\n",
    "  'cut_type': 'uppercut',\n",
    "  'best_cut': 0.8500000000000003},\n",
    " {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.7500000000000007},\n",
    " {'cut_var': 'balance',\n",
    "  'cut_type': 'lowercut',\n",
    "  'best_cut': 0.9999999999999998},\n",
    " {'cut_var': 'jetterm', 'cut_type': 'lowercut', 'best_cut': 80000.0},\n",
    " {'cut_var': 'metsigres', 'cut_type': 'uppercut', 'best_cut': 42000.0},\n",
    " {'cut_var': 'met_noJVT', 'cut_type': 'lowercut', 'best_cut': 100000.0},\n",
    " {'cut_var': 'VertexBDTScore',\n",
    "  'cut_type': 'lowercut',\n",
    "  'best_cut': 0.1000000000000003}]\n",
    "print('< -- Sum of weight each process -- >')\n",
    "tot_tmp = apply_all_cuts(tot, ntuple_names, cuts, getVarDict)\n",
    "for i in range(len(tot)):\n",
    "    print(ntuple_names[i], ak.sum(tot_tmp[i]['weights']))\n",
    "print(f'significance : {compute_total_significance(tot_tmp, ntuple_names, signal_name, getVarDict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84d051b6-b485-4ec5-a815-ff440ac67d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_ph.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_ph_baseline.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_el.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_el_baseline.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_mu_baseline.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_tau_baseline.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/mt.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/metsig.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/metsigres.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/met.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/met_noJVT.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/dmet.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/ph_pt.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/ph_eta.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/ph_phi.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/pv_ntracks.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jet_central_eta.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jet_central_vecSumPt.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jet_central_pt1.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jet_central_pt2.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/dphi_met_phterm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/dphi_met_jetterm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/dphi_phterm_jetterm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/failJVT_jet_pt1.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/failJVT_jet_vecSumPt.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/softerm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jetterm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/jetterm_sumet.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_jet.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_jet_central.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/n_jet_fwd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/central_jets_fraction.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/balance.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/dphi_jj.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selection2cut/VertexBDTScore.png\n"
     ]
    }
   ],
   "source": [
    "# path for plot storage\n",
    "mt_val_dir = 'mt100_140'\n",
    "\n",
    "# cut_name = 'basic'\n",
    "# plot_performance(tot, ntuple_names, sample_dict, getVarDict, zbi, mt_val_dir, cut_name) # basic\n",
    "\n",
    "cut_name = 'n-1'\n",
    "plot_performance(tot_tmp, ntuple_names, sample_dict, getVarDict, zbi, mt_val_dir, cut_name) # selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b04ae786-3c3f-4590-bc86-2e4eec534155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_VertexBDTScore_lowercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60/3256810261.py:304: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:305: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:306: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/VertexBDTScore.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_VertexBDTScore.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_metsig_lowercut.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/metsig.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_metsig.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_ph_eta_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60/3256810261.py:304: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:305: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:306: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/ph_eta.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_ph_eta.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dmet_lowercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60/3256810261.py:304: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:305: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:306: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dmet.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dmet.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dphi_jj_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60/3256810261.py:304: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:305: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:306: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dphi_jj.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dphi_jj.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dphi_met_phterm_lowercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60/3256810261.py:304: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:305: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:306: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dphi_met_phterm.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dphi_met_phterm.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dphi_met_jetterm_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60/3256810261.py:304: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:305: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:306: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dphi_met_jetterm.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dphi_met_jetterm.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_balance_lowercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60/3256810261.py:304: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:305: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:306: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/balance.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_balance.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60/3256810261.py:304: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:305: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_60/3256810261.py:306: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/metsigres.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_metsigres.png\n"
     ]
    }
   ],
   "source": [
    "def sel(tot, n_1_name=None):\n",
    "    \"\"\"\n",
    "    Apply baseline cuts to all fb in tot except the variable named by n_1_name.\n",
    "    \"\"\"\n",
    "    import awkward as ak\n",
    "    out = []\n",
    "    for i in range(len(tot)):\n",
    "        fb2 = tot[i]\n",
    "\n",
    "        if n_1_name != \"VertexBDTScore\":\n",
    "            VertexBDTScore_tmp = fb2['VertexBDTScore']\n",
    "            fb2 = fb2[VertexBDTScore_tmp > 0.10]\n",
    "\n",
    "        if n_1_name != \"metsig\":\n",
    "            metsig_tmp = fb2['met_tst_sig']\n",
    "            fb2 = fb2[(metsig_tmp > 7)]\n",
    "\n",
    "        if n_1_name != \"ph_eta\":\n",
    "            ph_eta_tmp = np.abs(ak.firsts(fb2['ph_eta']))\n",
    "            fb2 = fb2[ph_eta_tmp < 1.75]\n",
    "\n",
    "        if n_1_name != \"dphi_met_phterm\":\n",
    "            dphi_met_phterm_tmp = fb2['dphi_met_phterm']\n",
    "            fb2 = fb2[dphi_met_phterm_tmp > 1.25]\n",
    "            \n",
    "        if n_1_name != \"dmet\":\n",
    "            dmet_tmp = fb2['dmet']\n",
    "            fb2 = fb2[(dmet_tmp > -25000)]\n",
    "\n",
    "        if n_1_name != \"dphi_met_jetterm\":\n",
    "            dphi_met_jetterm_tmp = fb2['dphi_met_jetterm']\n",
    "            fb2 = fb2[dphi_met_jetterm_tmp <= 0.75]\n",
    "\n",
    "        if n_1_name != \"dphi_jj\":\n",
    "            dphi_jj_tmp = fb2['dphi_central_jj']\n",
    "            dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "            dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "            dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "            fb2 = fb2[dphi_jj_tmp < 2.5]\n",
    "\n",
    "        if n_1_name != \"balance\":\n",
    "            sumet_tmp = ak.sum(fb2['jet_central_pt'], axis=-1)\n",
    "            expr = (fb2['met_tst_et'] + ak.firsts(fb2['ph_pt'])) / ak.where(sumet_tmp != 0, sumet_tmp, 1)\n",
    "            balance_tmp = ak.where(sumet_tmp != 0, expr, -999) \n",
    "            mask_nan = balance_tmp == -999\n",
    "            mask = mask_nan | (balance_tmp > 0.9)\n",
    "            fb2 = fb2[mask]\n",
    "\n",
    "        out.append(fb2)\n",
    "    return out\n",
    "\n",
    "def getCutDict(n_1_name=None):\n",
    "    cut_dict = {}\n",
    "    if n_1_name is None or n_1_name == \"VertexBDTScore\":\n",
    "        cut_dict['VertexBDTScore'] = {'lowercut': np.arange(0.10, 0.36, 0.02)}\n",
    "    if n_1_name is None or n_1_name == \"dmet\":\n",
    "        cut_dict['dmet'] = {'lowercut': np.arange(-30000, 10000 + 5000, 5000)}\n",
    "    if n_1_name is None or n_1_name == \"metsig\":\n",
    "        cut_dict['metsig'] = {'lowercut': np.arange(0, 10 + 1, 1)}\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_phterm\":\n",
    "        cut_dict['dphi_met_phterm'] = {'lowercut': np.arange(1, 2 + 0.05, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_jetterm\":\n",
    "        cut_dict['dphi_met_jetterm'] = {'uppercut': np.arange(0.5, 1.00, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"ph_eta\":\n",
    "        cut_dict['ph_eta'] = {'uppercut': np.arange(1.0, 2.50 + 0.05, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"dphi_jj\":\n",
    "        cut_dict['dphi_jj'] = {'uppercut': np.arange(1.0, 3.10 + 0.05, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"balance\":\n",
    "        cut_dict['balance'] = {'lowercut': np.arange(0.3, 1.5 + 0.05, 0.05)}\n",
    "    return cut_dict\n",
    "\n",
    "\n",
    "def calculate_significance2(tot, ntuple_names, getVarDict, zbi, cut_var, cut_type, cut_values, signal_name=\"ggHyyd\"):\n",
    "    \n",
    "    sig_simple_list = []\n",
    "    sig_s_plus_b_list = []\n",
    "    sig_s_plus_1p3b_list = []\n",
    "    sig_binomial_list = []\n",
    "\n",
    "    sigacc_simple_list = []\n",
    "    sigacc_s_plus_b_list = []\n",
    "    sigacc_s_plus_1p3b_list = []\n",
    "    sigacc_binomial_list = []\n",
    "\n",
    "    acceptance_values = []  # Store acceptance percentages\n",
    "\n",
    "    for cut in cut_values:\n",
    "        sig_after_cut = 0\n",
    "        bkg_after_cut = []\n",
    "        sig_events = 0\n",
    "        \n",
    "        for i in range(len(ntuple_names)):\n",
    "            fb = tot[i]\n",
    "            process = ntuple_names[i]\n",
    "            var_config = getVarDict(fb, process, var_name=cut_var)\n",
    "            x = var_config[cut_var]['var']\n",
    "            mask_nan = x == -999\n",
    "            \n",
    "            if process == signal_name:\n",
    "                sig_events = fb['weights']\n",
    "                mask_cut = x > cut if cut_type == 'lowercut' else x < cut\n",
    "                mask = mask_nan | mask_cut\n",
    "                sig_after_cut = ak.sum(sig_events[mask])\n",
    "            else:\n",
    "                bkg_events = fb['weights']\n",
    "                mask_cut = x > cut if cut_type == 'lowercut' else x < cut\n",
    "                mask = mask_nan | mask_cut\n",
    "                bkg_after_cut.append(ak.sum(bkg_events[mask]))\n",
    "\n",
    "       # Now compute different types of significance\n",
    "        total_bkg = sum(bkg_after_cut)\n",
    "        total_signal = sig_after_cut\n",
    "\n",
    "        # Avoid zero division carefully\n",
    "        if total_bkg > 0:\n",
    "            sig_simple = total_signal / np.sqrt(total_bkg)\n",
    "            sig_s_plus_b = total_signal / np.sqrt(total_signal + total_bkg) if (total_signal + total_bkg) > 0 else 0\n",
    "            sig_s_plus_1p3b = total_signal / np.sqrt(total_signal + 1.3 * total_bkg) if (total_signal + 1.3*total_bkg) > 0 else 0\n",
    "            sig_binomial = zbi(total_signal, total_bkg, sigma_b_frac=0.3)\n",
    "        else:\n",
    "            sig_simple = sig_s_plus_b = sig_s_plus_1p3b = sig_binomial = 0\n",
    "\n",
    "        # Acceptance\n",
    "        acceptance = total_signal / sum(sig_events) if sum(sig_events) > 0 else 0\n",
    "        acceptance_values.append(acceptance * 100)  # percentage\n",
    "\n",
    "        # Save significance\n",
    "        sig_simple_list.append(sig_simple)\n",
    "        sig_s_plus_b_list.append(sig_s_plus_b)\n",
    "        sig_s_plus_1p3b_list.append(sig_s_plus_1p3b)\n",
    "        sig_binomial_list.append(sig_binomial)\n",
    "\n",
    "        # Save significance × acceptance\n",
    "        sigacc_simple_list.append(sig_simple * acceptance)\n",
    "        sigacc_s_plus_b_list.append(sig_s_plus_b * acceptance)\n",
    "        sigacc_s_plus_1p3b_list.append(sig_s_plus_1p3b * acceptance)\n",
    "        sigacc_binomial_list.append(sig_binomial * acceptance)\n",
    "\n",
    "    return (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "            sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "            acceptance_values)\n",
    "\n",
    "\n",
    "# --- config ---\n",
    "mt_val_dir = 'mt100_140'\n",
    "n_1_config = [\"VertexBDTScore\", \"metsig\", \"ph_eta\", \"dmet\", \"dphi_jj\", \"dphi_met_phterm\", \"dphi_met_jetterm\", \"balance\", \"jetterm\", \"metsigres\", \"met_noJVT\"]\n",
    "signal_name = 'ggHyyd'\n",
    "cut_name = 'n-1' \n",
    "\n",
    "\n",
    "def plot_n_1(tot, ntuple_names, sample_dict, getVarDict, zbi, getCutDict, sel, mt_val_dir, n_1_config, cut_name='n-1', signal_name=\"ggHyyd\"):\n",
    "\n",
    "    def ensure_dir(path_str):\n",
    "        Path(path_str).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def to_np(a):\n",
    "        \"\"\"Flatten awkward/numpy to 1D numpy array; empty-safe.\"\"\"\n",
    "        if a is None:\n",
    "            return np.array([])\n",
    "        try:\n",
    "            import awkward as ak\n",
    "            if hasattr(ak, \"to_numpy\"):\n",
    "                return ak.to_numpy(ak.flatten(a, axis=None))\n",
    "        except Exception:\n",
    "            pass\n",
    "        return np.asarray(a).ravel()\n",
    "    \n",
    "    def safe_concat(list_of_arrays):\n",
    "        \"\"\"Concatenate list of arrays safely (possibly empty).\"\"\"\n",
    "        if len(list_of_arrays) == 0:\n",
    "            return np.array([])\n",
    "        arrs = [to_np(x) for x in list_of_arrays if x is not None]\n",
    "        return np.concatenate(arrs) if len(arrs) else np.array([])\n",
    "    \n",
    "    def safe_hist(x, bins, w=None):\n",
    "        if x.size == 0:\n",
    "            return np.zeros(len(bins)-1, dtype=float), bins\n",
    "        return np.histogram(x, bins=bins, weights=w)\n",
    "    \n",
    "    # ---------- N-1 scan + plots ----------\n",
    "    \n",
    "    out_base = f\"/home/jlai/dark_photon/main/{mt_val_dir}/{cut_name}cut\"\n",
    "    ensure_dir(out_base)\n",
    "    \n",
    "    for cut_var_tmp in n_1_config:\n",
    "        cut_config = getCutDict(n_1_name=cut_var_tmp)\n",
    "        tot2 = sel(tot, n_1_name=cut_var_tmp)\n",
    "    \n",
    "        # --- Significance vs cut scans for this n-1 variable ---\n",
    "        for cut_var, cut_types in cut_config.items():\n",
    "            for cut_type, cut_values in cut_types.items():\n",
    "                (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "                 sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "                 acceptance_values) = calculate_significance2(tot, ntuple_names, getVarDict, zbi, cut_var, cut_type, cut_values)\n",
    "    \n",
    "                fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "    \n",
    "                # Top: S/sqrt(B) and vertical line at max\n",
    "                i_max = int(np.argmax(sig_simple_list)) if len(sig_simple_list) else 0\n",
    "                max_tmp = float(cut_values[i_max]) if len(cut_values) else np.nan\n",
    "                if len(cut_values):\n",
    "                    ax_top.axvline(x=max_tmp, color='r', linestyle='--', label=f'Max S/√B at {max_tmp:.2f}')\n",
    "                ax_top.plot(cut_values, sig_simple_list, marker='o', label='S/√B')\n",
    "                # Uncomment if you want the other metrics on same plot:\n",
    "                # ax_top.plot(cut_values, sig_s_plus_b_list, marker='s', label='S/√(S+B)')\n",
    "                # ax_top.plot(cut_values, sig_s_plus_1p3b_list, marker='^', label='S/√(S+1.3B)')\n",
    "                # ax_top.plot(cut_values, sig_binomial_list, marker='x', label='BinomialExpZ')\n",
    "                ax_top.set_ylabel('Significance')\n",
    "                ax_top.set_title(f'N-1: Significance vs. {cut_var} ({cut_type})')\n",
    "                ax_top.grid(True)\n",
    "                ax_top.legend()\n",
    "    \n",
    "                # Bottom: (S/√B) × Acceptance\n",
    "                if len(cut_values):\n",
    "                    ax_bot.axvline(x=max_tmp, color='r', linestyle='--')\n",
    "                ax_bot.plot(cut_values, sigacc_simple_list, marker='o', label='(S/√B) × Acceptance')\n",
    "    \n",
    "                for i, acc in enumerate(acceptance_values):\n",
    "                    ax_bot.text(cut_values[i], sigacc_simple_list[i], f'{acc:.1f}%',\n",
    "                                fontsize=9, ha='right', va='bottom', color='purple')\n",
    "    \n",
    "                # Label with pretty var title\n",
    "                var_cfg_for_label = getVarDict(tot2[0], signal_name, cut_var)\n",
    "                ax_bot.set_xlabel(var_cfg_for_label[cut_var]['title'])\n",
    "                ax_bot.set_ylabel('Significance × Acceptance')\n",
    "                ax_bot.grid(True)\n",
    "                ax_bot.legend()\n",
    "    \n",
    "                plt.tight_layout()\n",
    "                out_path = f\"{out_base}/significance_{cut_var}_{cut_type}.png\"\n",
    "                ensure_dir(Path(out_path).parent.as_posix())\n",
    "                plt.savefig(out_path)\n",
    "                print(f\"Saved: {out_path}\")\n",
    "                plt.close()\n",
    "    \n",
    "        # --- N-1 distributions + per-bin significance & ROC for THIS variable ---\n",
    "        var_cfg_sig = getVarDict(tot2[0], signal_name, var_name=cut_var_tmp)  # only request this var\n",
    "        for var in var_cfg_sig:\n",
    "            bg_vals, bg_wts, bg_cols, bg_labs = [], [], [], []\n",
    "            sig_vals, sig_wts = [], []\n",
    "            sig_col = None\n",
    "            sig_lab = None\n",
    "    \n",
    "            # Build stacks\n",
    "            for j in range(len(ntuple_names)):\n",
    "                process = ntuple_names[j]\n",
    "                fb2 = tot2[j]\n",
    "                var_cfg = getVarDict(fb2, process, var_name=var)\n",
    "                x = var_cfg[var]['var']\n",
    "                bins = var_cfg[var]['bins']\n",
    "                weights = fb2['weights']\n",
    "    \n",
    "                info = sample_dict[process]\n",
    "                if process == signal_name:\n",
    "                    sig_vals.append(x)\n",
    "                    sig_wts.append(weights)\n",
    "                    sig_col = info['color']; sig_lab = info['legend']\n",
    "                else:\n",
    "                    bg_vals.append(x); bg_wts.append(weights)\n",
    "                    bg_cols.append(info['color']); bg_labs.append(info['legend'])\n",
    "    \n",
    "            # Convert/concat\n",
    "            sig_all = safe_concat(sig_vals)\n",
    "            sig_w_all = safe_concat(sig_wts)\n",
    "            bg_all = safe_concat(bg_vals)\n",
    "            bg_w_all = safe_concat(bg_wts)\n",
    "    \n",
    "            # Figure / axes\n",
    "            fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(12, 13), gridspec_kw={'height_ratios':[9,4]})\n",
    "    \n",
    "            # Stacked BG + signal outline\n",
    "            if len(bg_vals):\n",
    "                ax_top.hist([to_np(v) for v in bg_vals], bins=bins,\n",
    "                            weights=[to_np(w) for w in bg_wts], color=bg_cols,\n",
    "                            label=bg_labs, stacked=True)\n",
    "            if sig_all.size:\n",
    "                ax_top.hist(sig_all, bins=bins, weights=sig_w_all, color=sig_col,\n",
    "                            label=sig_lab, histtype='step', linewidth=2)\n",
    "    \n",
    "                # Signal error bars\n",
    "                s_counts, s_edges = safe_hist(sig_all, bins=bins, w=sig_w_all)\n",
    "                s2, _ = safe_hist(sig_all, bins=bins, w=sig_w_all**2 if sig_w_all.size else None)\n",
    "                bin_centers = 0.5*(s_edges[:-1] + s_edges[1:])\n",
    "                s_err = np.sqrt(s2)\n",
    "                ax_top.errorbar(bin_centers, s_counts, yerr=s_err, fmt='.', linewidth=2,\n",
    "                                color=sig_col, capsize=0)\n",
    "    \n",
    "            ax_top.set_yscale('log')\n",
    "            ax_top.set_ylim(max(1e-4, 1e-6), 1e11)\n",
    "            ax_top.set_xlim(bins[0], bins[-1])\n",
    "            ax_top.minorticks_on()\n",
    "            ax_top.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "            ax_top.set_ylabel(\"Events\")\n",
    "            ax_top.legend(ncol=2)\n",
    "    \n",
    "            # Per-bin significance curves\n",
    "            S_counts, _ = safe_hist(sig_all, bins=bins, w=sig_w_all)\n",
    "            B_counts, _ = safe_hist(bg_all, bins=bins, w=bg_w_all)\n",
    "    \n",
    "            sqrt_B = np.sqrt(np.clip(B_counts, 0, None))\n",
    "            sqrt_SplusB = np.sqrt(np.clip(S_counts + B_counts, 0, None))\n",
    "            sqrt_Splus1p3B = np.sqrt(np.clip(S_counts + 1.3*B_counts, 0, None))\n",
    "    \n",
    "            sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
    "            sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
    "            sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n",
    "    \n",
    "            # Binomial ExpZ per bin\n",
    "            zbi_per_bin = np.array([zbi(S_counts[i], B_counts[i], sigma_b_frac=0.3) for i in range(len(S_counts))])\n",
    "    \n",
    "            bin_centers = 0.5*(bins[:-1] + bins[1:])\n",
    "    \n",
    "            # Totals\n",
    "            S_tot = float(np.sum(S_counts))\n",
    "            B_tot = float(np.sum(B_counts))\n",
    "            if B_tot > 0:\n",
    "                tot_SsqrtB = S_tot / np.sqrt(B_tot)\n",
    "                tot_SsqrtSB = S_tot / np.sqrt(S_tot + B_tot) if (S_tot + B_tot) > 0 else 0\n",
    "                tot_SsqrtS1p3B = S_tot / np.sqrt(S_tot + 1.3*B_tot) if (S_tot + 1.3*B_tot) > 0 else 0\n",
    "                tot_zbi = zbi(S_tot, B_tot, sigma_b_frac=0.3)\n",
    "            else:\n",
    "                tot_SsqrtB = tot_SsqrtSB = tot_SsqrtS1p3B = tot_zbi = 0.0\n",
    "    \n",
    "            ax_bot.step(bin_centers, sig_simple, where='mid', linewidth=2,\n",
    "                        label=f\"S/√B = {tot_SsqrtB:.4f}\", color='chocolate')\n",
    "            ax_bot.step(bin_centers, sig_s_plus_b, where='mid', linewidth=2,\n",
    "                        label=f\"S/√(S+B) = {tot_SsqrtSB:.4f}\", color='tomato')\n",
    "            ax_bot.step(bin_centers, sig_s_plus_1p3b, where='mid', linewidth=2,\n",
    "                        label=f\"S/√(S+1.3B) = {tot_SsqrtS1p3B:.4f}\", color='orange')\n",
    "            ax_bot.step(bin_centers, zbi_per_bin, where='mid', linewidth=2,\n",
    "                        label=f\"Binomial ExpZ = {tot_zbi:.4f}\", color='plum')\n",
    "    \n",
    "            ax_bot.set_xlabel(var_cfg_sig[var]['title'])\n",
    "            ax_bot.set_ylabel(\"Significance\")\n",
    "            ax_bot.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "            ax_bot.set_title(\"\")\n",
    "            leg = ax_bot.legend()\n",
    "            for t in leg.get_texts():\n",
    "                t.set_color('purple')\n",
    "    \n",
    "            plt.xlim(bins[0], bins[-1])\n",
    "            plt.tight_layout()\n",
    "    \n",
    "            dist_dir = f\"{out_base}\"\n",
    "            ensure_dir(dist_dir)\n",
    "            out_png = f\"{dist_dir}/{var}.png\"\n",
    "            plt.savefig(out_png)\n",
    "            print(f\"Saved: {out_png}\")\n",
    "            plt.close()\n",
    "    \n",
    "            # ROC using this single variable as score\n",
    "            y_true = np.concatenate([np.ones_like(S_counts).repeat(1)])  # placeholder to silence lints\n",
    "            # Build event-wise arrays, not binned:\n",
    "            y_true = np.concatenate([np.ones(sig_all.shape[0], dtype=int), np.zeros(bg_all.shape[0], dtype=int)])\n",
    "            y_scores = np.concatenate([sig_all, bg_all])\n",
    "            y_w = np.concatenate([sig_w_all if sig_w_all.size else np.ones(sig_all.shape[0]),\n",
    "                                  bg_w_all if bg_w_all.size else np.ones(bg_all.shape[0])])\n",
    "    \n",
    "            if y_scores.size and np.unique(y_true).size == 2:\n",
    "                fpr, tpr, thr = roc_curve(y_true, y_scores, sample_weight=y_w)\n",
    "                order = np.argsort(fpr)\n",
    "                roc_auc = auc(fpr[order], tpr[order])\n",
    "    \n",
    "                plt.figure(figsize=(8, 8))\n",
    "                plt.plot(fpr, tpr, lw=2, label=f'ROC (AUC = {roc_auc:.5f})')\n",
    "                plt.plot([0, 1], [0, 1], linestyle='--', label='Random')\n",
    "                plt.xlabel(\"False Positive Rate\")\n",
    "                plt.ylabel(\"True Positive Rate\")\n",
    "                plt.title(f\"N-1 ROC — {var}\")\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "                plt.tight_layout()\n",
    "                out_png = f\"{dist_dir}/roc_curve_{var}.png\"\n",
    "                plt.savefig(out_png)\n",
    "                print(f\"Saved: {out_png}\")\n",
    "                plt.close()\n",
    "\n",
    "\n",
    "plot_n_1(tot, ntuple_names, sample_dict, getVarDict, zbi, getCutDict, sel, mt_val_dir, n_1_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e7aea22-56fd-4cae-8160-6c82a02d295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
