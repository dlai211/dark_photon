{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import uproot, sys, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high\n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 18\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"]  # Legend\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeight(fb, sample):\n",
    "    # lumi = 25767.5\n",
    "    lumi = 135000\n",
    "    weight = fb['mconly_weight']/fb['mc_weight_sum']*fb['xsec_ami']*fb['filter_eff_ami']*fb['kfactor_ami']*fb['pu_weight']*fb['jvt_weight']*1000*lumi\n",
    "    if sample in ['ggHyyd','WH','VBF','ZH'] : \n",
    "        xsec_sig = 0.052 #if ( period == 'Run3' or 'mc23' in period ) else 0.048\n",
    "        # if sample != 'ggHyyd' : xsec_sig = fb['xsec_ami']\n",
    "        br = 0.01\n",
    "        weight = fb['mconly_weight']/fb['mc_weight_sum']*xsec_sig*fb['pu_weight']*fb['jvt_weight']*fb['filter_eff_ami']*fb['kfactor_ami']*1000*lumi*br\n",
    "    return weight\n",
    "\n",
    "def getSampleDict():\n",
    "    sample_dict = {}\n",
    "    sample_dict['Zjets'] = {\n",
    "        'color': 'darkgreen',   # approximates ROOT.kGreen-2\n",
    "        'legend': r'Z($\\nu\\nu$, ll)+jets',\n",
    "        'tree': 'nominal',\n",
    "        'filenames': ['Zjets']\n",
    "    }\n",
    "    sample_dict['Zgamma'] = {\n",
    "        'color': '#e6550d',      # approximates ROOT.kOrange+7\n",
    "        'legend': r'Z($\\nu\\nu$)+$\\gamma$',\n",
    "        'tree': 'nominal',\n",
    "        'filenames': ['Zgamma']\n",
    "    }\n",
    "    sample_dict['Wgamma'] = {\n",
    "        'color': 'darkorange',  # approximates ROOT.kOrange+1\n",
    "        'legend': r'W($l\\nu$)+$\\gamma$',\n",
    "        'tree': 'nominal',\n",
    "        'filenames': ['Wgamma']\n",
    "    }\n",
    "    sample_dict['Wjets'] = {\n",
    "        'color': 'teal',        # approximates ROOT.kTeal+5\n",
    "        'legend': r'W($l\\nu$)+jets',\n",
    "        'tree': 'nominal',\n",
    "        'filenames': ['Wjets']\n",
    "    }\n",
    "    sample_dict['gammajet_direct'] = {\n",
    "        'color': 'royalblue',   # approximates ROOT.kBlue+2\n",
    "        'legend': r'$\\gamma$+jets direct',\n",
    "        'tree': 'gammajets',\n",
    "        'filenames': ['gammajet_direct']\n",
    "    }\n",
    "    sample_dict['gammajet_frag'] = {\n",
    "        'color': 'navy',        # approximates ROOT.kBlue-5\n",
    "        'legend': r'$\\gamma$+jets frag',\n",
    "        'tree': 'gammajets',\n",
    "        'filenames': ['gammajet_frag']\n",
    "    }\n",
    "    sample_dict['dijet'] = {\n",
    "        'color': 'cyan',        # approximates ROOT.kCyan+1\n",
    "        'legend': 'multijets',\n",
    "        'tree': 'dijets',\n",
    "        'filenames': ['dijet']\n",
    "    }\n",
    "    sample_dict['ggHyyd'] = {\n",
    "        'color': 'red',         # approximates ROOT.kRed\n",
    "        'legend': r'ggH, H$\\rightarrow\\gamma\\gamma_{d}$',\n",
    "        'tree': 'nominal',\n",
    "        'filenames': ['ggHyyd']\n",
    "    }\n",
    "    return sample_dict\n",
    "sample_dict = getSampleDict()\n",
    "\n",
    "def getVarDict(fb, process, var_name=None):\n",
    "    var_dict = {}\n",
    "\n",
    "    # this has the same size as weight, so don't need adjustment on weighting\n",
    "    if var_name is None or var_name == 'vtx_sumPt':\n",
    "        var_dict['vtx_sumPt'] = {\n",
    "            'var': ak.flatten(fb['vtx_sumPt']),\n",
    "            'bins': np.linspace(0, 100, 20+1),  # 21 edges for 20 bins\n",
    "            'title': r'vtx\\_sumPt'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'n_ph':\n",
    "        var_dict['n_ph'] = {\n",
    "            'var': fb['n_ph'],\n",
    "            'bins': np.linspace(0, 7, 7+1),\n",
    "            'title': r'$N_{ph}$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'n_ph_baseline':\n",
    "        var_dict['n_ph_baseline'] = {\n",
    "            'var': fb['n_ph_baseline'],\n",
    "            'bins': np.linspace(0, 7, 7+1),\n",
    "            'title': r'$N_{ph\\_baseline}$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'n_el_baseline':\n",
    "        var_dict['n_el_baseline'] = {\n",
    "            'var': fb['n_el_baseline'],\n",
    "            'bins': np.linspace(0, 7, 7+1),\n",
    "            'title': r'$N_{el\\_baseline}$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'n_mu_baseline':\n",
    "        var_dict['n_mu_baseline'] = {\n",
    "            'var': fb['n_mu_baseline'],\n",
    "            'bins': np.linspace(0, 7, 7+1),\n",
    "            'title': r'$N_{mu\\_baseline}$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'n_tau_baseline':\n",
    "        var_dict['n_tau_baseline'] = {\n",
    "            'var': fb['n_tau_baseline'],\n",
    "            'bins': np.linspace(0, 7, 7+1),\n",
    "            'title': r'$N_{tau\\_baseline}$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'puWeight':\n",
    "        var_dict['puWeight'] = {\n",
    "            'var': fb['pu_weight'],\n",
    "            'bins': np.linspace(0, 2, 50+1),\n",
    "            'title': r'PU weight',\n",
    "            'shift': '+0'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'actualIntPerXing':\n",
    "        var_dict['actualIntPerXing'] = {\n",
    "            'var': fb['actualIntPerXing'],\n",
    "            'bins': np.linspace(0, 100, 50+1),\n",
    "            'title': r'$\\langle\\mu\\rangle$',\n",
    "            'shift': '+0'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'mt':\n",
    "        var_dict['mt'] = {\n",
    "            'var': np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "                           (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000,\n",
    "            'bins': np.linspace(0, 300, 15+1),\n",
    "            'title': r'$m_T\\ [GeV]$',\n",
    "            'shift': '+0'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'metsig':\n",
    "        var_dict['metsig'] = {\n",
    "            'var': fb['met_tst_sig'],\n",
    "            'bins': np.linspace(0, 30, 15+1),\n",
    "            'title': r'$E_T^{miss}\\ significance$',\n",
    "            'shift': '*1'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'metsigres':\n",
    "        var_dict['metsigres'] = {\n",
    "            'var': fb['met_tst_et'] / fb['met_tst_sig'],\n",
    "            'bins': np.linspace(0, 100000, 50+1),\n",
    "            'title': r'$E_T^{miss}\\ significance$',\n",
    "            'shift': '*1'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'met':\n",
    "        var_dict['met'] = {\n",
    "            'var': fb['met_tst_et'],\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$E_T^{miss}\\ [MeV]$',\n",
    "            'shift': '+50000'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'met_noJVT':\n",
    "        var_dict['met_noJVT'] = {\n",
    "            'var': fb['met_tst_noJVT_et'],\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$E_T^{miss}\\ [MeV]$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'met_cst':\n",
    "        var_dict['met_cst'] = {\n",
    "            'var': fb['met_cst_et'],\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$E_T^{miss}\\ CST\\ [MeV]$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'met_track':\n",
    "        var_dict['met_track'] = {\n",
    "            'var': fb['met_track_et'],\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$E_T^{miss}\\ Track\\ [MeV]$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'dmet':\n",
    "        var_dict['dmet'] = {\n",
    "            'var': fb['met_tst_noJVT_et'] - fb['met_tst_et'],\n",
    "            'bins': np.linspace(-100000, 100000, 20+1),\n",
    "            'title': r'$E_{T,\\mathrm{noJVT}}^{miss}-E_T^{miss}\\ [MeV]$',\n",
    "            'shift': '*1'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'ph_pt':\n",
    "        var_dict['ph_pt'] = {\n",
    "            'var': ak.firsts(fb['ph_pt']),\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$p_T^{\\gamma}\\ [MeV]$',\n",
    "            'shift': '-150000'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'ph_eta':\n",
    "        var_dict['ph_eta'] = {\n",
    "            'var': np.abs(ak.firsts(fb['ph_eta'])),\n",
    "            'bins': np.linspace(0, 4, 16+1),\n",
    "            'title': r'$\\eta^{\\gamma}$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'ph_phi':\n",
    "        var_dict['ph_phi'] = {\n",
    "            'var': ak.firsts(fb['ph_phi']),\n",
    "            'bins': np.linspace(-4, 4, 50+1),\n",
    "            'title': r'$\\phi^{\\gamma}$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == \"jet_central_eta\":\n",
    "        jet_central_eta_tmp = ak.firsts(fb['jet_central_eta'])\n",
    "        var_dict['jet_central_eta'] = {\n",
    "            'var': ak.fill_none(jet_central_eta_tmp, -999),\n",
    "            'bins': np.linspace(-4, 4, 50+1), \n",
    "            'title': r'$\\eta^{\\mathrm{jets}}$'\n",
    "        }\n",
    "\n",
    "    # Jet central pt1 (first jet)\n",
    "    if var_name is None or var_name == \"jet_central_pt1\":\n",
    "        jet_central_pt1_tmp = ak.firsts(fb['jet_central_pt'])\n",
    "        var_dict['jet_central_pt1'] = {\n",
    "            'var': ak.fill_none(jet_central_pt1_tmp, -999),\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$p_T^{j1}\\ [MeV]$'\n",
    "        }\n",
    "\n",
    "    # Jet central pt2 (second jet, if available)\n",
    "    if var_name is None or var_name == \"jet_central_pt2\":\n",
    "        jet_central_pt2_tmp = ak.mask(fb['jet_central_pt'], ak.num(fb['jet_central_pt']) >= 2)[:, 1]\n",
    "        var_dict['jet_central_pt2'] = {\n",
    "            'var': ak.fill_none(jet_central_pt2_tmp, -999),\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$p_T^{j2}\\ [MeV]$'\n",
    "        }\n",
    "\n",
    "    # Jet central pt (all jets)\n",
    "    if var_name is None or var_name == \"jet_central_pt\":\n",
    "        weight_tmp = getWeight(fb, process)\n",
    "        expanded_weights = ak.flatten(ak.broadcast_arrays(weight_tmp, fb['jet_central_pt'])[0])\n",
    "        var_dict['jet_central_pt'] = {\n",
    "            'var': ak.flatten(fb['jet_central_pt']),\n",
    "            'weight': expanded_weights,\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$p_T^{j}\\ [MeV]$'\n",
    "    }\n",
    "\n",
    "    if var_name is None or var_name == 'dphi_met_phterm':\n",
    "        var_dict['dphi_met_phterm'] = {\n",
    "            'var': np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])),\n",
    "            'bins': np.linspace(0, 4, 16+1),\n",
    "            'title': r'$\\Delta\\phi(E_T^{miss},\\, E_T^{\\gamma})$',\n",
    "            'shift': '+0'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'dphi_met_ph':\n",
    "        var_dict['dphi_met_ph'] = {\n",
    "            'var': np.arccos(np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi']))),\n",
    "            'bins': np.linspace(0, 4, 50+1),\n",
    "            'title': r'$\\Delta\\phi(E_T^{miss},\\, E_T^{\\gamma})$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'dphi_met_jetterm':\n",
    "        var_dict['dphi_met_jetterm'] = {\n",
    "            'var': np.where(fb['met_jetterm_et'] != 0,\n",
    "                            np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                            -999),\n",
    "            'bins': np.linspace(0, 4, 16+1),\n",
    "            'title': r'$\\Delta\\phi(E_T^{miss},\\, E_T^{jet})$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'dphi_phterm_jetterm':\n",
    "        var_dict['dphi_phterm_jetterm'] = {\n",
    "            'var': np.where(fb['met_jetterm_et'] > 0,\n",
    "                            np.arccos(np.cos(fb['met_phterm_phi'] - fb['met_jetterm_phi'])),\n",
    "                            -999),\n",
    "            'bins': np.linspace(0, 4, 50+1),\n",
    "            'title': r'$\\Delta\\phi(E_T^{\\gamma},\\, E_T^{jet})$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'dphi_met_phterm_minus_dphi_met_jetterm':\n",
    "        var_dict['dphi_met_phterm_minus_dphi_met_jetterm'] = {\n",
    "            'var': np.where(fb['met_jetterm_et'] > 0,\n",
    "                            np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])) -\n",
    "                            np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                            -999),  \n",
    "            'bins': np.linspace(-4, 4, 100+1),\n",
    "            'title': r'$\\Delta\\phi(E_T^{miss},\\, E_T^{\\gamma})-\\Delta\\phi(E_T^{miss},\\, E_T^{jet})$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'dphi_met_phterm_divide_dphi_met_jetterm':\n",
    "        numerator_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi']))\n",
    "        denominator_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi']))\n",
    "        var_dict['dphi_met_phterm_divide_dphi_met_jetterm'] = {\n",
    "            'var': np.where((fb['met_jetterm_et'] > 0) & (denominator_tmp != 0),\n",
    "                            numerator_tmp / denominator_tmp,\n",
    "                            -999),  \n",
    "            'bins': np.linspace(-4, 4, 100+1),\n",
    "            'title': r'$\\Delta\\phi(E_T^{miss},\\, E_T^{\\gamma})/\\Delta\\phi(E_T^{miss},\\, E_T^{jet})$'\n",
    "        }\n",
    "\n",
    "\n",
    "    # Delta phi (photon vs. central jet1)\n",
    "    if var_name is None or var_name == 'dphi_ph_centraljet1':\n",
    "        dphi_ph_centraljet1_tmp = np.arccos(np.cos(ak.firsts(fb['ph_phi']) - ak.firsts(fb['jet_central_phi'])))\n",
    "        var_dict['dphi_ph_centraljet1'] = {\n",
    "            'var': ak.fill_none(dphi_ph_centraljet1_tmp, -999),\n",
    "            'bins': np.linspace(0, 4, 50+1),\n",
    "            'title': r'$\\Delta\\phi(\\gamma,\\, j1)$'\n",
    "        }\n",
    "\n",
    "    # # Delta phi (photon vs. jet1)\n",
    "    if var_name is None or var_name == 'dphi_ph_jet1':\n",
    "        dphi_ph_jet1_tmp = np.arccos(np.cos(ak.firsts(fb['ph_phi']) - ak.firsts(fb['jet_central_phi'])))\n",
    "        var_dict['dphi_ph_jet1'] = {\n",
    "            'var': ak.fill_none(dphi_ph_jet1_tmp, -999),\n",
    "            'bins': np.linspace(0, 4, 50+1),\n",
    "            'title': r'$\\Delta\\phi(\\gamma,\\, j1)$'\n",
    "        }\n",
    "\n",
    "    # # Delta phi (central jet1 vs. jet2) (repeated with dphi_jj)\n",
    "    # if var_name is None or var_name == 'dphi_central_jet1_jet2':\n",
    "    #     phi1_tmp = ak.firsts(fb['jet_central_phi'])\n",
    "    #     phi2_tmp = ak.mask(fb['jet_central_phi'], ak.num(fb['jet_central_phi']) >= 2)[:, 1]\n",
    "    #     dphi_central_tmp = np.arccos(np.cos(phi1_tmp - phi2_tmp))\n",
    "    #     var_dict['dphi_central_jet1_jet2'] = {\n",
    "    #         'var': ak.fill_none(dphi_central_tmp, -999),\n",
    "    #         'bins': np.linspace(0, 4, 50+1),\n",
    "    #         'title': r'$\\Delta\\phi(j1,\\, j2)$'\n",
    "    #     }\n",
    "\n",
    "    # Met plus photon pt\n",
    "    if var_name is None or var_name == 'metplusph':\n",
    "        var_dict['metplusph'] = {\n",
    "            'var': fb['met_tst_et'] + ak.firsts(fb['ph_pt']),\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$E_T^{miss}+p_T^{\\gamma}\\ [MeV]$'\n",
    "        }\n",
    "\n",
    "    # # Fail JVT jet pt (all)\n",
    "    if var_name is None or var_name == 'failJVT_jet_pt':\n",
    "        weight_tmp = getWeight(fb, process)\n",
    "        expanded_weights = ak.flatten(ak.broadcast_arrays(weight_tmp, fb['failJVT_jet_pt'])[0])\n",
    "        var_dict['failJVT_jet_pt'] = {\n",
    "            'var': ak.flatten(fb['failJVT_jet_pt']),\n",
    "            'weight': expanded_weights,\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$p_T^{\\mathrm{noJVT\\ jet}}\\ [MeV]$'\n",
    "        }\n",
    "\n",
    "    # # Fail JVT jet pt1 (first element)\n",
    "    if var_name is None or var_name == 'failJVT_jet_pt1':\n",
    "        failJVT_jet_pt_tmp = ak.firsts(fb['failJVT_jet_pt'])\n",
    "        var_dict['failJVT_jet_pt1'] = {\n",
    "            'var': ak.fill_none(failJVT_jet_pt_tmp, -999),\n",
    "            'bins': np.linspace(20000, 60000, 40+1),\n",
    "            'title': r'$p_T^{\\mathrm{noJVT\\ jet1}}\\ [MeV]$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'softerm':\n",
    "        var_dict['softerm'] = {\n",
    "            'var': fb['met_softerm_tst_et'],\n",
    "            'bins': np.linspace(0, 100000, 50+1),\n",
    "            'title': r'$E_T^{soft}\\ [MeV]$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'jetterm':\n",
    "        var_dict['jetterm'] = {\n",
    "            'var': fb['met_jetterm_et'],\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$E_T^{jet}\\ [MeV]$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'jetterm_sumet':\n",
    "        var_dict['jetterm_sumet'] = {\n",
    "            'var': fb['met_jetterm_sumet'],\n",
    "            'bins': np.linspace(0, 300000, 50+1),\n",
    "            'title': r'$E_T^{jet}\\ [MeV]$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'n_jet':\n",
    "        var_dict['n_jet'] = {\n",
    "            'var': fb['n_jet'],\n",
    "            'bins': np.linspace(0, 10, 10+1),\n",
    "            'title': r'$N_{jet}$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'n_jet_central':\n",
    "        var_dict['n_jet_central'] = {\n",
    "            'var': fb['n_jet_central'],\n",
    "            'bins': np.linspace(0, 10, 10+1),\n",
    "            'title': r'$N_{jet}^{central}$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'n_jet_fwd':\n",
    "        var_dict['n_jet_fwd'] = {\n",
    "            'var': fb['n_jet'] - fb['n_jet_central'],\n",
    "            'bins': np.linspace(0, 10, 10+1),\n",
    "            'title': r'$N_{jet}^{fwd}$'\n",
    "        }\n",
    "\n",
    "    # if var_name is None or var_name == 'vertex':\n",
    "    #     var_dict['vertex'] = {\n",
    "    #         'var': (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) == \n",
    "    #                 np.min(np.abs(ak.firsts(fb['pv_truth_z']) - fb['pv_z']))),\n",
    "    #         'bins': np.linspace(0, 2, 2+1),\n",
    "    #         'title': r'good PV'\n",
    "    #     }\n",
    "\n",
    "    if var_name is None or var_name == 'goodPV':\n",
    "        var_dict['goodPV'] = {\n",
    "            'var': (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5),\n",
    "            'bins': np.linspace(0, 2, 2+1),\n",
    "            'title': r'good PV'\n",
    "        }\n",
    "    # # Delta phi (met vs. central jet)\n",
    "    if var_name is None or var_name == 'dphi_met_central_jet':\n",
    "        dphi_met_central_jet_tmp = np.arccos(np.cos(fb['met_tst_phi'] - ak.firsts(fb['jet_central_phi'])))\n",
    "        var_dict['dphi_met_central_jet'] = {\n",
    "            'var': ak.fill_none(dphi_met_central_jet_tmp, -999),\n",
    "            'bins': np.linspace(0, 4, 50+1),\n",
    "            'title': r'$\\Delta\\phi(E_T^{miss},\\, jet)$'\n",
    "        }\n",
    "\n",
    "    # # Counts: constant 0.5 (typically used for normalization)\n",
    "    # var_dict['counts'] = {\n",
    "    #     'var': 0.5,\n",
    "    #     'bins': np.linspace(0, 1, 1+1),\n",
    "    #     'title': ''\n",
    "    # }\n",
    "\n",
    "    # # Jet central timing1\n",
    "    if var_name is None or var_name == 'jet_central_timing1':\n",
    "        jet_central_timing1_tmp = ak.firsts(fb['jet_central_timing'])\n",
    "        var_dict['jet_central_timing1'] = {\n",
    "            'var': ak.fill_none(jet_central_timing1_tmp, -999),\n",
    "            'bins': np.linspace(-40, 40, 50+1),\n",
    "            'title': r'$Jet\\ timing$'\n",
    "        }\n",
    "\n",
    "    # # Jet central timing (all)\n",
    "    if var_name is None or var_name == 'jet_central_timing':\n",
    "        weight_tmp = getWeight(fb, process)\n",
    "        expanded_weights = ak.flatten(ak.broadcast_arrays(weight_tmp, fb['jet_central_timing'])[0])\n",
    "        var_dict['jet_central_timing'] = {\n",
    "            'var': ak.flatten(fb['jet_central_timing']),\n",
    "            'weight': expanded_weights,\n",
    "            'bins': np.linspace(-40, 40, 50+1),\n",
    "            'title': r'$Jet\\ timing$'\n",
    "        }\n",
    "\n",
    "    # # Jet central EM fraction\n",
    "    if var_name is None or var_name == 'jet_central_emfrac':\n",
    "        weight_tmp = getWeight(fb, process)\n",
    "        expanded_weights = ak.flatten(ak.broadcast_arrays(weight_tmp, fb['jet_central_emfrac'])[0])\n",
    "        var_dict['jet_central_emfrac'] = {\n",
    "            'var': ak.flatten(fb['jet_central_emfrac']),\n",
    "            'bins': np.linspace(-1, 2, 50+1),\n",
    "            'title': r'$Jet\\ EM\\ fraction$'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'jet_central_emfrac':\n",
    "        jet_central_emfrac1_tmp = ak.firsts(fb['jet_central_emfrac'])\n",
    "        var_dict['jet_central_emfrac'] = {\n",
    "            'var': ak.fill_none(jet_central_emfrac1_tmp, -999),\n",
    "            'bins': np.linspace(-1, 2, 50+1),\n",
    "            'title': r'$Jet\\ EM\\ fraction$'\n",
    "        }\n",
    "\n",
    "\n",
    "    # Balance: (met_tst_et+ph_pt[0]) divided by the sum over jet_central_pt.\n",
    "    if var_name is None or var_name == 'balance':\n",
    "        jet_sum_tmp = ak.sum(fb['jet_central_pt'], axis=-1)\n",
    "        expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "        balance = ak.where(jet_sum_tmp != 0, expr, -999) \n",
    "\n",
    "        var_dict['balance'] = {\n",
    "            'var': balance,\n",
    "            'bins': np.linspace(0, 20, 100+1),\n",
    "            'title': r'balance'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'balance_sumet':\n",
    "        sumet_tmp = fb['met_jetterm_sumet']\n",
    "        expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(sumet_tmp != 0, sumet_tmp, 1)\n",
    "        balance_sumet = ak.where(sumet_tmp != 0, expr, -999)\n",
    "\n",
    "        var_dict['balance_sumet'] = {\n",
    "            'var': balance_sumet,\n",
    "            'bins': np.linspace(0, 80, 80+1),\n",
    "            'title': r'balance'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'central_jets_fraction':\n",
    "        var_dict['central_jets_fraction'] = {\n",
    "            'var': np.where(fb['n_jet'] > 0, fb['n_jet_central']/fb['n_jet'], -1),\n",
    "            'bins': np.linspace(-1, 2, 50+1),\n",
    "            'title': r'Central jets fraction'\n",
    "        }\n",
    "\n",
    "    if var_name is None or var_name == 'trigger':\n",
    "        var_dict['trigger'] = {\n",
    "            'var': fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M'],\n",
    "            'bins': np.linspace(0, 2, 2+1),\n",
    "            'title': r'Pass Trigger'\n",
    "        }\n",
    "\n",
    "    # dphi_jj: Use Alt$ logic – if jet_central_phi has at least two entries, compute the difference; else -1.\n",
    "    # Here we use a Python conditional (this assumes fb['jet_central_phi'] is an array with shape information).\n",
    "    if var_name is None or var_name == 'dphi_jj':\n",
    "        phi1_tmp = ak.firsts(fb['jet_central_phi'])\n",
    "        phi2_tmp = ak.mask(fb['jet_central_phi'], ak.num(fb['jet_central_phi']) >= 2)[:, 1]\n",
    "        dphi_tmp = np.arccos(np.cos(phi1_tmp - phi2_tmp))\n",
    "        var_dict['dphi_jj'] = {\n",
    "            'var': ak.fill_none(dphi_tmp, -999),\n",
    "            'bins': np.linspace(-1, 4, 20+1),\n",
    "            'title': r'$\\Delta\\phi(j1,\\, j2)$'\n",
    "        }\n",
    "    \n",
    "    if var_name is None or var_name == 'BDTScore':\n",
    "        var_dict['BDTScore'] = {\n",
    "            'var': fb['BDTScore'],\n",
    "            'bins': np.arange(0, 1+0.1, 0.1),\n",
    "            'title': 'BDTScore'\n",
    "        }\n",
    "    \n",
    "    return var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dijet_y.root\t\tggHyyd_y.root\tVHyyd_y.root   Zgamma_y.root\n",
      "gammajet_direct_y.root\tqqZHyyd_y.root\tWgamma_y.root  Zjets_y.root\n",
      "gammajet_frag_y.root\tVBFHyyd_y.root\tWjets_y.root\n"
     ]
    }
   ],
   "source": [
    "!ls /data/tmathew/ntups/mc23d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run',\n",
       " 'randomRunNumber',\n",
       " 'event',\n",
       " 'year',\n",
       " 'averageIntPerXing',\n",
       " 'actualIntPerXing',\n",
       " 'corAverageIntPerXing',\n",
       " 'corActualIntPerXing',\n",
       " 'trigger_HLT_g100_loose_L1EM22VHI',\n",
       " 'trigger_HLT_g100_loose_L1eEM26M',\n",
       " 'trigger_HLT_g100_loose_L1eEM28M',\n",
       " 'trigger_HLT_g120_loose_L1EM22VHI',\n",
       " 'trigger_HLT_g120_loose_L1eEM26M',\n",
       " 'trigger_HLT_g120_loose_L1eEM28MHLT_g25_loose_L1EM20VH',\n",
       " 'trigger_HLT_g140_loose_L1EM22VHI',\n",
       " 'trigger_HLT_g140_loose_L1eEM26M',\n",
       " 'trigger_HLT_g25_loose_L1eEM24L',\n",
       " 'trigger_HLT_g30_loose_L1EM20VH',\n",
       " 'trigger_HLT_g30_loose_L1eEM24L',\n",
       " 'trigger_HLT_g40_loose_L1EM20VH',\n",
       " 'trigger_HLT_g40_loose_L1eEM24L',\n",
       " 'trigger_HLT_g50_loose_L1EM20VH',\n",
       " 'trigger_HLT_g50_loose_L1eEM24L',\n",
       " 'trigger_HLT_g50_tight_xe40_cell_xe50_pfopufit_80mTAC_EM22VHI',\n",
       " 'trigger_HLT_g50_tight_xe40_cell_xe50_pfopufit_80mTAC_L1eEM26M',\n",
       " 'trigger_HLT_g50_tight_xe40_cell_xe60_pfopufit_80mTAC_EM22VHI',\n",
       " 'trigger_HLT_g50_tight_xe40_cell_xe60_pfopufit_80mTAC_L1eEM26M',\n",
       " 'trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_EM22VHI',\n",
       " 'trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M',\n",
       " 'trigger_HLT_g60_loose_L1EM22VHI',\n",
       " 'trigger_HLT_g60_loose_L1eEM26M',\n",
       " 'trigger_HLT_g60_loose_L1eEM28M',\n",
       " 'trigger_HLT_g80_loose_L1EM22VHI',\n",
       " 'trigger_HLT_g80_loose_L1eEM26M',\n",
       " 'trigger_HLT_g80_loose_L1eEM28M',\n",
       " 'trigger_HLT_g90_loose_xe90_cell_EM22VHI',\n",
       " 'trigger_HLT_xe55_cell_xe70_tcpufit_xe90_pfsum_vssk_L1XE50',\n",
       " 'trigger_HLT_xe55_cell_xe70_tcpufit_xe95_pfsum_cssk_L1XE50',\n",
       " 'trigger_HLT_xe60_cell_xe95_pfsum_cssk_L1XE50',\n",
       " 'trigger_HLT_xe65_cell_xe100_mhtpufit_pf_L1XE50',\n",
       " 'trigger_HLT_xe65_cell_xe105_mhtpufit_em_L1XE50',\n",
       " 'trigger_HLT_xe65_cell_xe90_pfopufit_L1XE50',\n",
       " 'trigger_HLT_xe75_cell_xe65_tcpufit_xe90_trkmht_L1XE50',\n",
       " 'trigger_HLT_xe80_cell_xe115_tcpufit_L1XE50',\n",
       " 'trigger_single_el',\n",
       " 'trigger_single_mu',\n",
       " 'trigger_diel',\n",
       " 'trigger_dimu',\n",
       " 'trigger_matched_el',\n",
       " 'trigger_matched_mu',\n",
       " 'mconly_weight',\n",
       " 'pu_weight',\n",
       " 'jvt_weight',\n",
       " 'el_SF_weight',\n",
       " 'mu_SF_weight',\n",
       " 'ph_baseline_SF_weight',\n",
       " 'ph_loose_SF_weight',\n",
       " 'n_jet',\n",
       " 'n_jet_central',\n",
       " 'n_jet_fwd',\n",
       " 'n_jet_failJVT',\n",
       " 'n_bjet',\n",
       " 'n_ph',\n",
       " 'n_ph_baseline',\n",
       " 'n_ph_loose',\n",
       " 'n_el',\n",
       " 'n_el_baseline',\n",
       " 'n_mu',\n",
       " 'n_mu_baseline',\n",
       " 'n_tau',\n",
       " 'n_tau_baseline',\n",
       " 'met_tst_sig',\n",
       " 'met_tst_noJVT_sig',\n",
       " 'met_tst_nomuon_sig',\n",
       " 'met_tst_std_sig',\n",
       " 'jet_vecSumPt',\n",
       " 'failJVT_jet_vecSumPt',\n",
       " 'jet_vecSumPhi',\n",
       " 'failJVT_jet_vecSumPhi',\n",
       " 'jet_vecSumEta',\n",
       " 'failJVT_jet_vecSumEta',\n",
       " 'jet_sumPt',\n",
       " 'failJVT_jet_sumPt',\n",
       " 'jet_central_vecSumPt',\n",
       " 'jet_central_vecSumPhi',\n",
       " 'jet_central_vecSumEta',\n",
       " 'jet_central_sumPt',\n",
       " 'jet_fwd_vecSumPt',\n",
       " 'jet_fwd_vecSumPhi',\n",
       " 'jet_fwd_vecSumEta',\n",
       " 'jet_fwd_sumPt',\n",
       " 'n_pv',\n",
       " 'pv_x',\n",
       " 'pv_y',\n",
       " 'pv_z',\n",
       " 'pv_type',\n",
       " 'pv_truth_z',\n",
       " 'pv_ntracks',\n",
       " 'vtx_sumPt',\n",
       " 'vtx_sumPt2',\n",
       " 'z_asym',\n",
       " 'z_kurt',\n",
       " 'z_skew',\n",
       " 'vtx_Phi',\n",
       " 'met_cst_et',\n",
       " 'met_cst_phi',\n",
       " 'met_cst_sumet',\n",
       " 'met_eleterm_et',\n",
       " 'met_eleterm_phi',\n",
       " 'met_eleterm_sumet',\n",
       " 'met_jetterm_et',\n",
       " 'met_jetterm_phi',\n",
       " 'met_jetterm_sumet',\n",
       " 'met_jetterm_cst_et',\n",
       " 'met_jetterm_cst_phi',\n",
       " 'met_jetterm_cst_sumet',\n",
       " 'met_jetterm_noJVT_et',\n",
       " 'met_jetterm_noJVT_phi',\n",
       " 'met_jetterm_noJVT_sumet',\n",
       " 'met_muonterm_et',\n",
       " 'met_muonterm_phi',\n",
       " 'met_muonterm_sumet',\n",
       " 'met_phterm_et',\n",
       " 'met_phterm_phi',\n",
       " 'met_phterm_sumet',\n",
       " 'met_softerm_cst_et',\n",
       " 'met_softerm_cst_phi',\n",
       " 'met_softerm_cst_sumet',\n",
       " 'met_softerm_noJVT_et',\n",
       " 'met_softerm_noJVT_phi',\n",
       " 'met_softerm_noJVT_sumet',\n",
       " 'met_softerm_tst_et',\n",
       " 'met_softerm_tst_phi',\n",
       " 'met_softerm_tst_sumet',\n",
       " 'met_track_et',\n",
       " 'met_track_phi',\n",
       " 'met_track_sumet',\n",
       " 'met_truth_et',\n",
       " 'met_truth_phi',\n",
       " 'met_truth_sumet',\n",
       " 'met_tst_et',\n",
       " 'met_tst_phi',\n",
       " 'met_tst_sumet',\n",
       " 'met_tst_noJVT_et',\n",
       " 'met_tst_noJVT_phi',\n",
       " 'met_tst_noJVT_sumet',\n",
       " 'met_tst_nomuon_et',\n",
       " 'met_tst_nomuon_phi',\n",
       " 'met_tst_nomuon_sumet',\n",
       " 'met_tst_std_et',\n",
       " 'met_tst_std_phi',\n",
       " 'met_tst_std_sumet',\n",
       " 'mu_pt',\n",
       " 'mu_eta',\n",
       " 'mu_phi',\n",
       " 'mu_charge',\n",
       " 'mu_truth_type',\n",
       " 'mu_truth_origin',\n",
       " 'el_pt',\n",
       " 'el_eta',\n",
       " 'el_phi',\n",
       " 'el_charge',\n",
       " 'el_author',\n",
       " 'el_isConv',\n",
       " 'el_truth_status',\n",
       " 'el_truth_type',\n",
       " 'el_truth_origin',\n",
       " 'el__zvx',\n",
       " 'el__zvx_err',\n",
       " 'failJVT_jet_pt',\n",
       " 'failJVT_jet_eta',\n",
       " 'failJVT_jet_phi',\n",
       " 'failJVT_jet_m',\n",
       " 'failJVT_jet_timing',\n",
       " 'failJVT_jet_emfrac',\n",
       " 'failJVT_jet_jvt',\n",
       " 'failJVT_jet_fjvt',\n",
       " 'failJVT_jet_isFwd',\n",
       " 'failJVT_jet_isBjet',\n",
       " 'failJVT_jet_PartonTruthLabelID',\n",
       " 'ph_pt',\n",
       " 'ph_eta',\n",
       " 'ph_eta2',\n",
       " 'ph_phi',\n",
       " 'ph_ptcone20',\n",
       " 'ph_topoetcone40',\n",
       " 'ph_isEM',\n",
       " 'ph_author',\n",
       " 'ph_isConv',\n",
       " 'ph_truth_type',\n",
       " 'ph_truth_origin',\n",
       " 'ph_pdgId',\n",
       " 'ph_ZVtx',\n",
       " 'ph_ZVtx_err',\n",
       " 'ph_truth_pt',\n",
       " 'ph_truth_eta',\n",
       " 'ph_truth_phi',\n",
       " 'ph_truth_status',\n",
       " 'ph_loose_pt',\n",
       " 'ph_loose_eta',\n",
       " 'ph_loose_eta2',\n",
       " 'ph_loose_phi',\n",
       " 'ph_loose_ptcone20',\n",
       " 'ph_loose_topoetcone40',\n",
       " 'ph_loose_isEM',\n",
       " 'ph_loose_author',\n",
       " 'ph_loose_isConv',\n",
       " 'ph_loose_truth_type',\n",
       " 'ph_loose_truth_origin',\n",
       " 'ph_loose_pdgId',\n",
       " 'tau_charge',\n",
       " 'tau_pt',\n",
       " 'tau_eta',\n",
       " 'tau_phi',\n",
       " 'year',\n",
       " 'mc_weight_sum',\n",
       " 'xsec_ami',\n",
       " 'filter_eff_ami',\n",
       " 'kfactor_ami',\n",
       " 'dmet',\n",
       " 'dphi_met_jetterm',\n",
       " 'dphi_met_phterm',\n",
       " 'dphi_met_eleterm',\n",
       " 'dphi_jj',\n",
       " 'm_jj',\n",
       " 'dphi_central_jj',\n",
       " 'm_central_jj',\n",
       " 'central_balance',\n",
       " 'vector_central_balance',\n",
       " 'vector_balance',\n",
       " 'balance',\n",
       " 'jet_central_pt',\n",
       " 'jet_central_eta',\n",
       " 'jet_central_phi',\n",
       " 'jet_central_m',\n",
       " 'jet_central_timing',\n",
       " 'jet_central_emfrac',\n",
       " 'jet_central_jvt',\n",
       " 'jet_central_isBjet',\n",
       " 'jet_central_PartonTruthLabelID',\n",
       " 'jet_fwd_pt',\n",
       " 'jet_fwd_eta',\n",
       " 'jet_fwd_phi',\n",
       " 'jet_fwd_m',\n",
       " 'jet_fwd_timing',\n",
       " 'jet_fwd_emfrac',\n",
       " 'jet_fwd_jvt',\n",
       " 'jet_fwd_isBjet',\n",
       " 'jet_fwd_PartonTruthLabelID']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/data/tmathew/ntups/mc23d/ggHyyd_y.root\"\n",
    "f = uproot.open(path)['nominal']\n",
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file:  /data/tmathew/ntups/mc23d/ggHyyd_y.root\n",
      "Unweighted Events before cut:  225374\n",
      "Weighted Events before cut:  22918.521\n",
      "Unweighted Events after cut:  3718\n",
      "Weighted Events after cut:  374.83685\n",
      "Number of none values:  0\n",
      "Reading Time for ggHyyd: 2.0794506072998047 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Zjets_y.root\n",
      "Unweighted Events before cut:  11544081\n",
      "Weighted Events before cut:  1739103.6\n",
      "Unweighted Events after cut:  13734\n",
      "Weighted Events after cut:  836.12915\n",
      "Number of none values:  0\n",
      "Reading Time for Zjets: 117.88662528991699 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Zgamma_y.root\n",
      "Unweighted Events before cut:  4341141\n",
      "Weighted Events before cut:  310120.2\n",
      "Unweighted Events after cut:  703070\n",
      "Weighted Events after cut:  16731.758\n",
      "Number of none values:  0\n",
      "Reading Time for Zgamma: 46.97585368156433 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Wgamma_y.root\n",
      "Unweighted Events before cut:  1772654\n",
      "Weighted Events before cut:  567686.56\n",
      "Unweighted Events after cut:  168005\n",
      "Weighted Events after cut:  15610.069\n",
      "Number of none values:  0\n",
      "Reading Time for Wgamma: 16.474576950073242 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Wjets_y.root\n",
      "Unweighted Events before cut:  3041984\n",
      "Weighted Events before cut:  3974293.0\n",
      "Unweighted Events after cut:  39784\n",
      "Weighted Events after cut:  15982.568\n",
      "Number of none values:  0\n",
      "Reading Time for Wjets: 33.076627016067505 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/gammajet_direct_y.root\n",
      "Unweighted Events before cut:  13721741\n",
      "Weighted Events before cut:  172729870.0\n",
      "Unweighted Events after cut:  1064444\n",
      "Weighted Events after cut:  59343.797\n",
      "Number of none values:  0\n",
      "Reading Time for gammajet_direct: 122.8248233795166 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/gammajet_frag_y.root\n",
      "Unweighted Events before cut:  9857767\n",
      "Weighted Events before cut:  148784560.0\n",
      "Unweighted Events after cut:  381716\n",
      "Weighted Events after cut:  118698.35\n",
      "Number of none values:  0\n",
      "Reading Time for gammajet_frag: 106.63794088363647 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/dijet_y.root\n",
      "Unweighted Events before cut:  2191941\n",
      "Weighted Events before cut:  23179661000.0\n",
      "Unweighted Events after cut:  178869\n",
      "Weighted Events after cut:  255957.62\n",
      "Number of none values:  0\n",
      "Reading Time for dijet: 28.85202169418335 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variables = [\n",
    "    \"actualIntPerXing\", \"failJVT_jet_pt\", \"jet_central_emfrac\", \"jet_central_eta\",\n",
    "    \"jet_central_phi\", \"jet_central_pt\", \"jet_central_timing\", \"met_cst_et\",\n",
    "    \"met_jetterm_et\", \"met_jetterm_phi\", \"met_jetterm_sumet\", \"met_phterm_phi\",\n",
    "    \"met_softerm_tst_et\", \"met_tst_et\", \"met_tst_noJVT_et\", \"met_tst_phi\",\n",
    "    \"met_tst_sig\", \"met_track_et\", \"n_ph\", \"n_ph_baseline\", \"n_el_baseline\",\n",
    "    \"n_mu_baseline\", \"n_jet\", \"n_jet_central\", \"n_tau_baseline\", \"ph_eta\",\n",
    "    \"ph_phi\", \"ph_pt\", \"pu_weight\", \"pv_truth_z\", \"pv_z\",\n",
    "    \"trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M\", \"vtx_sumPt\",\n",
    "    \"mconly_weight\", \"mc_weight_sum\", \"xsec_ami\", \"filter_eff_ami\", \"kfactor_ami\",\n",
    "    \"pu_weight\", \"jvt_weight\", \"event\"\n",
    "]\n",
    "ntuple_name = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct','gammajet_frag','dijet']\n",
    "ntuple_name_BDT = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct','gammajet_frag','dijets']\n",
    "\n",
    "tot = []\n",
    "data = pd.DataFrame()\n",
    "unweighted_bcut, weighted_bcut, unweighted_acut, weighted_acut = [], [], [], []\n",
    "\n",
    "def test(fb):\n",
    "    # checking if there are any none values\n",
    "    mask = ak.is_none(fb['met_tst_et'])\n",
    "    n_none = ak.sum(mask)\n",
    "    print(\"Number of none values: \", n_none)\n",
    "    # if n_none > 0:\n",
    "    #     fb = fb[~mask]\n",
    "    # print(\"Events after removing none values: \", len(fb), ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "\n",
    "# i = 0\n",
    "for i in range(len(ntuple_name)):\n",
    "    cut = []\n",
    "    start_time = time.time()\n",
    "    path = f\"/data/tmathew/ntups/mc23d/{ntuple_name[i]}_y.root\" \n",
    "    path_BDT = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/mc23d_{ntuple_name_BDT[i]}_y_BDT_score.root\" \n",
    "    print('processing file: ', path)\n",
    "    f = uproot.open(path)['nominal']\n",
    "    fb = f.arrays(variables, library=\"ak\")\n",
    "\n",
    "    # add BDT score to fb\n",
    "    f_BDT = uproot.open(path_BDT)['nominal']\n",
    "    fb_BDT = f_BDT.arrays([\"event\", \"BDTScore\"], library=\"ak\")\n",
    "    tmp = fb[\"event\"] == fb_BDT[\"event\"]\n",
    "    if np.all(tmp) == True:\n",
    "        fb[\"BDTScore\"] = fb_BDT[\"BDTScore\"]\n",
    "    else: \n",
    "        print(\"Something is wrong, need arranging\")\n",
    "    \n",
    "\n",
    "    print(\"Unweighted Events before cut: \", len(fb))\n",
    "    print(\"Weighted Events before cut: \", sum(getWeight(fb, ntuple_name[i])))\n",
    "    unweighted_bcut.append(len(fb))\n",
    "    weighted_bcut.append(sum(getWeight(fb, ntuple_name[i])))\n",
    "\n",
    "\n",
    "    fb = fb[fb['n_ph_baseline'] == 1]\n",
    "    fb = fb[fb['n_ph'] == 1]\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    fb = fb[fb['n_el_baseline'] == 0]\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M']==1]\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0] # prevent none values in Tbranch\n",
    "    fb = fb[fb['met_tst_et'] >= 100000] # MET cut (basic cut)\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) >= 50000] # ph_pt cut (basic cut)\n",
    "    fb = fb[fb['n_jet_central'] <= 4] # n_jet_central cut (basic cut)\n",
    "\n",
    "    # goodPV on signal only\n",
    "    if ntuple_name[i] == 'ggHyyd':\n",
    "        fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "        good_pv_tmp = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "        fb = fb[good_pv_tmp]\n",
    "\n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "                            (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    mask1 = mt_tmp >= 100 # trigger cut\n",
    "    fb = fb[mask1]\n",
    "    cut.append(len(fb))\n",
    "\n",
    "    fb = fb[fb['BDTScore'] >= 0.1] # added cut 1\n",
    "    cut.append(len(fb))\n",
    "\n",
    "    print(\"Unweighted Events after cut: \", len(fb))\n",
    "    print(\"Weighted Events after cut: \", sum(getWeight(fb, ntuple_name[i])))\n",
    "    test(fb) # check for none value\n",
    "\n",
    "    print(f\"Reading Time for {ntuple_name[i]}: {(time.time()-start_time)} seconds\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    tot.append(fb)\n",
    "\n",
    "    fb = 0\n",
    "    fb_BDT = 0\n",
    "    tmp = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_BDTScore_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_balance_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_balance_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dmet_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dmet_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dphi_jj_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dphi_met_phterm_minus_dphi_met_jetterm_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dphi_met_phterm_minus_dphi_met_jetterm_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dphi_met_jetterm_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dphi_met_jetterm_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dphi_met_phterm_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dphi_met_phterm_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dphi_ph_centraljet1_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dphi_ph_centraljet1_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dphi_phterm_jetterm_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_dphi_phterm_jetterm_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_met_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_met_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_metsig_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_metsig_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_mt_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_mt_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_n_jet_central_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_ph_eta_uppercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_ph_pt_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_dphi_met_jettermcut/significance_ph_pt_uppercut.png\n"
     ]
    }
   ],
   "source": [
    "def sel(tot):\n",
    "    tot2 = []\n",
    "    for i in range(len(tot)):\n",
    "        fb2 = tot[i]\n",
    "\n",
    "        \n",
    "        dphi_met_phterm_minus_dphi_met_jetterm_tmp =  np.where(fb2['met_jetterm_et'] > 0,\n",
    "                            np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_phterm_phi'])) -\n",
    "                            np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_jetterm_phi'])),\n",
    "                            -999)\n",
    "        mask1 = dphi_met_phterm_minus_dphi_met_jetterm_tmp >= 0.8\n",
    "        mask2 = dphi_met_phterm_minus_dphi_met_jetterm_tmp == -999\n",
    "        fb2 = fb2[mask1 | mask2]\n",
    "\n",
    "        jet_sum_tmp = ak.sum(fb2['jet_central_pt'], axis=-1)\n",
    "        expr = (fb2['met_tst_et'] + ak.firsts(fb2['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "        balance_tmp = ak.where(jet_sum_tmp != 0, expr, -999)\n",
    "        mask1 = balance_tmp >= 0.8\n",
    "        mask2 = balance_tmp == -999\n",
    "        fb2 = fb2[mask1 | mask2]\n",
    "        \n",
    "        metsig_tmp = fb2['met_tst_sig'] \n",
    "        mask1 = metsig_tmp >= 5\n",
    "        mask2 = metsig_tmp <= 13\n",
    "        fb2 = fb2[mask1 * mask2]\n",
    "        \n",
    "        ph_eta_tmp = np.abs(ak.firsts(fb2['ph_eta']))\n",
    "        fb2 = fb2[ph_eta_tmp <= 1.75]\n",
    "\n",
    "        # dphi_met_phterm_tmp = np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_phterm_phi'])) # added cut 3\n",
    "        # fb2 = fb2[dphi_met_phterm_tmp >= 1.40]\n",
    "\n",
    "        dmet_tmp = fb2['met_tst_noJVT_et'] - fb2['met_tst_et']\n",
    "        mask1 = dmet_tmp >= -20000\n",
    "        mask2 = dmet_tmp <= 50000\n",
    "        fb2 = fb2[mask1 * mask2]\n",
    "\n",
    "        phi1_tmp = ak.firsts(fb2['jet_central_phi']) # added cut 7\n",
    "        phi2_tmp = ak.mask(fb2['jet_central_phi'], ak.num(fb2['jet_central_phi']) >= 2)[:, 1] \n",
    "        dphi_tmp = np.arccos(np.cos(phi1_tmp - phi2_tmp))\n",
    "        dphi_jj_tmp = ak.fill_none(dphi_tmp, -999)\n",
    "        fb2 = fb2[dphi_jj_tmp <= 2.3]\n",
    "\n",
    "        dphi_met_jetterm_tmp = np.where(fb2['met_jetterm_et'] != 0,   # added cut 5\n",
    "                            np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_jetterm_phi'])),\n",
    "                            -999)\n",
    "        fb2 = fb2[dphi_met_jetterm_tmp <= 0.75]\n",
    "\n",
    "        # mt_tmp = np.sqrt(2 * fb2['met_tst_et'] * ak.firsts(fb2['ph_pt']) * \n",
    "        #                     (1 - np.cos(fb2['met_tst_phi'] - ak.firsts(fb2['ph_phi'])))) / 1000\n",
    "        # mask1 = mt_tmp >= 95\n",
    "        # fb2 = fb2[mask1]\n",
    "\n",
    "        \n",
    "        tot2.append(fb2)\n",
    "    return tot2\n",
    "\n",
    "tot2 = sel(tot)\n",
    "# tot2 = tot\n",
    "\n",
    "signal_name = 'ggHyyd'  # Define signal dataset\n",
    "cut_name = 'dphi_met_jetterm'\n",
    "\n",
    "def getCutDict():\n",
    "    cut_dict = {}\n",
    "\n",
    "    cut_dict['BDTScore'] = {\n",
    "        'lowercut': np.arange(0, 0.4+0.1, 0.1) # BDTScore > cut\n",
    "    }\n",
    "    cut_dict['balance'] = {\n",
    "        'lowercut': np.arange(0, 1.5 + 0.05, 0.05), # balance > cut\n",
    "        'uppercut': np.arange(5, 8 + 0.2, 0.2) # balance < cut\n",
    "    }\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 0 + 5000, 5000), # dmet > cut\n",
    "        'uppercut': np.arange(10000, 100000 + 5000, 5000), # -10000 < dmet < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.1 + 0.1, 0.1) # dphi_jj < cut\n",
    "    }\n",
    "    cut_dict['dphi_met_phterm_minus_dphi_met_jetterm'] = {\n",
    "        'lowercut': np.arange(0, 1.5+0.05, 0.05),\n",
    "        'uppercut': np.arange(1.5, 3.1+0.05, 0.05)\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'lowercut': np.arange(0, 1 + 0.05, 0.05), # dphi_met_jetterm > cut \n",
    "        'uppercut': np.arange(0.5, 2 + 0.05, 0.05), # dphi_met_jetterm < cut \n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(1, 2 + 0.05, 0.05), # dphi_met_phterm > cut\n",
    "        'uppercut': np.arange(2, 3.1 + 0.1, 0.1), # dphi_met_phterm < cut\n",
    "    }\n",
    "    cut_dict['dphi_ph_centraljet1'] = {\n",
    "        'lowercut': np.arange(0, 2.5 + 0.1, 0.1), # dphi_ph_centraljet1 > cut\n",
    "        'uppercut': np.arange(1.5, 3.1 + 0.1, 0.1) # dphi_ph_centraljet1 < cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.05, 0.05), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['met'] = {\n",
    "        'lowercut': np.arange(100000, 140000 + 5000, 5000),  # met > cut\n",
    "        'uppercut': np.arange(140000, 300000 + 5000, 5000),  # met < cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "    }\n",
    "    cut_dict['mt'] = {\n",
    "        'lowercut': np.arange(80, 130+5, 5), # mt > cut\n",
    "        'uppercut': np.arange(120, 230+5, 5) # mt < cut\n",
    "    }\n",
    "    cut_dict['n_jet_central'] = {\n",
    "        'uppercut': np.arange(0, 8+1, 1) # njet < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.05, 0.05), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['ph_pt'] = {\n",
    "        'lowercut': np.arange(50000, 100000 + 5000, 5000),  # ph_pt > cut\n",
    "        'uppercut': np.arange(100000, 300000 + 10000, 10000),  # ph_pt > cut\n",
    "    }\n",
    "\n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "\n",
    "def calculate_significance(cut_var, cut_type, cut_values):\n",
    "    significance_values = []\n",
    "    significance_acceptance_values = []\n",
    "    acceptance_values = []  # Store acceptance percentages\n",
    "\n",
    "    for cut in cut_values:\n",
    "        sig_after_cut = 0\n",
    "        bkg_after_cut = []\n",
    "        sig_events = 0\n",
    "        \n",
    "        for i in range(len(ntuple_name)-1): # not include dijet\n",
    "            fb = tot2[i]\n",
    "            process = ntuple_name[i]\n",
    "            var_config = getVarDict(fb, process, var_name=cut_var)\n",
    "            x = var_config[cut_var]['var']\n",
    "            mask = x != -999 # Apply cut: Remove -999 values \n",
    "            x = x[mask]\n",
    "\n",
    "            if process == signal_name:\n",
    "                sig_events = getWeight(fb, process)\n",
    "                sig_events = sig_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                sig_after_cut = ak.sum(sig_events[mask])\n",
    "            \n",
    "            else:\n",
    "                bkg_events = getWeight(fb, process)\n",
    "                bkg_events = bkg_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                bkg_after_cut.append(ak.sum(bkg_events[mask]))\n",
    "\n",
    "        # Calculate significance\n",
    "        significance = sig_after_cut / np.sqrt(sum(bkg_after_cut)) if sum(bkg_after_cut) > 0 else 0\n",
    "\n",
    "        # Acceptance: ratio of surviving signal events\n",
    "        acceptance = sig_after_cut / sum(sig_events) if sum(sig_events) > 0 else 0\n",
    "        acceptance_values.append(acceptance * 100)  # Convert to percentage\n",
    "\n",
    "        significance_values.append(significance)\n",
    "        significance_acceptance_values.append(significance * acceptance)\n",
    "\n",
    "    return significance_values, significance_acceptance_values, acceptance_values\n",
    "\n",
    "# Compute significance for each variable dynamically\n",
    "for cut_var, cut_types in cut_config.items():\n",
    "    for cut_type, cut_values in cut_types.items():\n",
    "        significance_values, significance_acceptance_values, acceptance_values = calculate_significance(cut_var, cut_type, cut_values)\n",
    "\n",
    "        # # Reverse order for uppercut plots\n",
    "        # if cut_type == 'uppercut':\n",
    "        #     cut_values = cut_values[::-1]\n",
    "        #     significance_values = significance_values[::-1]\n",
    "        #     significance_acceptance_values = significance_acceptance_values[::-1]\n",
    "        #     acceptance_values = acceptance_values[::-1]\n",
    "\n",
    "        # Plot results\n",
    "        fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "\n",
    "        # Top plot: Significance vs. Cut\n",
    "        ax_top.plot(cut_values, significance_values, marker='o', label='Significance')\n",
    "        ax_top.set_ylabel('Significance')\n",
    "        ax_top.set_title(f'Significance vs. {cut_var} ({cut_type})')\n",
    "        ax_top.legend()\n",
    "        ax_top.grid(True)\n",
    "\n",
    "        # Bottom plot: Significance * Acceptance vs. Cut\n",
    "        ax_bot.plot(cut_values, significance_acceptance_values, marker='s', color='r', label='Significance × Acceptance')\n",
    "        for i, txt in enumerate(acceptance_values):\n",
    "            ax_bot.text(cut_values[i], significance_acceptance_values[i], f'{txt:.1f}%', \n",
    "                        fontsize=10, ha='right', va='bottom', color='purple')\n",
    "            \n",
    "        ax_bot.set_xlabel(f'{cut_var} Cut')\n",
    "        ax_bot.set_ylabel('Significance × Acceptance')\n",
    "        ax_bot.set_title(f'Significance × Acceptance vs. {cut_var} ({cut_type})')\n",
    "        \n",
    "        ax_bot.set_xticks(cut_values)\n",
    "        ax_bot.set_xticklabels(ax_bot.get_xticks(), rotation=45, ha='right')\n",
    "        ax_bot.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "        # ax_bot.xaxis.set_major_locator(ticker.MaxNLocator(nbins=15))  # Show at most 10 x-ticks\n",
    "        \n",
    "        var_configs_tmp = getVarDict(tot2[0], signal_name, cut_var)\n",
    "        ax_bot.set_xlabel(var_configs_tmp[cut_var]['title'])\n",
    "        ax_bot.legend()\n",
    "        ax_bot.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../test/dphi_diff/mc23d_{cut_name}cut/significance_{cut_var}_{cut_type}.png\")\n",
    "        print(f\"Successfully saved to ../test/dphi_diff/mc23d_{cut_name}cut/significance_{cut_var}_{cut_type}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217.16342\n",
      "66.28701\n",
      "1035.5365\n",
      "1800.9478\n",
      "1516.7921\n",
      "388.34274\n",
      "719.6864\n",
      "60.150063\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ntuple_name)):\n",
    "    fb_tmp = tot2[i]\n",
    "    print(sum(getWeight(fb_tmp, ntuple_name[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-1 Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_dphi_met_phterm_minus_dphi_met_jetterm_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_dphi_met_phterm_minus_dphi_met_jetterm_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n",
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to dphi_diff/mc23d_n-1cut/dphi_met_phterm_minus_dphi_met_jetterm_nodijet.png\n",
      "successfully saved to ../test/dphi_diff/mc23d_n-1cut/roc_curve_dphi_met_phterm_minus_dphi_met_jetterm.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_balance_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_balance_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n",
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to dphi_diff/mc23d_n-1cut/balance_nodijet.png\n",
      "successfully saved to ../test/dphi_diff/mc23d_n-1cut/roc_curve_balance.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_metsig_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_metsig_uppercut.png\n",
      "successfully saved to dphi_diff/mc23d_n-1cut/metsig_nodijet.png\n",
      "successfully saved to ../test/dphi_diff/mc23d_n-1cut/roc_curve_metsig.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_ph_eta_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to dphi_diff/mc23d_n-1cut/ph_eta_nodijet.png\n",
      "successfully saved to ../test/dphi_diff/mc23d_n-1cut/roc_curve_ph_eta.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_dmet_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_dmet_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to dphi_diff/mc23d_n-1cut/dmet_nodijet.png\n",
      "successfully saved to ../test/dphi_diff/mc23d_n-1cut/roc_curve_dmet.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_dphi_jj_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to dphi_diff/mc23d_n-1cut/dphi_jj_nodijet.png\n",
      "successfully saved to ../test/dphi_diff/mc23d_n-1cut/roc_curve_dphi_jj.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_dphi_met_jetterm_lowercut.png\n",
      "Successfully saved to ../test/dphi_diff/mc23d_n-1cut/significance_dphi_met_jetterm_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to dphi_diff/mc23d_n-1cut/dphi_met_jetterm_nodijet.png\n",
      "successfully saved to ../test/dphi_diff/mc23d_n-1cut/roc_curve_dphi_met_jetterm.png\n"
     ]
    }
   ],
   "source": [
    "n_1_config = [\"dphi_met_phterm_minus_dphi_met_jetterm\", \"balance\", \"metsig\", \"ph_eta\", \"dmet\",  \"dphi_jj\", \"dphi_met_jetterm\"]\n",
    "\n",
    "def sel(tot, n_1_name=None):\n",
    "    tot2 = []\n",
    "    for i in range(len(tot)):\n",
    "        fb2 = tot[i]\n",
    "\n",
    "        if n_1_name != \"dphi_met_phterm_minus_dphi_met_jetterm\":\n",
    "            dphi_met_phterm_minus_dphi_met_jetterm_tmp =  np.where(fb2['met_jetterm_et'] > 0,\n",
    "                                np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_phterm_phi'])) -\n",
    "                                np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_jetterm_phi'])),\n",
    "                                -999)\n",
    "            mask1 = dphi_met_phterm_minus_dphi_met_jetterm_tmp >= 0.80\n",
    "            mask2 = dphi_met_phterm_minus_dphi_met_jetterm_tmp == -999\n",
    "            fb2 = fb2[mask1 | mask2]\n",
    "\n",
    "        if n_1_name != \"balance\":\n",
    "            jet_sum_tmp = ak.sum(fb2['jet_central_pt'], axis=-1)\n",
    "            expr = (fb2['met_tst_et'] + ak.firsts(fb2['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "            balance_tmp = ak.where(jet_sum_tmp != 0, expr, -999)\n",
    "            mask1 = balance_tmp >= 0.8\n",
    "            mask2 = balance_tmp == -999\n",
    "            fb2 = fb2[mask1 | mask2]\n",
    "\n",
    "        if n_1_name != \"metsig\":\n",
    "            metsig_tmp = fb2['met_tst_sig'] \n",
    "            mask1 = metsig_tmp >= 5\n",
    "            mask2 = metsig_tmp <= 13\n",
    "            fb2 = fb2[mask1 * mask2]\n",
    "        \n",
    "        if n_1_name != \"ph_eta\":\n",
    "            ph_eta_tmp = np.abs(ak.firsts(fb2['ph_eta']))\n",
    "            fb2 = fb2[ph_eta_tmp <= 1.75]\n",
    "\n",
    "        # dphi_met_phterm_tmp = np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_phterm_phi'])) # added cut 3\n",
    "        # fb2 = fb2[dphi_met_phterm_tmp >= 1.40]\n",
    "\n",
    "        if n_1_name != \"dmet\":\n",
    "            dmet_tmp = fb2['met_tst_noJVT_et'] - fb2['met_tst_et']\n",
    "            mask1 = dmet_tmp >= -20000\n",
    "            mask2 = dmet_tmp <= 50000\n",
    "            fb2 = fb2[mask1 * mask2]\n",
    "\n",
    "        if n_1_name != \"dphi_met_jetterm\":\n",
    "            dphi_met_jetterm_tmp = np.where(fb2['met_jetterm_et'] != 0,   # added cut 5\n",
    "                                    np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_jetterm_phi'])),\n",
    "                                    -999)\n",
    "            fb2 = fb2[dphi_met_jetterm_tmp <= 0.75]\n",
    "\n",
    "        if n_1_name != \"dphi_jj\":\n",
    "            phi1_tmp = ak.firsts(fb2['jet_central_phi']) # added cut 7\n",
    "            phi2_tmp = ak.mask(fb2['jet_central_phi'], ak.num(fb2['jet_central_phi']) >= 2)[:, 1] \n",
    "            dphi_tmp = np.arccos(np.cos(phi1_tmp - phi2_tmp))\n",
    "            dphi_jj_tmp = ak.fill_none(dphi_tmp, -999)\n",
    "            fb2 = fb2[dphi_jj_tmp <= 2.3]\n",
    "\n",
    "\n",
    "        # mt_tmp = np.sqrt(2 * fb2['met_tst_et'] * ak.firsts(fb2['ph_pt']) * \n",
    "        #                     (1 - np.cos(fb2['met_tst_phi'] - ak.firsts(fb2['ph_phi'])))) / 1000\n",
    "        # mask1 = mt_tmp >= 95\n",
    "        # fb2 = fb2[mask1]\n",
    "\n",
    "\n",
    "        \n",
    "        tot2.append(fb2)\n",
    "    return tot2\n",
    "\n",
    "# tot2 = sel(tot)\n",
    "# tot2 = tot\n",
    "\n",
    "signal_name = 'ggHyyd'  # Define signal dataset\n",
    "cut_name = 'n-1'\n",
    "\n",
    "def getCutDict(n_1_name=None):\n",
    "    cut_dict = {}\n",
    "\n",
    "    if n_1_name is None or n_1_name == \"BDTScore\":\n",
    "        cut_dict['BDTScore'] = {\n",
    "            'lowercut': np.arange(0, 0.4+0.1, 0.1) # BDTScore > cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"balance\":\n",
    "        cut_dict['balance'] = {\n",
    "            'lowercut': np.arange(0, 1.5 + 0.05, 0.05), # balance > cut\n",
    "            'uppercut': np.arange(5, 8 + 0.2, 0.2) # balance < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dmet\":\n",
    "        cut_dict['dmet'] = {\n",
    "            'lowercut': np.arange(-30000, 0 + 5000, 5000), # dmet > cut\n",
    "            'uppercut': np.arange(10000, 100000 + 5000, 5000), # -10000 < dmet < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_jj\":\n",
    "        cut_dict['dphi_jj'] = {\n",
    "            'uppercut': np.arange(1, 3.1 + 0.1, 0.1) # dphi_jj < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_phterm_minus_dphi_met_jetterm\":\n",
    "        cut_dict['dphi_met_phterm_minus_dphi_met_jetterm'] = {\n",
    "            'lowercut': np.arange(0, 1.5+0.05, 0.05),\n",
    "            'uppercut': np.arange(1.5, 3.1+0.05, 0.05)\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_jetterm\":\n",
    "        cut_dict['dphi_met_jetterm'] = {\n",
    "            'lowercut': np.arange(0, 1 + 0.05, 0.05), # dphi_met_jetterm > cut \n",
    "            'uppercut': np.arange(0.5, 2 + 0.05, 0.05), # dphi_met_jetterm < cut \n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_phterm\":\n",
    "        cut_dict['dphi_met_phterm'] = {\n",
    "            'lowercut': np.arange(1, 2 + 0.05, 0.05), # dphi_met_phterm > cut\n",
    "            'uppercut': np.arange(2, 3.1 + 0.1, 0.1), # dphi_met_phterm < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_ph_centraljet1\":\n",
    "        cut_dict['dphi_ph_centraljet1'] = {\n",
    "            'lowercut': np.arange(0, 2.5 + 0.1, 0.1), # dphi_ph_centraljet1 > cut\n",
    "            'uppercut': np.arange(1.5, 3.1 + 0.1, 0.1) # dphi_ph_centraljet1 < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_phterm_jetterm\":\n",
    "        cut_dict['dphi_phterm_jetterm'] = {\n",
    "            'lowercut': np.arange(1, 2.5 + 0.05, 0.05), # dphi_phterm_jetterm > cut\n",
    "            'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"met\":\n",
    "        cut_dict['met'] = {\n",
    "            'lowercut': np.arange(100000, 140000 + 5000, 5000),  # met > cut\n",
    "            'uppercut': np.arange(140000, 300000 + 5000, 5000),  # met < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"metsig\":\n",
    "        cut_dict['metsig'] = {\n",
    "            'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "            'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"mt\":\n",
    "        cut_dict['mt'] = {\n",
    "            'lowercut': np.arange(80, 130+5, 5), # mt > cut\n",
    "            'uppercut': np.arange(120, 230+5, 5) # mt < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"n_jet_central\":\n",
    "        cut_dict['n_jet_central'] = {\n",
    "            'uppercut': np.arange(0, 8+1, 1) # njet < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"ph_eta\":\n",
    "        cut_dict['ph_eta'] = {\n",
    "            'uppercut': np.arange(1, 2.5 + 0.05, 0.05), # ph_eta < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"ph_pt\":\n",
    "        cut_dict['ph_pt'] = {\n",
    "            'lowercut': np.arange(50000, 100000 + 5000, 5000),  # ph_pt > cut\n",
    "            'uppercut': np.arange(100000, 300000 + 10000, 10000),  # ph_pt > cut\n",
    "        }\n",
    "\n",
    "    return cut_dict\n",
    "\n",
    "\n",
    "def calculate_significance(cut_var, cut_type, cut_values, tot2):\n",
    "    significance_values = []\n",
    "    significance_acceptance_values = []\n",
    "    acceptance_values = []  # Store acceptance percentages\n",
    "\n",
    "    for cut in cut_values:\n",
    "        sig_after_cut = 0\n",
    "        bkg_after_cut = []\n",
    "        sig_events = 0\n",
    "        \n",
    "        for i in range(len(ntuple_name)-1): # not include dijet\n",
    "            fb = tot2[i]\n",
    "            process = ntuple_name[i]\n",
    "            var_config = getVarDict(fb, process, var_name=cut_var)\n",
    "            x = var_config[cut_var]['var']\n",
    "            mask = x != -999 # Apply cut: Remove -999 values \n",
    "            x = x[mask]\n",
    "\n",
    "            if process == signal_name:\n",
    "                sig_events = getWeight(fb, process)\n",
    "                sig_events = sig_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                sig_after_cut = ak.sum(sig_events[mask])\n",
    "            \n",
    "            else:\n",
    "                bkg_events = getWeight(fb, process)\n",
    "                bkg_events = bkg_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                bkg_after_cut.append(ak.sum(bkg_events[mask]))\n",
    "\n",
    "        # Calculate significance\n",
    "        significance = sig_after_cut / np.sqrt(sum(bkg_after_cut)) if sum(bkg_after_cut) > 0 else 0\n",
    "\n",
    "        # Acceptance: ratio of surviving signal events\n",
    "        acceptance = sig_after_cut / sum(sig_events) if sum(sig_events) > 0 else 0\n",
    "        acceptance_values.append(acceptance * 100)  # Convert to percentage\n",
    "\n",
    "        significance_values.append(significance)\n",
    "        significance_acceptance_values.append(significance * acceptance)\n",
    "\n",
    "    return significance_values, significance_acceptance_values, acceptance_values\n",
    "\n",
    "for cut_var_tmp in n_1_config:\n",
    "    cut_config = getCutDict(n_1_name=cut_var_tmp)\n",
    "    tot2 = sel(tot, n_1_name=cut_var_tmp)\n",
    "    for cut_var, cut_types in cut_config.items():\n",
    "        for cut_type, cut_values in cut_types.items():\n",
    "            significance_values, significance_acceptance_values, acceptance_values = calculate_significance(cut_var, cut_type, cut_values, tot2)\n",
    "\n",
    "            # Plot results\n",
    "            fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "\n",
    "            # Top plot: Significance vs. Cut\n",
    "            ax_top.plot(cut_values, significance_values, marker='o', label='Significance')\n",
    "            ax_top.set_ylabel('Significance')\n",
    "            ax_top.set_title(f'Significance vs. {cut_var} ({cut_type})')\n",
    "            ax_top.legend()\n",
    "            ax_top.grid(True)\n",
    "\n",
    "            # Bottom plot: Significance * Acceptance vs. Cut\n",
    "            ax_bot.plot(cut_values, significance_acceptance_values, marker='s', color='r', label='Significance × Acceptance')\n",
    "            for i, txt in enumerate(acceptance_values):\n",
    "                ax_bot.text(cut_values[i], significance_acceptance_values[i], f'{txt:.1f}%', \n",
    "                            fontsize=10, ha='right', va='bottom', color='purple')\n",
    "                \n",
    "            ax_bot.set_xlabel(f'{cut_var} Cut')\n",
    "            ax_bot.set_ylabel('Significance × Acceptance')\n",
    "            ax_bot.set_title(f'Significance × Acceptance vs. {cut_var} ({cut_type})')\n",
    "            \n",
    "            ax_bot.set_xticks(cut_values)\n",
    "            ax_bot.set_xticklabels(ax_bot.get_xticks(), rotation=45, ha='right')\n",
    "            ax_bot.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            # ax_bot.xaxis.set_major_locator(ticker.MaxNLocator(nbins=15))  # Show at most 10 x-ticks\n",
    "            \n",
    "            var_configs_tmp = getVarDict(tot2[0], signal_name, cut_var)\n",
    "            ax_bot.set_xlabel(var_configs_tmp[cut_var]['title'])\n",
    "            ax_bot.legend()\n",
    "            ax_bot.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"../test/dphi_diff/mc23d_{cut_name}cut/significance_{cut_var}_{cut_type}.png\")\n",
    "            print(f\"Successfully saved to ../test/dphi_diff/mc23d_{cut_name}cut/significance_{cut_var}_{cut_type}.png\")\n",
    "            plt.close()\n",
    "\n",
    "    var_config = getVarDict(tot2[0], 'ggHyyd', var_name=cut_var_tmp)\n",
    "\n",
    "    for var in var_config:\n",
    "        bg_values = []     \n",
    "        bg_weights = []    \n",
    "        bg_colors = []     \n",
    "        bg_labels = []     \n",
    "\n",
    "        signal_values = [] \n",
    "        signal_weights = []\n",
    "        signal_color = None \n",
    "        signal_label = None\n",
    "\n",
    "        for j in range(len(ntuple_name)-1): # leave dijet out\n",
    "            process = ntuple_name[j]\n",
    "            fb = tot2[j]  # TTree\n",
    "            var_config = getVarDict(fb, process, var_name=var)\n",
    "\n",
    "            x = var_config[var]['var'] # TBranch\n",
    "            bins = var_config[var]['bins'] \n",
    "\n",
    "            if 'weight' in var_config[var]:  # If weight is there\n",
    "                weights = var_config[var]['weight']\n",
    "            else:\n",
    "                weights = getWeight(fb, process)\n",
    "            \n",
    "            sample_info = sample_dict[process]\n",
    "            color = sample_info['color']\n",
    "            legend = sample_info['legend']\n",
    "\n",
    "            \n",
    "            if process == 'ggHyyd':  # signal\n",
    "                signal_values.append(x)\n",
    "                signal_weights.append(weights)\n",
    "                signal_color = color\n",
    "                signal_label = legend\n",
    "            else:   # background\n",
    "                bg_values.append(x)\n",
    "                bg_weights.append(weights)\n",
    "                bg_colors.append(color)\n",
    "                bg_labels.append(legend)\n",
    "\n",
    "        fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(12, 13), gridspec_kw={'height_ratios': [9, 4]})\n",
    "\n",
    "        ax_top.hist(bg_values, bins=bins, weights=bg_weights, color=bg_colors,\n",
    "                    label=bg_labels, stacked=True)\n",
    "\n",
    "        ax_top.hist(signal_values, bins=bins, weights=signal_weights, color=signal_color,\n",
    "                    label=signal_label, histtype='step', linewidth=2)\n",
    "\n",
    "        signal_all = np.concatenate(signal_values) if len(signal_values) > 0 else np.array([])\n",
    "        signal_weights_all = np.concatenate(signal_weights) if len(signal_weights) > 0 else np.array([])\n",
    "\n",
    "        # Add error bar for signal (top plot)\n",
    "        if len(signal_all) > 0:\n",
    "            signal_counts, bin_edges = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "            sum_weights_sq, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all**2)\n",
    "            bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "            signal_errors = np.sqrt(sum_weights_sq)  # Poisson error sqrt(N)\n",
    "\n",
    "            ax_top.errorbar(bin_centers, signal_counts, yerr=signal_errors, fmt='.', linewidth=2,\n",
    "                            color=signal_color, capsize=0)\n",
    "\n",
    "        ax_top.set_yscale('log')\n",
    "        ax_top.set_ylim(0.0001, 1e11)\n",
    "        ax_top.set_xlim(bins[0], bins[-1])\n",
    "        ax_top.minorticks_on()\n",
    "        ax_top.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        ax_top.set_ylabel(\"Events\")\n",
    "        ax_top.legend(ncol=2)\n",
    "\n",
    "        bg_all = np.concatenate(bg_values) if len(bg_values) > 0 else np.array([])\n",
    "        bg_weights_all = np.concatenate(bg_weights) if len(bg_weights) > 0 else np.array([])\n",
    "\n",
    "        # Compute the weighted histogram counts using np.histogram.\n",
    "        S_counts, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "        B_counts, _ = np.histogram(bg_all, bins=bins, weights=bg_weights_all)     \n",
    "\n",
    "        # Compute per-bin significance S/sqrt(B) (set to 0 if B==0)\n",
    "        sig_per_bin = np.zeros_like(S_counts, dtype=float)\n",
    "        sqrt_B = np.sqrt(B_counts)\n",
    "        sig_per_bin = np.where(B_counts > 0, S_counts / sqrt_B, 0) # Use np.where to avoid division by zero\n",
    "        sig_per_bin = np.nan_to_num(sig_per_bin) # Replace any possible NaNs with 0\n",
    "\n",
    "        # Compute the bin centers for plotting.\n",
    "        bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "        # Compute the total significance: total S / sqrt(total B)\n",
    "        total_signal = np.sum(S_counts)\n",
    "        total_bkg = np.sum(B_counts)\n",
    "        if total_bkg > 0:\n",
    "            total_sig = total_signal / np.sqrt(total_bkg)\n",
    "        else:\n",
    "            total_sig = 0\n",
    "\n",
    "        ax_bot.step(bin_centers, sig_per_bin, where='mid', color='black', linewidth=2,\n",
    "                    label=f\"Total S/√B = {total_sig:.5f}\")\n",
    "\n",
    "        ax_bot.set_xlabel(var_config[var]['title'])\n",
    "        # ax_bot.set_xticks(np.linspace(bins[0], bins[-1], 11))\n",
    "        ax_bot.set_ylabel(\"S/√B\")\n",
    "        ax_bot.set_ylim(0, 2)\n",
    "        ax_top.set_xlim(bins[0], bins[-1])\n",
    "\n",
    "        # Do not set a title on the bottom plot.\n",
    "        ax_bot.set_title(\"\")\n",
    "\n",
    "        # Draw a legend with purple text.\n",
    "        leg = ax_bot.legend()\n",
    "        for text in leg.get_texts():\n",
    "            text.set_color('purple')\n",
    "\n",
    "        plt.xlim(bins[0], bins[-1])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../test/dphi_diff/mc23d_{cut_name}cut/{var}_nodijet.png\")\n",
    "        print(f\"successfully saved to dphi_diff/mc23d_{cut_name}cut/{var}_nodijet.png\")\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "\n",
    "        y_true = np.concatenate([np.ones_like(signal_all), np.zeros_like(bg_all)])\n",
    "        # Use the vtx_sumPt values as the classifier output.\n",
    "        y_scores = np.concatenate([signal_all, bg_all])\n",
    "        # Combine the weights for all events.\n",
    "        y_weights = np.concatenate([signal_weights_all, bg_weights_all])\n",
    "\n",
    "        # Compute the weighted ROC curve.\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_scores, sample_weight=y_weights)\n",
    "        sorted_indices = np.argsort(fpr)\n",
    "        fpr_sorted = fpr[sorted_indices]\n",
    "        tpr_sorted = tpr[sorted_indices]\n",
    "\n",
    "        roc_auc = auc(fpr_sorted, tpr_sorted)\n",
    "\n",
    "        # Create a new figure for the ROC curve.\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(fpr, tpr, lw=2, color='red', label=f'ROC curve (AUC = {roc_auc:.5f})')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random chance')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"ROC Curve for {var}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../test/dphi_diff/mc23d_{cut_name}cut/roc_curve_{var}.png\")\n",
    "        print(f\"successfully saved to ../test/dphi_diff/mc23d_{cut_name}cut/roc_curve_{var}.png\")\n",
    "        plt.close()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_sum_tmp = ak.sum(fb['jet_central_pt'], axis=-1)\n",
    "mask = jet_sum_tmp != 0 # True for events where jet_sum is not 0.\n",
    "balance = (fb['met_tst_et'][mask] + ak.firsts(fb['ph_pt'])[mask]) / jet_sum_tmp[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findnone(arr):\n",
    "    mask = ak.is_none(arr)\n",
    "\n",
    "    n_none = ak.sum(mask)\n",
    "    print(\"Number of None values:\", n_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    }
   ],
   "source": [
    "# Compute sqrt(B_counts) in a safe way\n",
    "sqrt_B = np.sqrt(B_counts)\n",
    "# Use np.where to avoid division by zero:\n",
    "sig_per_bin = np.where(B_counts > 0, S_counts / sqrt_B, 0)\n",
    "# Replace any possible NaNs with 0:\n",
    "sig_per_bin = np.nan_to_num(sig_per_bin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = {\n",
    "    'ntuple': [ntuple_name[i]] * len(fb),\n",
    "    'vtx_sumPt': fb['vtx_sumPt'],\n",
    "    'n_ph': fb['n_ph'],\n",
    "    'n_ph_baseline': fb['n_ph_baseline'],\n",
    "    'n_el_baseline': fb['n_el_baseline'],\n",
    "    'n_mu_baseline': fb['n_mu_baseline'],\n",
    "    'n_tau_baseline': fb['n_tau_baseline'],\n",
    "    'puWeight': fb['pu_weight'],\n",
    "    'actualIntPerXing': fb['actualIntPerXing'],\n",
    "    'mt': np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * (1 - np.cos(fb['met_tst_phi'] - ak.first(fb['ph_phi'])))) / 1000,\n",
    "    'metsig': fb['met_tst_sig'],\n",
    "    'metsigres': fb['met_tst_et'] / fb['met_tst_sig'],\n",
    "    'met': fb['met_tst_et'] + 50000,  # applying the '+50000' shift???\n",
    "    'met_noJVT': fb['met_tst_noJVT_et'],\n",
    "    'met_cst': fb['met_cst_et'],\n",
    "    'met_track': fb['met_track_et'],\n",
    "    'dmet': fb['met_tst_noJVT_et'] - fb['met_tst_et'],\n",
    "    'ph_pt': ak.first(fb['ph_pt']) - 150000,  # applying the '-150000' shift???\n",
    "    'ph_eta': np.abs(ak.first(fb['ph_eta'])),\n",
    "    'ph_phi': ak.first(fb['ph_phi']),\n",
    "    'jet_central_eta': ak.first(fb['jet_central_eta']),\n",
    "    'jet_central_pt1': ak.first(fb['jet_central_pt']),\n",
    "    'jet_central_pt2': fb['jet_central_pt'][:, 1],\n",
    "    'jet_central_pt': fb['jet_central_pt'],\n",
    "    'dphi_met_phterm': np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])),\n",
    "    'dphi_met_ph': np.arccos(np.cos(fb['met_tst_phi'] - ak.first(fb['ph_phi']))),\n",
    "    'dphi_met_jetterm': np.where(fb['met_jetterm_et'] != 0,\n",
    "                                  np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                                  0),\n",
    "    'dphi_phterm_jetterm': np.where(fb['met_jetterm_et'] > 0,\n",
    "                                    np.arccos(np.cos(fb['met_phterm_phi'] - fb['met_jetterm_phi'])),\n",
    "                                    4),\n",
    "    'dphi_ph_centraljet1': np.arccos(np.cos(ak.first(fb['ph_phi']) - ak.first(fb['jet_central_phi']))),\n",
    "    'dphi_ph_jet1': np.arccos(np.cos(ak.first(fb['ph_phi']) - ak.first(fb['jet_central_phi']))),\n",
    "    'dphi_central_jet1_jet2': np.arccos(np.cos(fb['jet_central_phi'][0] - fb['jet_central_phi'][1])),\n",
    "    'metplusph': fb['met_tst_et'] + ak.first(fb['ph_pt']),\n",
    "    'failJVT_jet_pt': fb['failJVT_jet_pt'],\n",
    "    'failJVT_jet_pt1': ak.first(fb['failJVT_jet_pt']),\n",
    "    'softerm': fb['met_softerm_tst_et'],\n",
    "    'jetterm': fb['met_jetterm_et'],\n",
    "    'jetterm_sumet': fb['met_jetterm_sumet'],\n",
    "    'n_jet': fb['n_jet'],\n",
    "    'n_jet_central': fb['n_jet_central'],\n",
    "    'n_jet_fwd': fb['n_jet'] - fb['n_jet_central'],\n",
    "    'vertex': np.abs(fb['pv_truth_z'][0] - fb['pv_z'][0]) == np.min(np.abs(fb['pv_truth_z'][0] - fb['pv_z'])),\n",
    "    'goodPV': np.abs(fb['pv_truth_z'][0] - fb['pv_z'][0]) <= 0.5,\n",
    "    'dphi_met_central_jet': np.arccos(np.cos(fb['met_tst_phi'] - ak.first(fb['jet_central_phi']))),\n",
    "    'counts': 0.5,\n",
    "    'jet_central_timing1': ak.first(fb['jet_central_timing']),\n",
    "    'jet_central_timing': fb['jet_central_timing'],\n",
    "    'jet_central_emfrac': fb['jet_central_emfrac'],\n",
    "    'jet_central_emfrac1': ak.first(fb['jet_central_emfrac']),\n",
    "    'balance': (fb['met_tst_et'] + ak.first(fb['ph_pt'])) / np.sum(fb['jet_central_pt']),\n",
    "    'balance_sumet': (fb['met_tst_et'] + ak.first(fb['ph_pt'])) / fb['met_jetterm_sumet'],\n",
    "    'central_jets_fraction': np.where(fb['n_jet'] > 0, fb['n_jet_central'] / fb['n_jet'], -1),\n",
    "    'trigger': fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M'],\n",
    "    'dphi_jj': np.arccos(np.cos(fb['jet_central_phi'][1] - fb['jet_central_phi'][0])) if len(fb['jet_central_phi']) > 1 else -1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={}\n",
    "dict['allcut'] = {\n",
    "    'str': (\n",
    "        'met_tst_et > 100000 && '\n",
    "        'trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M && '\n",
    "        'ph_pt[0] > 50000 && ' \n",
    "        'ph_pt[0] < 200000 && '\n",
    "        '(met_tst_noJVT_et-met_tst_et) > -60000 && ' # dmet\n",
    "        '(met_tst_noJVT_et-met_tst_et) < 60000 && '\n",
    "        'sqrt(2*met_tst_et*ph_pt[0]*(1-cos(met_tst_phi-ph_phi[0])))/1000 > 40 && ' # mt\n",
    "        'sqrt(2*met_tst_et*ph_pt[0]*(1-cos(met_tst_phi-ph_phi[0])))/1000 < 200 && '\n",
    "        '((met_jetterm_et!=0)*Alt$(acos(cos(met_tst_phi-met_jetterm_phi)),0)+(met_jetterm_et==0)*0) < 1.5 && ' # dphi_met_jetterm\n",
    "        '(met_tst_et+ph_pt[0])/Sum$(jet_central_pt) <= 12' # balance\n",
    "    )}\n",
    "dict['allcut']['str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
