{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b554e4a-b04e-4d60-a13b-d903f6cb27c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math, pickle, os, csv, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# import config functions\n",
    "sys.path.append(\"/home/jlai/jet-faking/config\")\n",
    "from jet_faking_plot_config import getWeight, zbi, sample_dict, getVarDict\n",
    "from plot_var import variables, variables_data, ntuple_names, ntuple_names_BDT\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high  \n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"]  # Legend\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb911931-934d-4e5b-a09a-7482badc05a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:04<00:26,  4.47s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m path_BDT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/mc23d_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mntuple_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_y_BDT_score.root\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m f \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39mopen(path)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnominal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 84\u001b[0m fb \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mak\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# add BDT score (same file path, same tree)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m f_BDT \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39mopen(path_BDT)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnominal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/uproot/behaviors/TBranch.py:832\u001b[0m, in \u001b[0;36mHasBranches.arrays\u001b[0;34m(self, expressions, cut, filter_name, filter_typename, filter_branch, aliases, language, entry_start, entry_stop, decompression_executor, interpretation_executor, array_cache, library, ak_add_doc, how)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 ranges_or_baskets\u001b[38;5;241m.\u001b[39mappend((branch, basket_num, range_or_basket))\n\u001b[1;32m    831\u001b[0m interp_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mak_add_doc\u001b[39m\u001b[38;5;124m\"\u001b[39m: ak_add_doc}\n\u001b[0;32m--> 832\u001b[0m \u001b[43m_ranges_or_baskets_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mranges_or_baskets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbranchid_interpretation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentry_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentry_stop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecompression_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpretation_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;66;03m# no longer needed; save memory\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m ranges_or_baskets\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/uproot/behaviors/TBranch.py:3017\u001b[0m, in \u001b[0;36m_ranges_or_baskets_to_arrays\u001b[0;34m(hasbranches, ranges_or_baskets, branchid_interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, library, arrays, update_ranges_or_baskets, interp_options)\u001b[0m\n\u001b[1;32m   3015\u001b[0m     ranges\u001b[38;5;241m.\u001b[39mappend(range_or_basket)\n\u001b[1;32m   3016\u001b[0m     range_args[range_or_basket] \u001b[38;5;241m=\u001b[39m (branch, basket_num)\n\u001b[0;32m-> 3017\u001b[0m     \u001b[43mrange_original_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrange_or_basket\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m original_index\n\u001b[1;32m   3018\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3019\u001b[0m     notifications\u001b[38;5;241m.\u001b[39mput(range_or_basket)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -------- CONFIG --------\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# LOG_DIR = f\"./cutlogs_{RUN_TAG}\"\n",
    "LOG_DIR = \"./cutlogs_80mT_selection1\"\n",
    "try:\n",
    "    shutil.rmtree(LOG_DIR)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "os.makedirs(LOG_DIR, exist_ok=False)\n",
    "TXT_LOG = os.path.join(LOG_DIR, \"cutflow.log\")\n",
    "CSV_LOG = os.path.join(LOG_DIR, \"cutflow.csv\")\n",
    "\n",
    "ntuple_names = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct', 'data23']\n",
    "\n",
    "def weight_sum(fb, ntuple_name):\n",
    "    if ntuple_name == 'data23':\n",
    "        return float(np.sum(getWeight(fb, ntuple_name, jet_faking=True)))\n",
    "    else:\n",
    "        return float(np.sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "# ---- logging helpers ----\n",
    "class CutLogger:\n",
    "    def __init__(self, txt_path, csv_path):\n",
    "        self.txt_path = txt_path\n",
    "        self.csv_path = csv_path\n",
    "        if not os.path.exists(csv_path):\n",
    "            with open(csv_path, \"w\", newline=\"\") as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"sample\",\"step_idx\",\"step\",\"events\",\"weighted\",\"elapsed_s\"])\n",
    "        # fresh txt header\n",
    "        with open(txt_path, \"a\") as f:\n",
    "            f.write(f\"\\n==== Cutflow run {RUN_TAG} ====\\n\")\n",
    "\n",
    "    def write(self, sample, step_idx, step, events, weighted, elapsed):\n",
    "        # text\n",
    "        with open(self.txt_path, \"a\") as f:\n",
    "            f.write(f\"[{sample:12s}] {step_idx:02d}  {step:30s}  \"\n",
    "                    f\"events={events:8d}  weighted={weighted:.6g}  dt={elapsed:.3f}s\\n\")\n",
    "        # csv\n",
    "        with open(self.csv_path, \"a\", newline=\"\") as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([sample, step_idx, step, int(events), f\"{weighted:.12g}\", f\"{elapsed:.6f}\"])\n",
    "\n",
    "logger = CutLogger(TXT_LOG, CSV_LOG)\n",
    "\n",
    "def log_step(sample, step_idx, step_label, fb, t0):\n",
    "    nevt = len(fb)\n",
    "    wsum = weight_sum(fb, sample)\n",
    "    logger.write(sample, step_idx, step_label, nevt, wsum, time.time() - t0)\n",
    "\n",
    "def require(mask, name):\n",
    "    \"\"\"Utility to guard awkward masks and give readable errors if shapes mismatch.\"\"\"\n",
    "    if isinstance(mask, (np.ndarray, ak.Array)) and ak.num(mask, axis=0) is not None:\n",
    "        return mask\n",
    "    raise RuntimeError(f\"Mask '{name}' has wrong shape/type: {type(mask)}\")\n",
    "\n",
    "# ---- your loop with logging ----\n",
    "for ntuple_name in tqdm(ntuple_names):\n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "\n",
    "    if ntuple_name == 'data23':  # data-driven\n",
    "        path = \"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/data23_y_BDT_score.root\"\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables_data, library=\"ak\")\n",
    "        fb['VertexBDTScore'] = fb['BDTScore']\n",
    "\n",
    "        log_step(ntuple_name, step, \"loaded\", fb, start_time); step += 1\n",
    "\n",
    "        # ensure photon arrays exist for reweighting usage downstream\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]\n",
    "        # jet-faking-photon cut (data control)\n",
    "        mask = (ak.firsts(fb['ph_topoetcone40']) - 2450.)/ak.firsts(fb['ph_pt']) > 0.1\n",
    "        fb = fb[require(mask, \"jetfake\")]\n",
    "        log_step(ntuple_name, step, \"jet_faking_photon\", fb, start_time); step += 1\n",
    "\n",
    "        fb = fb[fb['n_ph_baseline'] == 1]\n",
    "        log_step(ntuple_name, step, \"n_ph_baseline==1\", fb, start_time); step += 1\n",
    "\n",
    "    else:  # MC\n",
    "        path = f\"/data/tmathew/ntups/mc23d/{ntuple_name}_y.root\" \n",
    "        path_BDT = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/mc23d_{ntuple_name}_y_BDT_score.root\"\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables, library=\"ak\")\n",
    "\n",
    "        # add BDT score (same file path, same tree)\n",
    "        f_BDT = uproot.open(path_BDT)['nominal']\n",
    "        fb_BDT = f_BDT.arrays([\"event\", \"BDTScore\"], library=\"ak\")\n",
    "        if np.all(fb[\"event\"] == fb_BDT[\"event\"]):\n",
    "            fb[\"VertexBDTScore\"] = fb_BDT[\"BDTScore\"]\n",
    "        else:\n",
    "            print(f\"[WARN] Event mismatch in {ntuple_name}; BDT not attached\")\n",
    "\n",
    "        log_step(ntuple_name, step, \"loaded\", fb, start_time); step += 1\n",
    "\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]\n",
    "        fb = fb[fb['n_ph'] == 1]\n",
    "        log_step(ntuple_name, step, \"n_ph==1\", fb, start_time); step += 1\n",
    "\n",
    "        if ntuple_name in (\"Zjets\",\"Wjets\"):\n",
    "            mask = ak.firsts(fb['ph_truth_type']) == 2   # keep e->gamma only\n",
    "            fb = fb[require(mask, \"ph_truth_type==2\")]\n",
    "            log_step(ntuple_name, step, \"truth e->gamma\", fb, start_time); step += 1\n",
    "\n",
    "        if ntuple_name == \"ggHyyd\":\n",
    "            fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "            log_step(ntuple_name, step, \"pv_z exists\", fb, start_time); step += 1\n",
    "            good_pv = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "            fb = fb[require(good_pv, \"goodPV\")]\n",
    "            log_step(ntuple_name, step, \"goodPV\", fb, start_time); step += 1\n",
    "\n",
    "    # --------- BASIC CUTS (shared) ----------\n",
    "    # NOTE: If 'ggHyyd' is signal without a prompt μ, consider not requiring n_mu==1 for that sample.\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    log_step(ntuple_name, step, \"n_mu_baseline==0\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['n_el_baseline'] == 0]\n",
    "    log_step(ntuple_name, step, \"n_el_baseline==0\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    log_step(ntuple_name, step, \"n_tau_baseline==0\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M'] == 1]\n",
    "    log_step(ntuple_name, step, \"trigger==1\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0]\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) > 50_000]\n",
    "    log_step(ntuple_name, step, \"ph_pt>50GeV\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['met_tst_et'] > 100_000]\n",
    "    log_step(ntuple_name, step, \"MET>100GeV\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['n_jet_central'] <= 3]\n",
    "    log_step(ntuple_name, step, \"n_jet_central<=3\", fb, start_time); step += 1\n",
    "\n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) *\n",
    "                     (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000.0\n",
    "    # mask1 = mt_tmp > 100\n",
    "    # mask2 = mt_tmp < 140\n",
    "    # fb = fb[mask1 * mask2]\n",
    "    # log_step(ntuple_name, step, \"140>mT>100GeV\", fb, start_time); step += 1\n",
    "    mask1 = mt_tmp > 80\n",
    "    fb = fb[mask1]\n",
    "    log_step(ntuple_name, step, \"mT>80GeV\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['VertexBDTScore'] > 0.1]\n",
    "    log_step(ntuple_name, step, \"VertexBDTScore>0.1\", fb, start_time); step += 1\n",
    "\n",
    "# ---------- SELECTION CUT ------------\n",
    "\n",
    "    metsig_tmp = fb['met_tst_sig'] \n",
    "    mask1 = metsig_tmp > 7\n",
    "    fb = fb[mask1]\n",
    "    log_step(ntuple_name, step, \"met_tst_sig>7\", fb, start_time); step += 1\n",
    "    \n",
    "    ph_eta_tmp = np.abs(ak.firsts(fb['ph_eta']))\n",
    "    fb = fb[ph_eta_tmp < 1.75]\n",
    "    log_step(ntuple_name, step, \"ph_eta<1.75\", fb, start_time); step += 1\n",
    "\n",
    "    dphi_met_phterm_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])) # added cut 3\n",
    "    fb = fb[dphi_met_phterm_tmp > 1.35]\n",
    "    log_step(ntuple_name, step, \"dphi_met_phterm>1.35\", fb, start_time); step += 1\n",
    "\n",
    "    dmet_tmp = fb['met_tst_noJVT_et'] - fb['met_tst_et']\n",
    "    mask1 = dmet_tmp > -20000\n",
    "    fb = fb[mask1]\n",
    "    log_step(ntuple_name, step, \"dmet>-20GeV\", fb, start_time); step += 1\n",
    "\n",
    "    dphi_jj_tmp = fb['dphi_central_jj']\n",
    "    dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "    dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "    dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "    fb = fb[dphi_jj_tmp < 2.5]\n",
    "    log_step(ntuple_name, step, \"dphi_jj_central<2.5\", fb, start_time); step += 1\n",
    "\n",
    "    dphi_met_jetterm_tmp = np.where(fb['met_jetterm_et'] != 0,   # added cut 5\n",
    "                        np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                        -999)\n",
    "    fb = fb[dphi_met_jetterm_tmp < 0.75]\n",
    "    log_step(ntuple_name, step, \"dphi_met_jetterm<0.75\", fb, start_time); step += 1\n",
    "\n",
    "\n",
    "    # ---------- FURTHER SELECTION CUT ------------\n",
    "    # jet_sum_tmp = ak.sum(fb['jet_central_pt'], axis=-1)\n",
    "    # expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "    # balance_tmp = ak.where(jet_sum_tmp != 0, expr, -999)\n",
    "    # mask_nan = balance_tmp == -999\n",
    "    # mask = mask_nan | (balance_tmp > 0.90)\n",
    "    # fb = fb[mask]\n",
    "    # log_step(ntuple_name, step, \"balance>0.90\", fb, start_time); step += 1\n",
    "\n",
    "    # fb = fb[fb['met_jetterm_et'] > 80000]\n",
    "    # log_step(ntuple_name, step, \"jetterm>80GeV\", fb, start_time); step += 1\n",
    "\n",
    "    # dphi_phterm_jetterm_tmp = np.where(fb['met_jetterm_et'] > 0,\n",
    "    #                                     np.arccos(np.cos(fb['met_phterm_phi'] - fb['met_jetterm_phi'])),\n",
    "    #                                     -999)\n",
    "    # mask1 = dphi_phterm_jetterm_tmp == -999\n",
    "    # mask2 = dphi_phterm_jetterm_tmp > 1.8\n",
    "    # mask3 = dphi_phterm_jetterm_tmp < 3.1 \n",
    "    # in_window = mask2 & mask3\n",
    "    # mask = mask1 | in_window\n",
    "    # fb = fb[mask]\n",
    "    # log_step(ntuple_name, step, \"3.1>dphi_phterm_jetterm>1.8\", fb, start_time); step += 1\n",
    "\n",
    "    # # metsigres_tmp = fb['met_tst_et'] / fb['met_tst_sig']\n",
    "    # # fb = fb[metsigres_tmp < 42000]\n",
    "    # # log_step(ntuple_name, step, \"metsigres<42GeV\", fb, start_time); step += 1\n",
    "\n",
    "    # fb = fb[fb['met_tst_noJVT_et'] > 90000]\n",
    "    # log_step(ntuple_name, step, \"met_noJVT>90GeV\", fb, start_time); step += 1\n",
    "    \n",
    "    \n",
    "    # tot.append(fb) # save the fb for further study\n",
    "\n",
    "    # ---- sanity check for None ----\n",
    "    n_none = int(ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "    with open(TXT_LOG, \"a\") as ftxt:\n",
    "        ftxt.write(f\"[{ntuple_name:12s}] None-check met_tst_et: {n_none}\\n\")\n",
    "\n",
    "    # optional: free memory\n",
    "    del fb\n",
    "\n",
    "print(f\"\\nLogs written to:\\n - {TXT_LOG}\\n - {CSV_LOG}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da14ac67-4fea-48a9-ad3c-e99984205c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_order = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct','data23']\n",
    "\n",
    "preselection_end = {\n",
    "    'ggHyyd':          'goodPV',               # pv_z exists -> goodPV (take the last one)\n",
    "    'Zjets':           'truth e->gamma',\n",
    "    'Wjets':           'truth e->gamma',\n",
    "    'Zgamma':          'n_ph==1',\n",
    "    'Wgamma':          'n_ph==1',\n",
    "    'gammajet_direct': 'n_ph==1',\n",
    "    'data23':          'n_ph_baseline==1',     # jet_faking_photon -> n_ph_baseline==1 (take the last one)\n",
    "}\n",
    "\n",
    "shared_cuts = [\n",
    "    'n_mu_baseline==0',\n",
    "    'n_el_baseline==0',\n",
    "    'n_tau_baseline==0',\n",
    "    'trigger==1',\n",
    "    'ph_pt>50GeV',\n",
    "    'MET>100GeV',\n",
    "    'n_jet_central<=3',\n",
    "    'mT>80GeV',\n",
    "    'VertexBDTScore>0.1',\n",
    "    'met_tst_sig>7',\n",
    "    'ph_eta<1.75',\n",
    "    'dphi_met_phterm>1.35',\n",
    "    'dmet>-20GeV',\n",
    "    'dphi_jj_central<2.5',\n",
    "    'dphi_met_jetterm<0.75'\n",
    "]\n",
    "\n",
    "\n",
    "# Load and sanitize the log\n",
    "df = pd.read_csv(CSV_LOG)\n",
    "# Ensure numeric\n",
    "df['weighted'] = pd.to_numeric(df['weighted'], errors='coerce')\n",
    "df['step_idx'] = pd.to_numeric(df['step_idx'], errors='coerce')\n",
    "\n",
    "# Keep last entry per (sample, step)\n",
    "df = (df.sort_values(['sample','step_idx'])\n",
    "        .drop_duplicates(subset=['sample','step'], keep='last'))\n",
    "\n",
    "# Helper to fetch the weighted yield for a given (sample, step label)\n",
    "def get_yield(sample, step_label):\n",
    "    row = df[(df['sample'] == sample) & (df['step'] == step_label)]\n",
    "    if not row.empty:\n",
    "        return float(row['weighted'].iloc[0])\n",
    "    # Fallback: if a step is unexpectedly missing, try using the latest prior step by index\n",
    "    # (shouldn't happen after preselection, but keeps the pipeline resilient)\n",
    "    sample_rows = df[df['sample'] == sample].sort_values('step_idx')\n",
    "    prior = sample_rows[sample_rows['step_idx'] <= sample_rows['step_idx'].max()]\n",
    "    return float(prior['weighted'].iloc[-1]) if not prior.empty else np.nan\n",
    "\n",
    "# 1) LOAD row = 'loaded'\n",
    "rows = ['LOAD', 'CUT 1 (preprocessing)'] + shared_cuts\n",
    "table = pd.DataFrame(index=rows, columns=process_order, dtype=float)\n",
    "\n",
    "for p in process_order:\n",
    "    table.loc['LOAD', p] = get_yield(p, 'loaded')\n",
    "\n",
    "# 2) CUT 1 row = process-specific preselection_end\n",
    "for p in process_order:\n",
    "    end_step = preselection_end[p]\n",
    "    table.loc['CUT 1 (preprocessing)', p] = get_yield(p, end_step)\n",
    "\n",
    "# 3) Shared cuts: same step name for all processes\n",
    "for cut in shared_cuts:\n",
    "    for p in process_order:\n",
    "        table.loc[cut, p] = get_yield(p, cut)\n",
    "\n",
    "# Compute S/sqrt(B) for each row\n",
    "signal_col = 'ggHyyd'\n",
    "data_cols = ['data23']\n",
    "bkg_cols = [c for c in process_order if c not in ([signal_col])]\n",
    "\n",
    "S = table[signal_col].fillna(0.0)\n",
    "B = table[bkg_cols].sum(axis=1).astype(float)\n",
    "\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    ssb = S / np.sqrt(B)                     # S/sqrt(B)\n",
    "    ssb.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    ss_sb   = S / np.sqrt(S + B)             # S/sqrt(S+B)\n",
    "    ss_sb.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    ss_s13b = S / np.sqrt(S + 1.3*B)         # S/sqrt(S+1.3B)\n",
    "    ss_s13b.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "SIGMA_B_FRAC = 0.30  # 30% relative background uncertainty; change as needed\n",
    "# Vectorized ZBi over rows (robust if B<=0 -> 0.0)\n",
    "ZBi = pd.Series(\n",
    "    [zbi(float(s), float(b), sigma_b_frac=SIGMA_B_FRAC) for s, b in zip(S.values, B.values)],\n",
    "    index=table.index, dtype=float\n",
    ")\n",
    "\n",
    "# Pretty output\n",
    "disp = table.copy()\n",
    "def fmt(x):\n",
    "    if pd.isna(x): return 'n/a'\n",
    "    # scientific for very small/large; fixed otherwise\n",
    "    return f\"{x:.3g}\" if (x != 0 and (abs(x) < 1e-2 or abs(x) >= 1e4)) else f\"{x:.3f}\"\n",
    "\n",
    "disp_out = disp.applymap(fmt)\n",
    "disp_out['S/sqrt(B)']           = ssb.map(lambda v: 'n/a' if pd.isna(v) else f\"{v:.3f}\")\n",
    "disp_out['S/sqrt(S+B)']         = ss_sb.map(lambda v: 'n/a' if pd.isna(v) else f\"{v:.3f}\")\n",
    "disp_out['S/sqrt(S+1.3B)']      = ss_s13b.map(lambda v: 'n/a' if pd.isna(v) else f\"{v:.3f}\")\n",
    "disp_out[f'ZBi (σ_b={SIGMA_B_FRAC:.0%})'] = ZBi.map(lambda v: 'n/a' if pd.isna(v) else f\"{v:.3f}\")\n",
    "disp_out.insert(0, 'cut', disp_out.index)\n",
    "\n",
    "# Save + print (add the two new columns)\n",
    "out_csv = Path(LOG_DIR) / \"cutflow_unified.csv\"\n",
    "out_md  = Path(LOG_DIR) / \"cutflow_unified.md\"\n",
    "disp_out.to_csv(out_csv, index=False)\n",
    "with open(out_md, \"w\") as f:\n",
    "    f.write(disp_out.to_markdown(index=False))\n",
    "\n",
    "print(\"Unified cutflow written to:\")\n",
    "print(f\"  - {out_csv}\")\n",
    "print(f\"  - {out_md}\")\n",
    "print(disp_out[['cut'] + process_order + ['S/sqrt(B)','S/sqrt(S+B)','S/sqrt(S+1.3B)', f'ZBi (σ_b={SIGMA_B_FRAC:.0%})']].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
