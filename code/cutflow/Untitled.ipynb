{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5020690e-b6b3-46c3-a87e-734d3d654821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math, pickle, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "\n",
    "# import config functions\n",
    "sys.path.append('/home/jlai/dark_photon/code/config')\n",
    "from plot_config import getWeight, zbi, sample_dict, getVarDict\n",
    "from plot_var import variables, variables_mc, ntuple_names\n",
    "from n_1_iteration_functions import get_best_cut, calculate_significance, apply_cut_to_fb, apply_all_cuts, compute_total_significance, n_minus_1_optimizer\n",
    "# from cut_config import cut_config\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high  \n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14,\n",
    "    \"title\": 20\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"],  # Legend\n",
    "    \"axes.titlesize\": font_size[\"title\"] # Title\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389f224-20c1-4dd8-8de0-69cfa0bb750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- CONFIG --------\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# LOG_DIR = f\"./cutlogs_{RUN_TAG}\"\n",
    "LOG_DIR = \"./cutlogs_100mT_selection1\"\n",
    "try:\n",
    "    shutil.rmtree(LOG_DIR)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "os.makedirs(LOG_DIR, exist_ok=False)\n",
    "TXT_LOG = os.path.join(LOG_DIR, \"cutflow.log\")\n",
    "CSV_LOG = os.path.join(LOG_DIR, \"cutflow.csv\")\n",
    "\n",
    "ntuple_names = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct', 'data23']\n",
    "\n",
    "def weight_sum(fb, ntuple_name):\n",
    "    if ntuple_name == 'data23':\n",
    "        return float(np.sum(getWeight(fb, ntuple_name, jet_faking=True)))\n",
    "    else:\n",
    "        return float(np.sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "# ---- logging helpers ----\n",
    "class CutLogger:\n",
    "    def __init__(self, txt_path, csv_path):\n",
    "        self.txt_path = txt_path\n",
    "        self.csv_path = csv_path\n",
    "        if not os.path.exists(csv_path):\n",
    "            with open(csv_path, \"w\", newline=\"\") as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"sample\",\"step_idx\",\"step\",\"events\",\"weighted\",\"elapsed_s\"])\n",
    "        # fresh txt header\n",
    "        with open(txt_path, \"a\") as f:\n",
    "            f.write(f\"\\n==== Cutflow run {RUN_TAG} ====\\n\")\n",
    "\n",
    "    def write(self, sample, step_idx, step, events, weighted, elapsed):\n",
    "        # text\n",
    "        with open(self.txt_path, \"a\") as f:\n",
    "            f.write(f\"[{sample:12s}] {step_idx:02d}  {step:30s}  \"\n",
    "                    f\"events={events:8d}  weighted={weighted:.6g}  dt={elapsed:.3f}s\\n\")\n",
    "        # csv\n",
    "        with open(self.csv_path, \"a\", newline=\"\") as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([sample, step_idx, step, int(events), f\"{weighted:.12g}\", f\"{elapsed:.6f}\"])\n",
    "\n",
    "logger = CutLogger(TXT_LOG, CSV_LOG)\n",
    "\n",
    "def log_step(sample, step_idx, step_label, fb, t0):\n",
    "    nevt = len(fb)\n",
    "    wsum = weight_sum(fb, sample)\n",
    "    logger.write(sample, step_idx, step_label, nevt, wsum, time.time() - t0)\n",
    "\n",
    "def require(mask, name):\n",
    "    \"\"\"Utility to guard awkward masks and give readable errors if shapes mismatch.\"\"\"\n",
    "    if isinstance(mask, (np.ndarray, ak.Array)) and ak.num(mask, axis=0) is not None:\n",
    "        return mask\n",
    "    raise RuntimeError(f\"Mask '{name}' has wrong shape/type: {type(mask)}\")\n",
    "\n",
    "# ---- your loop with logging ----\n",
    "for ntuple_name in tqdm(ntuple_names):\n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "\n",
    "    if ntuple_name == 'data23':  # data-driven\n",
    "        path = \"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/data23_y_BDT_score.root\"\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables_data, library=\"ak\")\n",
    "        fb['VertexBDTScore'] = fb['BDTScore']\n",
    "\n",
    "        log_step(ntuple_name, step, \"loaded\", fb, start_time); step += 1\n",
    "\n",
    "        # ensure photon arrays exist for reweighting usage downstream\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]\n",
    "        # jet-faking-photon cut (data control)\n",
    "        mask = (ak.firsts(fb['ph_topoetcone40']) - 2450.)/ak.firsts(fb['ph_pt']) > 0.1\n",
    "        fb = fb[require(mask, \"jetfake\")]\n",
    "        log_step(ntuple_name, step, \"jet_faking_photon\", fb, start_time); step += 1\n",
    "\n",
    "        fb = fb[fb['n_ph_baseline'] == 1]\n",
    "        log_step(ntuple_name, step, \"n_ph_baseline==1\", fb, start_time); step += 1\n",
    "\n",
    "    else:  # MC\n",
    "        path = f\"/data/tmathew/ntups/mc23d/{ntuple_name}_y.root\" \n",
    "        path_BDT = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/mc23d_{ntuple_name}_y_BDT_score.root\"\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables, library=\"ak\")\n",
    "\n",
    "        # add BDT score (same file path, same tree)\n",
    "        f_BDT = uproot.open(path_BDT)['nominal']\n",
    "        fb_BDT = f_BDT.arrays([\"event\", \"BDTScore\"], library=\"ak\")\n",
    "        if np.all(fb[\"event\"] == fb_BDT[\"event\"]):\n",
    "            fb[\"VertexBDTScore\"] = fb_BDT[\"BDTScore\"]\n",
    "        else:\n",
    "            print(f\"[WARN] Event mismatch in {ntuple_name}; BDT not attached\")\n",
    "\n",
    "        log_step(ntuple_name, step, \"loaded\", fb, start_time); step += 1\n",
    "\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]\n",
    "        fb = fb[fb['n_ph'] == 1]\n",
    "        log_step(ntuple_name, step, \"n_ph==1\", fb, start_time); step += 1\n",
    "\n",
    "        if ntuple_name in (\"Zjets\",\"Wjets\"):\n",
    "            mask = ak.firsts(fb['ph_truth_type']) == 2   # keep e->gamma only\n",
    "            fb = fb[require(mask, \"ph_truth_type==2\")]\n",
    "            log_step(ntuple_name, step, \"truth e->gamma\", fb, start_time); step += 1\n",
    "\n",
    "        if ntuple_name == \"ggHyyd\":\n",
    "            fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "            log_step(ntuple_name, step, \"pv_z exists\", fb, start_time); step += 1\n",
    "            good_pv = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "            fb = fb[require(good_pv, \"goodPV\")]\n",
    "            log_step(ntuple_name, step, \"goodPV\", fb, start_time); step += 1\n",
    "\n",
    "    # --------- BASIC CUTS (shared) ----------\n",
    "    # NOTE: If 'ggHyyd' is signal without a prompt Î¼, consider not requiring n_mu==1 for that sample.\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    log_step(ntuple_name, step, \"n_mu_baseline==0\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['n_el_baseline'] == 0]\n",
    "    log_step(ntuple_name, step, \"n_el_baseline==0\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    log_step(ntuple_name, step, \"n_tau_baseline==0\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M'] == 1]\n",
    "    log_step(ntuple_name, step, \"trigger==1\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0]\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) > 50_000]\n",
    "    log_step(ntuple_name, step, \"ph_pt>50GeV\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['met_tst_et'] > 100_000]\n",
    "    log_step(ntuple_name, step, \"MET>100GeV\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['n_jet_central'] <= 3]\n",
    "    log_step(ntuple_name, step, \"n_jet_central<=3\", fb, start_time); step += 1\n",
    "\n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) *\n",
    "                     (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000.0\n",
    "    # mask1 = mt_tmp > 100\n",
    "    # mask2 = mt_tmp < 140\n",
    "    # fb = fb[mask1 * mask2]\n",
    "    # log_step(ntuple_name, step, \"140>mT>100GeV\", fb, start_time); step += 1\n",
    "    mask1 = mt_tmp > 80\n",
    "    fb = fb[mask1]\n",
    "    log_step(ntuple_name, step, \"mT>80GeV\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['VertexBDTScore'] > 0.1]\n",
    "    log_step(ntuple_name, step, \"VertexBDTScore>0.1\", fb, start_time); step += 1\n",
    "\n",
    "# ---------- SELECTION CUT ------------\n",
    "\n",
    "    metsig_tmp = fb['met_tst_sig'] \n",
    "    mask1 = metsig_tmp > 7\n",
    "    fb = fb[mask1]\n",
    "    log_step(ntuple_name, step, \"met_tst_sig>7\", fb, start_time); step += 1\n",
    "    \n",
    "    ph_eta_tmp = np.abs(ak.firsts(fb['ph_eta']))\n",
    "    fb = fb[ph_eta_tmp < 1.75]\n",
    "    log_step(ntuple_name, step, \"ph_eta<1.75\", fb, start_time); step += 1\n",
    "\n",
    "    dphi_met_phterm_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])) # added cut 3\n",
    "    fb = fb[dphi_met_phterm_tmp > 1.35]\n",
    "    log_step(ntuple_name, step, \"dphi_met_phterm>1.35\", fb, start_time); step += 1\n",
    "\n",
    "    dmet_tmp = fb['met_tst_noJVT_et'] - fb['met_tst_et']\n",
    "    mask1 = dmet_tmp > -20000\n",
    "    fb = fb[mask1]\n",
    "    log_step(ntuple_name, step, \"dmet>-20GeV\", fb, start_time); step += 1\n",
    "\n",
    "    dphi_jj_tmp = fb['dphi_central_jj']\n",
    "    dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "    dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "    dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "    fb = fb[dphi_jj_tmp < 2.5]\n",
    "    log_step(ntuple_name, step, \"dphi_jj_central<2.5\", fb, start_time); step += 1\n",
    "\n",
    "    dphi_met_jetterm_tmp = np.where(fb['met_jetterm_et'] != 0,   # added cut 5\n",
    "                        np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                        -999)\n",
    "    fb = fb[dphi_met_jetterm_tmp < 0.75]\n",
    "    log_step(ntuple_name, step, \"dphi_met_jetterm<0.75\", fb, start_time); step += 1\n",
    "\n",
    "\n",
    "    # ---------- FURTHER SELECTION CUT ------------\n",
    "    # jet_sum_tmp = ak.sum(fb['jet_central_pt'], axis=-1)\n",
    "    # expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "    # balance_tmp = ak.where(jet_sum_tmp != 0, expr, -999)\n",
    "    # mask_nan = balance_tmp == -999\n",
    "    # mask = mask_nan | (balance_tmp > 0.90)\n",
    "    # fb = fb[mask]\n",
    "    # log_step(ntuple_name, step, \"balance>0.90\", fb, start_time); step += 1\n",
    "\n",
    "    # fb = fb[fb['met_jetterm_et'] > 80000]\n",
    "    # log_step(ntuple_name, step, \"jetterm>80GeV\", fb, start_time); step += 1\n",
    "\n",
    "    # dphi_phterm_jetterm_tmp = np.where(fb['met_jetterm_et'] > 0,\n",
    "    #                                     np.arccos(np.cos(fb['met_phterm_phi'] - fb['met_jetterm_phi'])),\n",
    "    #                                     -999)\n",
    "    # mask1 = dphi_phterm_jetterm_tmp == -999\n",
    "    # mask2 = dphi_phterm_jetterm_tmp > 1.8\n",
    "    # mask3 = dphi_phterm_jetterm_tmp < 3.1 \n",
    "    # in_window = mask2 & mask3\n",
    "    # mask = mask1 | in_window\n",
    "    # fb = fb[mask]\n",
    "    # log_step(ntuple_name, step, \"3.1>dphi_phterm_jetterm>1.8\", fb, start_time); step += 1\n",
    "\n",
    "    # # metsigres_tmp = fb['met_tst_et'] / fb['met_tst_sig']\n",
    "    # # fb = fb[metsigres_tmp < 42000]\n",
    "    # # log_step(ntuple_name, step, \"metsigres<42GeV\", fb, start_time); step += 1\n",
    "\n",
    "    # fb = fb[fb['met_tst_noJVT_et'] > 90000]\n",
    "    # log_step(ntuple_name, step, \"met_noJVT>90GeV\", fb, start_time); step += 1\n",
    "    \n",
    "    \n",
    "    # tot.append(fb) # save the fb for further study\n",
    "\n",
    "    # ---- sanity check for None ----\n",
    "    n_none = int(ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "    with open(TXT_LOG, \"a\") as ftxt:\n",
    "        ftxt.write(f\"[{ntuple_name:12s}] None-check met_tst_et: {n_none}\\n\")\n",
    "\n",
    "    # optional: free memory\n",
    "    del fb\n",
    "\n",
    "print(f\"\\nLogs written to:\\n - {TXT_LOG}\\n - {CSV_LOG}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
