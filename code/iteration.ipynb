{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd91d671-f884-4af4-88f1-975e1e3caeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mc23d_ggHyyd_y Unweighted Events before cut:  17999\n",
      "mc23d_ggHyyd_y Weighted Events before cut:  1918.8756675680827\n",
      "mc23d_ggHyyd_y Unweighted Events after basic:  2627\n",
      "mc23d_ggHyyd_y Weighted Events after basic:  286.17152634919125\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_ggHyyd_y: 0.41992783546447754 seconds\n",
      "\n",
      "mc23d_Zgamma_y Unweighted Events before cut:  2520609\n",
      "mc23d_Zgamma_y Weighted Events before cut:  21734.468674981053\n",
      "mc23d_Zgamma_y Unweighted Events after basic:  19478\n",
      "mc23d_Zgamma_y Weighted Events after basic:  265.2141821877743\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_Zgamma_y: 17.117194890975952 seconds\n",
      "\n",
      "mc23d_Wgamma_y Unweighted Events before cut:  685525\n",
      "mc23d_Wgamma_y Weighted Events before cut:  23464.591275458304\n",
      "mc23d_Wgamma_y Unweighted Events after basic:  13933\n",
      "mc23d_Wgamma_y Weighted Events after basic:  535.5532902564596\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_Wgamma_y: 4.428694009780884 seconds\n",
      "\n",
      "mc23d_gammajet_direct_y Unweighted Events before cut:  1872548\n",
      "mc23d_gammajet_direct_y Weighted Events before cut:  1527485.7594546063\n",
      "mc23d_gammajet_direct_y Unweighted Events after basic:  30515\n",
      "mc23d_gammajet_direct_y Weighted Events after basic:  974.0549210779564\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_gammajet_direct_y: 11.704716920852661 seconds\n",
      "\n",
      "data23_y Unweighted Events before cut:  1489084\n",
      "data23_y Weighted Events before cut:  3077821.8039979036\n",
      "data23_y Unweighted Events after basic:  1397\n",
      "data23_y Weighted Events after basic:  2903.8609999999826\n",
      "Number of none values:  0\n",
      "Reading Time for data23_y: 14.19617772102356 seconds\n",
      "\n",
      "data23_eprobe Unweighted Events before cut:  991882\n",
      "data23_eprobe Weighted Events before cut:  35278.89142854558\n",
      "data23_eprobe Unweighted Events after basic:  24949\n",
      "data23_eprobe Weighted Events after basic:  1127.4378565699576\n",
      "Number of none values:  0\n",
      "Reading Time for data23_eprobe: 5.627890586853027 seconds\n",
      "\n",
      "mc23e_Zgamma_y Unweighted Events before cut:  8622736\n",
      "mc23e_Zgamma_y Weighted Events before cut:  66651.54542882358\n",
      "mc23e_Zgamma_y Unweighted Events after basic:  68044\n",
      "mc23e_Zgamma_y Weighted Events after basic:  798.1511253245422\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_Zgamma_y: 57.22029948234558 seconds\n",
      "\n",
      "mc23e_Wgamma_y Unweighted Events before cut:  2162708\n",
      "mc23e_Wgamma_y Weighted Events before cut:  74823.05389455653\n",
      "mc23e_Wgamma_y Unweighted Events after basic:  44545\n",
      "mc23e_Wgamma_y Weighted Events after basic:  1592.4189527449048\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_Wgamma_y: 14.397810459136963 seconds\n",
      "\n",
      "mc23e_gammajet_direct_y Unweighted Events before cut:  2268382\n",
      "mc23e_gammajet_direct_y Weighted Events before cut:  6522209.851531688\n",
      "mc23e_gammajet_direct_y Unweighted Events after basic:  29591\n",
      "mc23e_gammajet_direct_y Weighted Events after basic:  3672.988737405649\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_gammajet_direct_y: 14.100159645080566 seconds\n",
      "\n",
      "data24_y Unweighted Events before cut:  7913491\n",
      "data24_y Weighted Events before cut:  13122730.235302538\n",
      "data24_y Unweighted Events after basic:  6993\n",
      "data24_y Weighted Events after basic:  11516.719999999303\n",
      "Number of none values:  0\n",
      "Reading Time for data24_y: 73.72354435920715 seconds\n",
      "\n",
      "data24_eprobe Unweighted Events before cut:  4452447\n",
      "data24_eprobe Weighted Events before cut:  168317.91138638573\n",
      "data24_eprobe Unweighted Events after basic:  110499\n",
      "data24_eprobe Weighted Events after basic:  5371.424155399616\n",
      "Number of none values:  0\n",
      "Reading Time for data24_eprobe: 24.75926947593689 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math, pickle, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "\n",
    "# import config functions\n",
    "sys.path.append('/home/jlai/dark_photon/code/config')\n",
    "from plot_config import getWeight, zbi, sample_dict, getVarDict\n",
    "from plot_var import variables, variables_mc, ntuple_names\n",
    "from n_1_iteration_functions import get_best_cut, calculate_significance, apply_cut_to_fb, apply_all_cuts, compute_total_significance, n_minus_1_optimizer\n",
    "# from cut_config import cut_config\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high  \n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14,\n",
    "    \"title\": 20\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"],  # Legend\n",
    "    \"axes.titlesize\": font_size[\"title\"] # Title\n",
    "})\n",
    "\n",
    "\n",
    "tot = []\n",
    "signal_name = 'ggHyyd'\n",
    "data = pd.DataFrame()\n",
    "\n",
    "def test(fb):\n",
    "    # checking if there are any none values\n",
    "    mask = ak.is_none(fb['met_tst_et'])\n",
    "    n_none = ak.sum(mask)\n",
    "    print(\"Number of none values: \", n_none)\n",
    "    # if n_none > 0:\n",
    "    #     fb = fb[~mask]\n",
    "    # print(\"Events after removing none values: \", len(fb), ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "\n",
    "def print_cut(ntuple_name, fb, label):\n",
    "    print(f\"{ntuple_name} Unweighted Events {label}: \", len(fb))\n",
    "    print(f\"{ntuple_name} Weighted Events {label}: \", sum(getWeight(fb, ntuple_name)))\n",
    "        \n",
    "for i in range(len(ntuple_names)):\n",
    "    start_time = time.time()\n",
    "    ntuple_name = ntuple_names[i]\n",
    "    path = f\"/data/fpiazza/ggHyyd/NtuplesWithBDTSkim/{ntuple_name}_nominal_bdt.root\"\n",
    "    f = uproot.open(path)['nominal']\n",
    "    if ntuple_name.startswith(\"mc\"):\n",
    "        fb = f.arrays(variables+variables_mc, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "        \n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "        fb = fb[fb['n_ph'] == 1]\n",
    "        fb = fb[fb['n_el_baseline'] == 0]\n",
    "\n",
    "        # goodPV on signal only\n",
    "        if ntuple_name == 'ggHyyd':\n",
    "            fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "            good_pv_tmp = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "            fb = fb[good_pv_tmp]\n",
    "            \n",
    "        \n",
    "    if (ntuple_name == \"data23_y\") or (ntuple_name == \"data24_y\"):  # jet-faking \n",
    "        fb = f.arrays(variables, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]\n",
    "        mask1 = (ak.firsts(fb['ph_topoetcone40'])-2450.)/ak.firsts(fb['ph_pt']) > 0.1   # jet_faking_photon cut\n",
    "        fb = fb[mask1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 1]\n",
    "        fb = fb[fb['n_el_baseline'] == 0]\n",
    "\n",
    "\n",
    "    if (ntuple_name == \"data23_eprobe\") or (ntuple_name == \"data24_eprobe\"): # electron-faking\n",
    "        fb = f.arrays(variables, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "        \n",
    "        fb = fb[fb['n_el'] == 1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 0]\n",
    "\n",
    "        # using electron info for photon info\n",
    "        fb['ph_pt'] = fb['el_pt']\n",
    "        fb['ph_eta'] = fb['el_eta']\n",
    "        fb['ph_phi'] = fb['el_phi']\n",
    "        fb['dphi_met_phterm'] = fb['dphi_met_eleterm']  \n",
    "\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0] # prevent none values in Tbranch\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) >= 50000] # ph_pt cut (basic cut)\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M']==1]\n",
    "    fb = fb[fb['met_tst_et'] >= 100000] # MET cut (basic cut)\n",
    "    fb = fb[fb['n_jet_central'] <= 3] # n_jet_central cut (basic cut)\n",
    "    \n",
    "    fb['VertexBDTScore'] = fb['BDTScore'] # renaming BDTScore to ensure this is recognized as Vertex BDT Score\n",
    "    fb = fb[fb['VertexBDTScore'] > 0.1]\n",
    "    \n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "                    (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    mask1 = mt_tmp > 100\n",
    "    mask2 = mt_tmp < 140\n",
    "    fb = fb[mask1 * mask2]\n",
    "\n",
    "    # ------ Adjustment --------\n",
    "    fb['weights'] = getWeight(fb, ntuple_name)\n",
    "    \n",
    "    dphi_met_jetterm_tmp = fb['dphi_met_jetterm']\n",
    "    cond = ak.fill_none(dphi_met_jetterm_tmp == -10, False)\n",
    "    fb['dphi_met_jetterm'] = ak.where(cond, -999, dphi_met_jetterm_tmp)\n",
    "\n",
    "    fb['dphi_met_phterm'] = np.arccos(np.cos(fb['dphi_met_phterm']))\n",
    "\n",
    "    print_cut(ntuple_name, fb, 'after basic')\n",
    "\n",
    "    test(fb) # check for none value\n",
    "\n",
    "    print(f\"Reading Time for {ntuple_name}: {(time.time()-start_time)} seconds\\n\")\n",
    "\n",
    "    tot.append(fb)\n",
    "\n",
    "    del fb \n",
    "\n",
    "# combining 23d + 23e {Zgamma (1, 6), Wgamma (2, 7), gammajet_direct (3, 8)}\n",
    "# combining 2023 + 2024 {data_y (4, 9), data_eprobe (5, 10)}\n",
    "tot_tmp = tot\n",
    "tot = [tot_tmp[0]]\n",
    "for i in tqdm(range(5)):\n",
    "    tot.append(ak.concatenate([tot_tmp[i+1], tot_tmp[i+6]]))\n",
    "ntuple_names = [\"ggHyyd\", \"Zgamma\", \"Wgamma\", \"gammajet_direct\", \"data_y\", \"data_eprobe\"]\n",
    "del tot_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782e3c5-ead0-4c82-9c3b-bc05565e3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_name = 'ggHyyd'\n",
    "tot2 = []\n",
    "for i in range(len(tot)):\n",
    "    fb = tot[i]\n",
    "    # ---------- INTERNAL SELECTION CUT ------------\n",
    "    fb = fb[fb['VertexBDTScore'] > 0.1]\n",
    "    \n",
    "    metsig_tmp = fb['met_tst_sig'] \n",
    "    mask1 = metsig_tmp > 7\n",
    "    fb = fb[mask1]\n",
    "    \n",
    "    ph_eta_tmp = np.abs(ak.firsts(fb['ph_eta']))\n",
    "    fb = fb[ph_eta_tmp < 1.75]\n",
    "\n",
    "    dphi_met_phterm_tmp = fb['dphi_met_phterm']\n",
    "    fb = fb[dphi_met_phterm_tmp > 1.35]\n",
    "\n",
    "    dmet_tmp = fb['dmet']\n",
    "    fb = fb[mask1]\n",
    "\n",
    "    dphi_jj_tmp = fb['dphi_central_jj']\n",
    "    dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "    dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "    dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "    fb = fb[dphi_jj_tmp < 2.5]\n",
    "\n",
    "    dphi_met_jetterm_tmp = fb['dphi_met_jetterm']\n",
    "    fb = fb[dphi_met_jetterm_tmp < 0.75]\n",
    "    \n",
    "    '''\n",
    "    # ---------- SELECTION CUT ------------\n",
    "\n",
    "    metsig_tmp = fb['met_tst_sig'] \n",
    "    mask1 = metsig_tmp > 7\n",
    "    # fb = fb[mask1]\n",
    "    mask2 = metsig_tmp < 16\n",
    "    fb = fb[mask1 * mask2]\n",
    "    \n",
    "    ph_eta_tmp = np.abs(ak.firsts(fb['ph_eta']))\n",
    "    fb = fb[ph_eta_tmp < 1.74]\n",
    "\n",
    "    dphi_met_phterm_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])) # added cut 3\n",
    "    fb = fb[dphi_met_phterm_tmp > 1.35]\n",
    "\n",
    "    dmet_tmp = fb['met_tst_noJVT_et'] - fb['met_tst_et']\n",
    "    mask1 = dmet_tmp > -17900\n",
    "    # fb = fb[mask1]\n",
    "    mask2 = dmet_tmp < 41900\n",
    "    fb = fb[mask1 * mask2]\n",
    "\n",
    "    dphi_jj_tmp = fb['dphi_central_jj']\n",
    "    dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "    dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "    dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "    fb = fb[dphi_jj_tmp < 2.58]\n",
    "\n",
    "    dphi_met_jetterm_tmp = np.where(fb['met_jetterm_et'] != 0,   # added cut 5\n",
    "                        np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                        -999)\n",
    "    fb = fb[dphi_met_jetterm_tmp < 0.73]\n",
    "'''\n",
    "    # # ---------- FURTHER SELECTION CUT ------------\n",
    "    jet_sum_tmp = ak.sum(fb['jet_central_pt'], axis=-1)\n",
    "    expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "    balance_tmp = ak.where(jet_sum_tmp != 0, expr, -999)\n",
    "    mask_nan = balance_tmp == -999\n",
    "    mask = mask_nan | (balance_tmp > 0.90)\n",
    "    fb = fb[mask]\n",
    "\n",
    "\n",
    "    # ------------ mT cut ---------------\n",
    "    # mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "    #                     (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    # mask1 = mt_tmp > 80\n",
    "    # fb = fb[mask1]\n",
    "    # mask1 = mt_tmp > 100\n",
    "    # mask2 = mt_tmp < 140 \n",
    "    # fb = fb[mask1 * mask2]\n",
    "\n",
    "    tot2.append(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06348be4-eee2-48c8-84ea-dbac12362388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance:  1.6875358436074388\n"
     ]
    }
   ],
   "source": [
    "def compute_total_significance(tot2, ntuple_names, signal_name, getVarDict):\n",
    "    signal_sum = 0\n",
    "    bkg_sum = 0\n",
    "    for i in range(len(ntuple_names)):\n",
    "        fb = tot2[i]\n",
    "        process = ntuple_names[i]\n",
    "        weights = fb['weights']\n",
    "        if process == signal_name:\n",
    "            signal_sum += ak.sum(weights)\n",
    "        else:\n",
    "            bkg_sum += ak.sum(weights)\n",
    "    return signal_sum / np.sqrt(bkg_sum) if bkg_sum > 0 else 0\n",
    "\n",
    "sig_tmp = compute_total_significance(tot, ntuple_names, signal_name, getVarDict)\n",
    "print(\"significance: \", sig_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c03e9d-e0cb-433d-b90e-329e02d887af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef getCutDict():\\n    cut_dict = {}\\n    # Selection 1: same variables as in the internal note\\n    cut_dict['dmet'] = {\\n        'lowercut': np.arange(-30000, 10000 + 100, 100), # dmet > cut\\n        'uppercut': np.arange(10000, 100000 + 100, 100), # -10000 < dmet < cut\\n    }\\n    cut_dict['metsig'] = {\\n        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\\n        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \\n    }\\n    cut_dict['dphi_met_phterm'] = {\\n        'lowercut': np.arange(1, 2 + 0.01, 0.01), # dphi_met_phterm > cut\\n    }\\n    cut_dict['dphi_met_jetterm'] = {\\n        'uppercut': np.arange(0.5, 1, 0.01), # dphi_met_jetterm < cut\\n    }\\n    cut_dict['ph_eta'] = {\\n        'uppercut': np.arange(1, 2.5 + 0.01, 0.01), # ph_eta < cut\\n    }\\n    cut_dict['dphi_jj'] = {\\n        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\\n    }\\n\\n    # Selection 2\\n    cut_dict['balance'] = {\\n        'lowercut': np.arange(0.3, 1.5 + 0.05, 0.05), # balance > cut\\n    }\\n    cut_dict['jetterm'] = {\\n        'lowercut': np.arange(0, 150000+10000, 10000) # jetterm > cut\\n    }\\n    cut_dict['dphi_phterm_jetterm'] = {\\n        'lowercut': np.arange(1, 2.5 + 0.1, 0.1), # dphi_phterm_jetterm > cut\\n        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\\n    }\\n    cut_dict['metsigres'] = {\\n        'uppercut': np.arange(12000, 60000, 10000)\\n    }\\n    cut_dict['met_noJVT'] = {\\n        'lowercut': np.arange(50000, 120000, 10000),\\n    }\\n    \\n    return cut_dict\\ncut_config = getCutDict()\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getCutDict(): # same cut as the internal note\n",
    "    cut_dict = {}\n",
    "    cut_dict['VertexBDTScore'] = {\n",
    "        'lowercut': np.arange(0.1, 0.24, 0.02),\n",
    "    }\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 10000 + 5000, 5000), # dmet > cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(0, 2 + 0.05, 0.05), # dphi_met_phterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'uppercut': np.arange(0.5, 1, 0.05), # dphi_met_jetterm < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.05, 0.05), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.1 + 0.05, 0.05) # dphi_jj < cut\n",
    "    }\n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "\n",
    "'''\n",
    "def getCutDict():\n",
    "    cut_dict = {}\n",
    "    # Selection 1: same variables as in the internal note\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 10000 + 100, 100), # dmet > cut\n",
    "        'uppercut': np.arange(10000, 100000 + 100, 100), # -10000 < dmet < cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(1, 2 + 0.01, 0.01), # dphi_met_phterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'uppercut': np.arange(0.5, 1, 0.01), # dphi_met_jetterm < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.01, 0.01), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\n",
    "    }\n",
    "\n",
    "    # Selection 2\n",
    "    cut_dict['balance'] = {\n",
    "        'lowercut': np.arange(0.3, 1.5 + 0.05, 0.05), # balance > cut\n",
    "    }\n",
    "    cut_dict['jetterm'] = {\n",
    "        'lowercut': np.arange(0, 150000+10000, 10000) # jetterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.1, 0.1), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['metsigres'] = {\n",
    "        'uppercut': np.arange(12000, 60000, 10000)\n",
    "    }\n",
    "    cut_dict['met_noJVT'] = {\n",
    "        'lowercut': np.arange(50000, 120000, 10000),\n",
    "    }\n",
    "    \n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "701aeca3-838d-4d2b-b707-8dde8b8c0f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VertexBDTScore 0 7\n",
      "{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -20000, 'best_sig_x_acc': 1.7421825201114591, 'significance': 1.757729758830313, 'acceptance': 99.11549322978979}\n",
      "{'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6, 'best_sig_x_acc': 2.2432117059552157, 'significance': 2.4373864833736554, 'acceptance': 92.03348427740204}\n",
      "{'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 0.9500000000000001, 'best_sig_x_acc': 1.733971594184369, 'significance': 1.7439149116207298, 'acceptance': 99.42982783333622}\n",
      "{'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.8500000000000003, 'best_sig_x_acc': 1.688170825061066, 'significance': 1.6881723688763681, 'acceptance': 99.99990855108575}\n",
      "{'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 2.4000000000000012, 'best_sig_x_acc': 1.6875343003742322, 'significance': 1.6875358436074388, 'acceptance': 99.99990855108575}\n",
      "dphi_jj 42 43\n"
     ]
    }
   ],
   "source": [
    "signal_name='ggHyyd'\n",
    "initial_cut = []\n",
    "# tot2 = tot  # return the initial cut\n",
    "\n",
    "# < -- Initial Cut on all variables (maximize the significance * acceptance) -- > \n",
    "for cut_var, cut_types in cut_config.items():\n",
    "    for cut_type, cut_values in cut_types.items():\n",
    "        sig_simple_list, sigacc_simple_list, acceptance_values = calculate_significance(\n",
    "            cut_var, cut_type, cut_values, tot, ntuple_names, signal_name, getVarDict\n",
    "        )\n",
    "\n",
    "        best_cut, best_sig, idx = get_best_cut(cut_values, sigacc_simple_list) \n",
    "        \n",
    "        if idx == 0 or idx == len(sigacc_simple_list) - 1: # I chose to use index to indicate not to make unnecessary cut (for initial cut)\n",
    "            print(cut_var, idx, len(sigacc_simple_list))\n",
    "            continue\n",
    "            \n",
    "        result = {\n",
    "            \"cut_var\": cut_var,\n",
    "            \"cut_type\": cut_type,\n",
    "            \"best_cut\": best_cut,\n",
    "            \"best_sig_x_acc\": best_sig,\n",
    "            \"significance\": sig_simple_list[idx],\n",
    "            \"acceptance\": acceptance_values[idx]\n",
    "        }\n",
    "\n",
    "        print(result)\n",
    "        initial_cut.append(dict(list(result.items())[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d15f70-27f9-4ad7-82ee-4cb9c93f0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my cut\n",
    "initial_cut = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 2.4},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 0.95},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -20000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.85},\n",
    "]\n",
    "\n",
    "\n",
    "# internal note cut (just in case)\n",
    "# initial_cut = [\n",
    "#     {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "#     {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6},\n",
    "#     {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "#     {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "#     {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -20000},\n",
    "#     {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "#     {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6e9d45-ced3-4179-ac43-65aa2394e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after initial cutting, signficance:  2.5845005666830088\n"
     ]
    }
   ],
   "source": [
    "tot2_initial_cut = apply_all_cuts(tot, ntuple_names, initial_cut, getVarDict)\n",
    "final_significance = compute_total_significance(tot2_initial_cut, ntuple_names, signal_name, getVarDict)\n",
    "print('after initial cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "435c829b-a8dd-45eb-a394-b3fb350ebacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "Updating VertexBDTScore (lowercut): 0.1 → 0.12000000000000001  (N-1 2.585 → with-cut 2.594)\n",
      "Updating metsig (lowercut): 6 → 8  (N-1 1.904 → with-cut 2.709)\n",
      "Updating ph_eta (uppercut): 2.4 → 1.7500000000000007  (N-1 2.709 → with-cut 2.829)\n",
      "Updating dphi_met_phterm (lowercut): 0.95 → 1.2000000000000002  (N-1 2.773 → with-cut 2.845)\n",
      "Updating dphi_jj (uppercut): 2.5 → 2.300000000000001  (N-1 2.798 → with-cut 2.854)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Updating metsig (lowercut): 8.0 → 7  (N-1 2.083 → with-cut 2.869)\n",
      "Updating dmet (lowercut): -20000 → -15000  (N-1 2.813 → with-cut 2.871)\n",
      "Updating dphi_jj (uppercut): 2.300000000000001 → 2.3500000000000014  (N-1 2.812 → with-cut 2.871)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Updating VertexBDTScore (lowercut): 0.12000000000000001 → 0.1  (N-1 2.873 → with-cut 2.873)\n",
      "\n",
      "--- Iteration 4 ---\n",
      "optimized cuts, end of iteration\n",
      "after optimized cutting, signficance:  2.8734646861177247\n",
      "CPU times: user 45.9 s, sys: 122 ms, total: 46 s\n",
      "Wall time: 46.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "# < -- n-1 iterations until no further improvement (max significance) -- >\n",
    "optimized_cuts, final_significance = n_minus_1_optimizer(\n",
    "    initial_cut, cut_config, tot2_initial_cut, ntuple_names, signal_name, getVarDict, final_significance, allow_drop=True\n",
    ")\n",
    "print('after optimized cutting, signficance: ', final_significance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "046f0a65-fada-4152-9fdb-b68f5222ede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " < -- Final Optimized Cuts -- > \n",
      "VertexBDTScore > 0.1\n",
      "metsig > 7.0\n",
      "ph_eta < 1.7500000000000007\n",
      "dphi_met_phterm > 1.2000000000000002\n",
      "dmet > -15000.0\n",
      "dphi_jj < 2.3500000000000014\n",
      "dphi_met_jetterm < 0.85\n",
      "after optimized cutting, signficance:  2.8462060684579473\n"
     ]
    }
   ],
   "source": [
    "print( ' < -- Final Optimized Cuts -- > ')\n",
    "# print(optimized_cuts)\n",
    "\n",
    "for cut in optimized_cuts:\n",
    "    var = cut['cut_var']\n",
    "    val = cut['best_cut']\n",
    "    if cut['cut_type'] == 'uppercut':\n",
    "        print(f\"{var} < {val}\")\n",
    "    elif cut['cut_type'] == 'lowercut':\n",
    "        print(f\"{var} > {val}\")\n",
    "        \n",
    "print('after optimized cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a5df7e9-0dbd-4b83-9c54-3e3fb9ef2184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< -- Sum of weight each process -- >\n",
      "ggHyyd 193.8945\n",
      "Zgamma 512.39087\n",
      "Wgamma 976.59406\n",
      "gammajet_direct 43.55256\n",
      "data_y 1295.4519999999948\n",
      "data_eprobe 1725.237019880597\n"
     ]
    }
   ],
   "source": [
    "tot2_optimized_cuts = apply_all_cuts(tot, ntuple_names, optimized_cuts, getVarDict)\n",
    "\n",
    "print('< -- Sum of weight each process -- >')\n",
    "\n",
    "for i in range(len(tot2_optimized_cuts)):\n",
    "    print(ntuple_names[i], ak.sum(tot2_optimized_cuts[i]['weights']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "617519cd-9838-4142-a601-9a0d47ecee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< -- Sum of weight each process -- >\n",
      "ggHyyd 286.17126\n",
      "Zgamma 1063.357\n",
      "Wgamma 2127.965\n",
      "gammajet_direct 4646.3975\n",
      "data_y 14420.580999998801\n",
      "data_eprobe 6498.862011968874\n"
     ]
    }
   ],
   "source": [
    "print('< -- Sum of weight each process -- >')\n",
    "\n",
    "for i in range(len(tot2_optimized_cuts)):\n",
    "    print(ntuple_names[i], ak.sum(tot[i]['weights']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8342146-c9e5-4012-bfc9-d51dd8b48241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after initial cutting, signficance:  2.8462060684579473\n"
     ]
    }
   ],
   "source": [
    "# internal note cut (just in case)\n",
    "initial_cut = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.20},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -15000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "]\n",
    "final_significance = compute_total_significance(apply_all_cuts(tot, ntuple_names, initial_cut, getVarDict), ntuple_names, signal_name, getVarDict)\n",
    "# final_significance = compute_total_significance(apply_all_cuts(tot, ntuple_names, optimized_cuts, getVarDict), ntuple_names, signal_name, getVarDict)\n",
    "print('after initial cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be17b0ec-4c6f-415d-a17e-668891cb4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(tot2, ntuple_names, sample_dict, getVarDict, mt_val_dir, cut_name, signal_name='ggHyyd'):\n",
    "    var_config = getVarDict(tot2[0], 'ggHyyd', )\n",
    "    \n",
    "    for var in var_config:\n",
    "        bg_values = []     \n",
    "        bg_weights = []    \n",
    "        bg_colors = []     \n",
    "        bg_labels = []     \n",
    "    \n",
    "        signal_values = [] \n",
    "        signal_weights = []\n",
    "        signal_color = None \n",
    "        signal_label = None\n",
    "    \n",
    "        for j in range(len(ntuple_names)):\n",
    "            process = ntuple_names[j]\n",
    "            fb = tot2[j]  # TTree\n",
    "            var_config = getVarDict(fb, process, var_name=var)\n",
    "    \n",
    "            x = var_config[var]['var'] # TBranch\n",
    "            bins = var_config[var]['bins'] \n",
    "            weights = fb['weights']\n",
    "            \n",
    "            sample_info = sample_dict[process]\n",
    "            color = sample_info['color']\n",
    "            legend = sample_info['legend']\n",
    "    \n",
    "            \n",
    "            if process == 'ggHyyd':  # signal\n",
    "                signal_values.append(x)\n",
    "                signal_weights.append(weights)\n",
    "                signal_color = color\n",
    "                signal_label = legend\n",
    "            else:   # background\n",
    "                bg_values.append(x)\n",
    "                bg_weights.append(weights)\n",
    "                bg_colors.append(color)\n",
    "                bg_labels.append(legend)\n",
    "    \n",
    "        fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(12, 13), gridspec_kw={'height_ratios': [9, 4]})\n",
    "    \n",
    "        ax_top.hist(bg_values, bins=bins, weights=bg_weights, color=bg_colors,\n",
    "                    label=bg_labels, stacked=True)\n",
    "    \n",
    "        ax_top.hist(signal_values, bins=bins, weights=signal_weights, color=signal_color,\n",
    "                    label=signal_label, histtype='step', linewidth=2)\n",
    "    \n",
    "        signal_all = np.concatenate(signal_values) if len(signal_values) > 0 else np.array([])\n",
    "        signal_weights_all = np.concatenate(signal_weights) if len(signal_weights) > 0 else np.array([])\n",
    "    \n",
    "        # Add error bar for signal (top plot)\n",
    "        if len(signal_all) > 0:\n",
    "            signal_counts, bin_edges = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "            sum_weights_sq, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all**2)\n",
    "            bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "            signal_errors = np.sqrt(sum_weights_sq)  # Poisson error sqrt(N)\n",
    "    \n",
    "            ax_top.errorbar(bin_centers, signal_counts, yerr=signal_errors, fmt='.', linewidth=2,\n",
    "                            color=signal_color, capsize=0)\n",
    "    \n",
    "        ax_top.set_yscale('log')\n",
    "        ax_top.set_ylim(0.0001, 1e11)\n",
    "        ax_top.set_xlim(bins[0], bins[-1])\n",
    "        ax_top.minorticks_on()\n",
    "        ax_top.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        ax_top.set_ylabel(\"Events\")\n",
    "        ax_top.legend(ncol=2)\n",
    "    \n",
    "        bg_all = np.concatenate(bg_values) if len(bg_values) > 0 else np.array([])\n",
    "        bg_weights_all = np.concatenate(bg_weights) if len(bg_weights) > 0 else np.array([])\n",
    "    \n",
    "        # Compute the weighted histogram counts using np.histogram\n",
    "        S_counts, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "        B_counts, _ = np.histogram(bg_all, bins=bins, weights=bg_weights_all)     \n",
    "    \n",
    "        # Compute per-bin significance\n",
    "        sig_simple = np.zeros_like(S_counts, dtype=float)\n",
    "        sig_s_plus_b = np.zeros_like(S_counts, dtype=float)\n",
    "        sig_s_plus_1p3b = np.zeros_like(S_counts, dtype=float)\n",
    "    \n",
    "        sqrt_B = np.sqrt(B_counts)\n",
    "        sqrt_SplusB = np.sqrt(S_counts + B_counts)\n",
    "        sqrt_Splus1p3B = np.sqrt(S_counts + 1.3 * B_counts)\n",
    "    \n",
    "        # Avoid division by zero safely\n",
    "        sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0)\n",
    "        sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0)\n",
    "        sig_s_plus_1p3b = np.where((S_counts + 1.3 * B_counts) > 0, S_counts / sqrt_Splus1p3B, 0)\n",
    "    \n",
    "        # Add Binomial ExpZ per bin\n",
    "        zbi_per_bin = np.array([\n",
    "            zbi(S_counts[i], B_counts[i], sigma_b_frac=0.3)\n",
    "            for i in range(len(S_counts))\n",
    "        ])\n",
    "    \n",
    "        # Compute the bin centers for plotting\n",
    "        bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "    \n",
    "        # Compute the total significance: total S / sqrt(total B)\n",
    "        total_signal = np.sum(S_counts)\n",
    "        total_bkg = np.sum(B_counts)\n",
    "    \n",
    "        if total_bkg > 0:\n",
    "            total_sig_simple = total_signal / np.sqrt(total_bkg)\n",
    "            total_sig_s_plus_b = total_signal / np.sqrt(total_signal + total_bkg)\n",
    "            total_sig_s_plus_1p3b = total_signal / np.sqrt(total_signal + 1.3 * total_bkg)\n",
    "            total_sig_binomial = zbi(total_signal, total_bkg, sigma_b_frac=0.3)\n",
    "        else:\n",
    "            total_sig_simple = total_sig_s_plus_b = total_sig_s_plus_1p3b = total_sig_binomial = 0\n",
    "    \n",
    "        # --- Plot all significance curves ---\n",
    "        ax_bot.step(bin_centers, sig_simple, where='mid', color='chocolate', linewidth=2,\n",
    "                    label=f\"S/√B = {total_sig_simple:.4f}\")\n",
    "        ax_bot.step(bin_centers, sig_s_plus_b, where='mid', color='tomato', linewidth=2,\n",
    "                    label=f\"S/√(S+B) = {total_sig_s_plus_b:.4f}\")\n",
    "        ax_bot.step(bin_centers, sig_s_plus_1p3b, where='mid', color='orange', linewidth=2,\n",
    "                    label=f\"S/√(S+1.3B) = {total_sig_s_plus_1p3b:.4f}\")\n",
    "        ax_bot.step(bin_centers, zbi_per_bin, where='mid', color='plum', linewidth=2,\n",
    "                    label=f\"Binomial ExpZ = {total_sig_binomial:.4f}\")\n",
    "    \n",
    "        ax_bot.set_xlabel(var_config[var]['title'])\n",
    "        # ax_bot.set_xticks(np.linspace(bins[0], bins[-1], 11))\n",
    "        ax_bot.set_ylabel(\"Significance\")\n",
    "        # ax_bot.set_ylim(-0.8, 2)\n",
    "        ax_top.set_xlim(bins[0], bins[-1])\n",
    "    \n",
    "        # Do not set a title on the bottom plot.\n",
    "        ax_bot.set_title(\"\")\n",
    "    \n",
    "        # Draw a legend with purple text.\n",
    "        leg = ax_bot.legend()\n",
    "        for text in leg.get_texts():\n",
    "            text.set_color('purple')\n",
    "    \n",
    "        plt.xlim(bins[0], bins[-1])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/home/jlai/dark_photon/main/{mt_val_dir}/{cut_name}cut/{var}.png\")\n",
    "        print(f\"successfully saved to /home/jlai/dark_photon/main/{mt_val_dir}/{cut_name}cut/{var}.png\")\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "    \n",
    "        y_true = np.concatenate([np.ones_like(signal_all), np.zeros_like(bg_all)])\n",
    "        y_scores = np.concatenate([signal_all, bg_all])\n",
    "        # Combine the weights for all events.\n",
    "        y_weights = np.concatenate([signal_weights_all, bg_weights_all])\n",
    "    \n",
    "        # Compute the weighted ROC curve.\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_scores, sample_weight=y_weights)\n",
    "        sorted_indices = np.argsort(fpr)\n",
    "        fpr_sorted = fpr[sorted_indices]\n",
    "        tpr_sorted = tpr[sorted_indices]\n",
    "    \n",
    "        roc_auc = auc(fpr_sorted, tpr_sorted)\n",
    "    \n",
    "        # Create a new figure for the ROC curve.\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(fpr, tpr, lw=2, color='red', label=f'ROC curve (AUC = {roc_auc:.5f})')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random chance')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"ROC Curve for {var}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        plt.tight_layout()    \n",
    "        plt.savefig(f\"/home/jlai/dark_photon/main/{mt_val_dir}/{cut_name}cut/roc_curve_{var}.png\")\n",
    "        plt.close()\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84d051b6-b485-4ec5-a815-ff440ac67d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/n_ph.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/n_ph_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/n_el.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/n_el_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/n_mu_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/n_tau_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/mt.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/metsig.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n",
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/metsigres.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/met.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/met_noJVT.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/dmet.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/ph_pt.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/ph_eta.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/ph_phi.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/pv_ntracks.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/jet_central_eta.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/jet_central_vecSumPt.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/jet_central_pt1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/jet_central_pt2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/dphi_met_phterm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/dphi_met_jetterm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/dphi_phterm_jetterm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/failJVT_jet_pt1.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/failJVT_jet_vecSumPt.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/softerm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/jetterm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/jetterm_sumet.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/n_jet.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/n_jet_central.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/n_jet_fwd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/central_jets_fraction.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n",
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/balance.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/dphi_jj.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/selectioncut/VertexBDTScore.png\n"
     ]
    }
   ],
   "source": [
    "# path for plot storage\n",
    "mt_val_dir = 'mt100_140'\n",
    "cut_name = 'selection'\n",
    "\n",
    "# plot_performance(tot, ntuple_names, sample_dict, getVarDict, mt_val_dir, cut_name) # basic\n",
    "plot_performance(tot2_optimized_cuts, ntuple_names, sample_dict, getVarDict, mt_val_dir, cut_name) # selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6408753a-9946-42dd-86d7-bb579470da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_VertexBDTScore_lowercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2490/886220581.py:310: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:311: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:312: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/VertexBDTScore.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_VertexBDTScore.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_metsig_lowercut.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/metsig.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_metsig.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_ph_eta_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2490/886220581.py:310: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:311: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:312: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/ph_eta.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_ph_eta.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dmet_lowercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2490/886220581.py:310: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:311: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:312: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dmet.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dmet.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dphi_jj_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2490/886220581.py:310: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:311: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:312: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dphi_jj.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dphi_jj.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dphi_met_phterm_lowercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2490/886220581.py:310: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:311: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:312: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dphi_met_phterm.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dphi_met_phterm.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/significance_dphi_met_jetterm_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2490/886220581.py:310: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:311: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
      "/tmp/ipykernel_2490/886220581.py:312: RuntimeWarning: invalid value encountered in divide\n",
      "  sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/dphi_met_jetterm.png\n",
      "Saved: /home/jlai/dark_photon/main/mt100_140/n-1cut/roc_curve_dphi_met_jetterm.png\n"
     ]
    }
   ],
   "source": [
    "# --- config ---\n",
    "mt_val_dir = 'mt100_140'\n",
    "n_1_config = [\"VertexBDTScore\", \"metsig\", \"ph_eta\", \"dmet\", \"dphi_jj\", \"dphi_met_phterm\", \"dphi_met_jetterm\"]\n",
    "signal_name = 'ggHyyd'\n",
    "cut_name = 'n-1' \n",
    "\n",
    "# --- helpers ---\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def ensure_dir(path_str):\n",
    "    Path(path_str).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def to_np(a):\n",
    "    \"\"\"Flatten awkward/numpy to 1D numpy array; empty-safe.\"\"\"\n",
    "    if a is None:\n",
    "        return np.array([])\n",
    "    try:\n",
    "        import awkward as ak\n",
    "        if hasattr(ak, \"to_numpy\"):\n",
    "            return ak.to_numpy(ak.flatten(a, axis=None))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.asarray(a).ravel()\n",
    "\n",
    "def safe_concat(list_of_arrays):\n",
    "    \"\"\"Concatenate list of arrays safely (possibly empty).\"\"\"\n",
    "    if len(list_of_arrays) == 0:\n",
    "        return np.array([])\n",
    "    arrs = [to_np(x) for x in list_of_arrays if x is not None]\n",
    "    return np.concatenate(arrs) if len(arrs) else np.array([])\n",
    "\n",
    "def safe_hist(x, bins, w=None):\n",
    "    if x.size == 0:\n",
    "        return np.zeros(len(bins)-1, dtype=float), bins\n",
    "    return np.histogram(x, bins=bins, weights=w)\n",
    "\n",
    "def sel(tot, n_1_name=None):\n",
    "    \"\"\"\n",
    "    Apply baseline cuts to all fb in tot except the variable named by n_1_name.\n",
    "    \"\"\"\n",
    "    import awkward as ak\n",
    "    out = []\n",
    "    for i in range(len(tot)):\n",
    "        fb2 = tot[i]\n",
    "\n",
    "        # VertexBDTScore > 0.12 (unless N-1 on it)\n",
    "        if n_1_name != \"VertexBDTScore\":\n",
    "            fb2 = fb2[fb2['VertexBDTScore'] >= 0.1]\n",
    "\n",
    "        # metsig: 7 <= met_tst_sig <= 16 (only lower applied previously; fix & allow N-1)\n",
    "        if n_1_name != \"metsig\":\n",
    "            metsig_tmp = fb2['met_tst_sig']\n",
    "            fb2 = fb2[(metsig_tmp > 7)]\n",
    "\n",
    "        # photon |eta| < 1.75\n",
    "        if n_1_name != \"ph_eta\":\n",
    "            ph_eta_tmp = np.abs(ak.firsts(fb2['ph_eta']))\n",
    "            fb2 = fb2[ph_eta_tmp < 1.75]\n",
    "\n",
    "        # dmet in [-15000, 50000]\n",
    "        if n_1_name != \"dmet\":\n",
    "            dmet_tmp = fb2['dmet']\n",
    "            fb2 = fb2[(dmet_tmp >= -15000)]\n",
    "\n",
    "        # dphi_met_jetterm < 0.8\n",
    "        if n_1_name != \"dphi_met_jetterm\":\n",
    "            dphi_met_jetterm_tmp = fb2['dphi_met_jetterm']\n",
    "            fb2 = fb2[dphi_met_jetterm_tmp <= 0.85]\n",
    "\n",
    "        # dphi_jj < 2.3   (fix fb->fb2, keep wrap into [0,pi], treat sentinel -10)\n",
    "        if n_1_name != \"dphi_jj\":\n",
    "            dphi_jj_tmp = fb2['dphi_central_jj']\n",
    "            dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "            dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "            dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "            fb2 = fb2[dphi_jj_tmp <= 2.35]\n",
    "\n",
    "        out.append(fb2)\n",
    "    return out\n",
    "\n",
    "def getCutDict(n_1_name=None):\n",
    "    cut_dict = {}\n",
    "    if n_1_name is None or n_1_name == \"VertexBDTScore\":\n",
    "        cut_dict['VertexBDTScore'] = {'lowercut': np.arange(0.10, 0.24, 0.02)}\n",
    "    if n_1_name is None or n_1_name == \"dmet\":\n",
    "        cut_dict['dmet'] = {'lowercut': np.arange(-30000, 10000 + 5000, 5000)}\n",
    "    if n_1_name is None or n_1_name == \"metsig\":\n",
    "        cut_dict['metsig'] = {'lowercut': np.arange(0, 10 + 1, 1)}\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_phterm\":\n",
    "        cut_dict['dphi_met_phterm'] = {'lowercut': np.arange(1, 2 + 0.05, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_jetterm\":\n",
    "        cut_dict['dphi_met_jetterm'] = {'uppercut': np.arange(0.5, 1.00, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"ph_eta\":\n",
    "        cut_dict['ph_eta'] = {'uppercut': np.arange(1.0, 2.50 + 0.05, 0.05)}\n",
    "    if n_1_name is None or n_1_name == \"dphi_jj\":\n",
    "        cut_dict['dphi_jj'] = {'uppercut': np.arange(1.0, 3.10 + 0.05, 0.05)}\n",
    "    return cut_dict\n",
    "\n",
    "# You already have calculate_significance(cut_var, cut_type, cut_values)\n",
    "# assuming it uses global ntuple_names, sample_dict, tot2, signal_name, etc.\n",
    "\n",
    "# ---------- N-1 scan + plots ----------\n",
    "\n",
    "out_base = f\"/home/jlai/dark_photon/main/{mt_val_dir}/{cut_name}cut\"\n",
    "ensure_dir(out_base)\n",
    "\n",
    "def calculate_significance(cut_var, cut_type, cut_values):\n",
    "    sig_simple_list = []\n",
    "    sig_s_plus_b_list = []\n",
    "    sig_s_plus_1p3b_list = []\n",
    "    sig_binomial_list = []\n",
    "\n",
    "    sigacc_simple_list = []\n",
    "    sigacc_s_plus_b_list = []\n",
    "    sigacc_s_plus_1p3b_list = []\n",
    "    sigacc_binomial_list = []\n",
    "\n",
    "    acceptance_values = []  # Store acceptance percentages\n",
    "\n",
    "    for cut in cut_values:\n",
    "        sig_after_cut = 0\n",
    "        bkg_after_cut = []\n",
    "        sig_events = 0\n",
    "        \n",
    "        for i in range(len(ntuple_names)):\n",
    "            fb = tot2[i]\n",
    "            process = ntuple_names[i]\n",
    "            var_config = getVarDict(fb, process, var_name=cut_var)\n",
    "            x = var_config[cut_var]['var']\n",
    "            mask = x != -999 # Apply cut: Remove -999 values \n",
    "            x = x[mask]\n",
    "\n",
    "            if process == signal_name:\n",
    "                sig_events = fb['weights']\n",
    "                sig_events = sig_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                sig_after_cut = ak.sum(sig_events[mask])\n",
    "            \n",
    "            else:\n",
    "                bkg_events = fb['weights']\n",
    "                bkg_events = bkg_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                bkg_after_cut.append(ak.sum(bkg_events[mask]))\n",
    "\n",
    "       # Now compute different types of significance\n",
    "        total_bkg = sum(bkg_after_cut)\n",
    "        total_signal = sig_after_cut\n",
    "\n",
    "        # Avoid zero division carefully\n",
    "        if total_bkg > 0:\n",
    "            sig_simple = total_signal / np.sqrt(total_bkg)\n",
    "            sig_s_plus_b = total_signal / np.sqrt(total_signal + total_bkg) if (total_signal + total_bkg) > 0 else 0\n",
    "            sig_s_plus_1p3b = total_signal / np.sqrt(total_signal + 1.3 * total_bkg) if (total_signal + 1.3*total_bkg) > 0 else 0\n",
    "            sig_binomial = zbi(total_signal, total_bkg, sigma_b_frac=0.3)\n",
    "        else:\n",
    "            sig_simple = sig_s_plus_b = sig_s_plus_1p3b = sig_binomial = 0\n",
    "\n",
    "        # Acceptance\n",
    "        acceptance = total_signal / sum(sig_events) if sum(sig_events) > 0 else 0\n",
    "        acceptance_values.append(acceptance * 100)  # percentage\n",
    "\n",
    "        # Save significance\n",
    "        sig_simple_list.append(sig_simple)\n",
    "        sig_s_plus_b_list.append(sig_s_plus_b)\n",
    "        sig_s_plus_1p3b_list.append(sig_s_plus_1p3b)\n",
    "        sig_binomial_list.append(sig_binomial)\n",
    "\n",
    "        # Save significance × acceptance\n",
    "        sigacc_simple_list.append(sig_simple * acceptance)\n",
    "        sigacc_s_plus_b_list.append(sig_s_plus_b * acceptance)\n",
    "        sigacc_s_plus_1p3b_list.append(sig_s_plus_1p3b * acceptance)\n",
    "        sigacc_binomial_list.append(sig_binomial * acceptance)\n",
    "\n",
    "    return (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "            sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "            acceptance_values)\n",
    "\n",
    "\n",
    "for cut_var_tmp in n_1_config:\n",
    "    # Build cut grid for THIS n-1 variable and apply baseline to all others\n",
    "    cut_config = getCutDict(n_1_name=cut_var_tmp)\n",
    "    tot2 = sel(tot, n_1_name=cut_var_tmp)\n",
    "\n",
    "    # --- Significance vs cut scans for this n-1 variable ---\n",
    "    for cut_var, cut_types in cut_config.items():\n",
    "        for cut_type, cut_values in cut_types.items():\n",
    "            (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "             sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "             acceptance_values) = calculate_significance(cut_var, cut_type, cut_values)\n",
    "\n",
    "            fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "\n",
    "            # Top: S/sqrt(B) and vertical line at max\n",
    "            i_max = int(np.argmax(sig_simple_list)) if len(sig_simple_list) else 0\n",
    "            max_tmp = float(cut_values[i_max]) if len(cut_values) else np.nan\n",
    "            if len(cut_values):\n",
    "                ax_top.axvline(x=max_tmp, color='r', linestyle='--', label=f'Max S/√B at {max_tmp:.2f}')\n",
    "            ax_top.plot(cut_values, sig_simple_list, marker='o', label='S/√B')\n",
    "            # Uncomment if you want the other metrics on same plot:\n",
    "            # ax_top.plot(cut_values, sig_s_plus_b_list, marker='s', label='S/√(S+B)')\n",
    "            # ax_top.plot(cut_values, sig_s_plus_1p3b_list, marker='^', label='S/√(S+1.3B)')\n",
    "            # ax_top.plot(cut_values, sig_binomial_list, marker='x', label='BinomialExpZ')\n",
    "            ax_top.set_ylabel('Significance')\n",
    "            ax_top.set_title(f'N-1: {cut_var_tmp} — Significance vs. {cut_var} ({cut_type})')\n",
    "            ax_top.grid(True)\n",
    "            ax_top.legend()\n",
    "\n",
    "            # Bottom: (S/√B) × Acceptance\n",
    "            if len(cut_values):\n",
    "                ax_bot.axvline(x=max_tmp, color='r', linestyle='--')\n",
    "            ax_bot.plot(cut_values, sigacc_simple_list, marker='o', label='(S/√B) × Acceptance')\n",
    "\n",
    "            for i, acc in enumerate(acceptance_values):\n",
    "                ax_bot.text(cut_values[i], sigacc_simple_list[i], f'{acc:.1f}%',\n",
    "                            fontsize=9, ha='right', va='bottom', color='purple')\n",
    "\n",
    "            # Label with pretty var title\n",
    "            var_cfg_for_label = getVarDict(tot2[0], signal_name, cut_var)\n",
    "            ax_bot.set_xlabel(var_cfg_for_label[cut_var]['title'])\n",
    "            ax_bot.set_ylabel('Significance × Acceptance')\n",
    "            ax_bot.grid(True)\n",
    "            ax_bot.legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            out_path = f\"{out_base}/significance_{cut_var}_{cut_type}.png\"\n",
    "            ensure_dir(Path(out_path).parent.as_posix())\n",
    "            plt.savefig(out_path)\n",
    "            print(f\"Saved: {out_path}\")\n",
    "            plt.close()\n",
    "\n",
    "    # --- N-1 distributions + per-bin significance & ROC for THIS variable ---\n",
    "    var_cfg_sig = getVarDict(tot2[0], signal_name, var_name=cut_var_tmp)  # only request this var\n",
    "    for var in var_cfg_sig:\n",
    "        bg_vals, bg_wts, bg_cols, bg_labs = [], [], [], []\n",
    "        sig_vals, sig_wts = [], []\n",
    "        sig_col = None\n",
    "        sig_lab = None\n",
    "\n",
    "        # Build stacks\n",
    "        for j in range(len(ntuple_names)):\n",
    "            process = ntuple_names[j]\n",
    "            fb2 = tot2[j]\n",
    "            var_cfg = getVarDict(fb2, process, var_name=var)\n",
    "            x = var_cfg[var]['var']\n",
    "            bins = var_cfg[var]['bins']\n",
    "            weights = fb2['weights']\n",
    "\n",
    "            info = sample_dict[process]\n",
    "            if process == signal_name:\n",
    "                sig_vals.append(x)\n",
    "                sig_wts.append(weights)\n",
    "                sig_col = info['color']; sig_lab = info['legend']\n",
    "            else:\n",
    "                bg_vals.append(x); bg_wts.append(weights)\n",
    "                bg_cols.append(info['color']); bg_labs.append(info['legend'])\n",
    "\n",
    "        # Convert/concat\n",
    "        sig_all = safe_concat(sig_vals)\n",
    "        sig_w_all = safe_concat(sig_wts)\n",
    "        bg_all = safe_concat(bg_vals)\n",
    "        bg_w_all = safe_concat(bg_wts)\n",
    "\n",
    "        # Figure / axes\n",
    "        fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(12, 13), gridspec_kw={'height_ratios':[9,4]})\n",
    "\n",
    "        # Stacked BG + signal outline\n",
    "        if len(bg_vals):\n",
    "            ax_top.hist([to_np(v) for v in bg_vals], bins=bins,\n",
    "                        weights=[to_np(w) for w in bg_wts], color=bg_cols,\n",
    "                        label=bg_labs, stacked=True)\n",
    "        if sig_all.size:\n",
    "            ax_top.hist(sig_all, bins=bins, weights=sig_w_all, color=sig_col,\n",
    "                        label=sig_lab, histtype='step', linewidth=2)\n",
    "\n",
    "            # Signal error bars\n",
    "            s_counts, s_edges = safe_hist(sig_all, bins=bins, w=sig_w_all)\n",
    "            s2, _ = safe_hist(sig_all, bins=bins, w=sig_w_all**2 if sig_w_all.size else None)\n",
    "            bin_centers = 0.5*(s_edges[:-1] + s_edges[1:])\n",
    "            s_err = np.sqrt(s2)\n",
    "            ax_top.errorbar(bin_centers, s_counts, yerr=s_err, fmt='.', linewidth=2,\n",
    "                            color=sig_col, capsize=0)\n",
    "\n",
    "        ax_top.set_yscale('log')\n",
    "        ax_top.set_ylim(max(1e-4, 1e-6), 1e11)\n",
    "        ax_top.set_xlim(bins[0], bins[-1])\n",
    "        ax_top.minorticks_on()\n",
    "        ax_top.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        ax_top.set_ylabel(\"Events\")\n",
    "        ax_top.legend(ncol=2)\n",
    "\n",
    "        # Per-bin significance curves\n",
    "        S_counts, _ = safe_hist(sig_all, bins=bins, w=sig_w_all)\n",
    "        B_counts, _ = safe_hist(bg_all, bins=bins, w=bg_w_all)\n",
    "\n",
    "        sqrt_B = np.sqrt(np.clip(B_counts, 0, None))\n",
    "        sqrt_SplusB = np.sqrt(np.clip(S_counts + B_counts, 0, None))\n",
    "        sqrt_Splus1p3B = np.sqrt(np.clip(S_counts + 1.3*B_counts, 0, None))\n",
    "\n",
    "        sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0.0)\n",
    "        sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0.0)\n",
    "        sig_s_plus_1p3b = np.where((S_counts + 1.3*B_counts) > 0, S_counts / sqrt_Splus1p3B, 0.0)\n",
    "\n",
    "        # Binomial ExpZ per bin\n",
    "        zbi_per_bin = np.array([zbi(S_counts[i], B_counts[i], sigma_b_frac=0.3) for i in range(len(S_counts))])\n",
    "\n",
    "        bin_centers = 0.5*(bins[:-1] + bins[1:])\n",
    "\n",
    "        # Totals\n",
    "        S_tot = float(np.sum(S_counts))\n",
    "        B_tot = float(np.sum(B_counts))\n",
    "        if B_tot > 0:\n",
    "            tot_SsqrtB = S_tot / np.sqrt(B_tot)\n",
    "            tot_SsqrtSB = S_tot / np.sqrt(S_tot + B_tot) if (S_tot + B_tot) > 0 else 0\n",
    "            tot_SsqrtS1p3B = S_tot / np.sqrt(S_tot + 1.3*B_tot) if (S_tot + 1.3*B_tot) > 0 else 0\n",
    "            tot_zbi = zbi(S_tot, B_tot, sigma_b_frac=0.3)\n",
    "        else:\n",
    "            tot_SsqrtB = tot_SsqrtSB = tot_SsqrtS1p3B = tot_zbi = 0.0\n",
    "\n",
    "        ax_bot.step(bin_centers, sig_simple, where='mid', linewidth=2,\n",
    "                    label=f\"S/√B = {tot_SsqrtB:.4f}\", color='chocolate')\n",
    "        ax_bot.step(bin_centers, sig_s_plus_b, where='mid', linewidth=2,\n",
    "                    label=f\"S/√(S+B) = {tot_SsqrtSB:.4f}\", color='tomato')\n",
    "        ax_bot.step(bin_centers, sig_s_plus_1p3b, where='mid', linewidth=2,\n",
    "                    label=f\"S/√(S+1.3B) = {tot_SsqrtS1p3B:.4f}\", color='orange')\n",
    "        ax_bot.step(bin_centers, zbi_per_bin, where='mid', linewidth=2,\n",
    "                    label=f\"Binomial ExpZ = {tot_zbi:.4f}\", color='plum')\n",
    "\n",
    "        ax_bot.set_xlabel(var_cfg_sig[var]['title'])\n",
    "        ax_bot.set_ylabel(\"Significance\")\n",
    "        ax_bot.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        ax_bot.set_title(\"\")\n",
    "        leg = ax_bot.legend()\n",
    "        for t in leg.get_texts():\n",
    "            t.set_color('purple')\n",
    "\n",
    "        plt.xlim(bins[0], bins[-1])\n",
    "        plt.tight_layout()\n",
    "\n",
    "        dist_dir = f\"{out_base}\"\n",
    "        ensure_dir(dist_dir)\n",
    "        out_png = f\"{dist_dir}/{var}.png\"\n",
    "        plt.savefig(out_png)\n",
    "        print(f\"Saved: {out_png}\")\n",
    "        plt.close()\n",
    "\n",
    "        # ROC using this single variable as score\n",
    "        y_true = np.concatenate([np.ones_like(S_counts).repeat(1)])  # placeholder to silence lints\n",
    "        # Build event-wise arrays, not binned:\n",
    "        y_true = np.concatenate([np.ones(sig_all.shape[0], dtype=int), np.zeros(bg_all.shape[0], dtype=int)])\n",
    "        y_scores = np.concatenate([sig_all, bg_all])\n",
    "        y_w = np.concatenate([sig_w_all if sig_w_all.size else np.ones(sig_all.shape[0]),\n",
    "                              bg_w_all if bg_w_all.size else np.ones(bg_all.shape[0])])\n",
    "\n",
    "        if y_scores.size and np.unique(y_true).size == 2:\n",
    "            fpr, tpr, thr = roc_curve(y_true, y_scores, sample_weight=y_w)\n",
    "            order = np.argsort(fpr)\n",
    "            roc_auc = auc(fpr[order], tpr[order])\n",
    "\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.plot(fpr, tpr, lw=2, label=f'ROC (AUC = {roc_auc:.5f})')\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--', label='Random')\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.title(f\"N-1 ROC — {var}\")\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "            plt.tight_layout()\n",
    "            out_png = f\"{dist_dir}/roc_curve_{var}.png\"\n",
    "            plt.savefig(out_png)\n",
    "            print(f\"Saved: {out_png}\")\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7aea22-56fd-4cae-8160-6c82a02d295a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
