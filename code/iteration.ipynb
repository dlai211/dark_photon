{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd91d671-f884-4af4-88f1-975e1e3caeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mc23d_ggHyyd_y Unweighted Events before cut:  17999\n",
      "mc23d_ggHyyd_y Weighted Events before cut:  476.41051071983003\n",
      "mc23d_ggHyyd_y Unweighted Events after basic:  2627\n",
      "mc23d_ggHyyd_y Weighted Events after basic:  71.04948243695699\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_ggHyyd_y: 0.39095211029052734 seconds\n",
      "\n",
      "mc23d_Zgamma_y Unweighted Events before cut:  2520609\n",
      "mc23d_Zgamma_y Weighted Events before cut:  21734.468674981053\n",
      "mc23d_Zgamma_y Unweighted Events after basic:  19478\n",
      "mc23d_Zgamma_y Weighted Events after basic:  265.2141821877743\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_Zgamma_y: 16.48499608039856 seconds\n",
      "\n",
      "mc23d_Wgamma_y Unweighted Events before cut:  685525\n",
      "mc23d_Wgamma_y Weighted Events before cut:  23464.591275458304\n",
      "mc23d_Wgamma_y Unweighted Events after basic:  13933\n",
      "mc23d_Wgamma_y Weighted Events after basic:  535.5532902564596\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_Wgamma_y: 4.542269468307495 seconds\n",
      "\n",
      "mc23d_gammajet_direct_y Unweighted Events before cut:  1872548\n",
      "mc23d_gammajet_direct_y Weighted Events before cut:  1527485.7594546063\n",
      "mc23d_gammajet_direct_y Unweighted Events after basic:  30515\n",
      "mc23d_gammajet_direct_y Weighted Events after basic:  974.0549210779564\n",
      "Number of none values:  0\n",
      "Reading Time for mc23d_gammajet_direct_y: 11.81044888496399 seconds\n",
      "\n",
      "data23_y Unweighted Events before cut:  1489084\n",
      "data23_y Weighted Events before cut:  3077821.8039979036\n",
      "data23_y Unweighted Events after basic:  1397\n",
      "data23_y Weighted Events after basic:  2903.8609999999826\n",
      "Number of none values:  0\n",
      "Reading Time for data23_y: 13.740416526794434 seconds\n",
      "\n",
      "data23_eprobe Unweighted Events before cut:  991882\n",
      "data23_eprobe Weighted Events before cut:  35278.89142854558\n",
      "data23_eprobe Unweighted Events after basic:  24949\n",
      "data23_eprobe Weighted Events after basic:  1127.4378565699576\n",
      "Number of none values:  0\n",
      "Reading Time for data23_eprobe: 5.975416421890259 seconds\n",
      "\n",
      "mc23e_Zgamma_y Unweighted Events before cut:  8622736\n",
      "mc23e_Zgamma_y Weighted Events before cut:  66651.54542882358\n",
      "mc23e_Zgamma_y Unweighted Events after basic:  68044\n",
      "mc23e_Zgamma_y Weighted Events after basic:  798.1511253245422\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_Zgamma_y: 56.62154841423035 seconds\n",
      "\n",
      "mc23e_Wgamma_y Unweighted Events before cut:  2162708\n",
      "mc23e_Wgamma_y Weighted Events before cut:  74823.05389455653\n",
      "mc23e_Wgamma_y Unweighted Events after basic:  44545\n",
      "mc23e_Wgamma_y Weighted Events after basic:  1592.4189527449048\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_Wgamma_y: 32.79501128196716 seconds\n",
      "\n",
      "mc23e_gammajet_direct_y Unweighted Events before cut:  2268382\n",
      "mc23e_gammajet_direct_y Weighted Events before cut:  6522209.851531688\n",
      "mc23e_gammajet_direct_y Unweighted Events after basic:  29591\n",
      "mc23e_gammajet_direct_y Weighted Events after basic:  3672.988737405649\n",
      "Number of none values:  0\n",
      "Reading Time for mc23e_gammajet_direct_y: 86.33926749229431 seconds\n",
      "\n",
      "data24_y Unweighted Events before cut:  7913491\n",
      "data24_y Weighted Events before cut:  13122730.235302538\n",
      "data24_y Unweighted Events after basic:  6993\n",
      "data24_y Weighted Events after basic:  11516.719999999303\n",
      "Number of none values:  0\n",
      "Reading Time for data24_y: 192.73313093185425 seconds\n",
      "\n",
      "data24_eprobe Unweighted Events before cut:  4452447\n",
      "data24_eprobe Weighted Events before cut:  168317.91138638573\n",
      "data24_eprobe Unweighted Events after basic:  110499\n",
      "data24_eprobe Weighted Events after basic:  5371.424155399616\n",
      "Number of none values:  0\n",
      "Reading Time for data24_eprobe: 25.839619874954224 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math, pickle, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "\n",
    "# import config functions\n",
    "sys.path.append('/home/jlai/dark_photon/code/config')\n",
    "from plot_config import getWeight, zbi, sample_dict, getVarDict\n",
    "from plot_var import variables, variables_mc, ntuple_names\n",
    "from n_1_iteration_functions import get_best_cut, calculate_significance, apply_cut_to_fb, apply_all_cuts, compute_total_significance, n_minus_1_optimizer\n",
    "# from cut_config import cut_config\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high  \n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14,\n",
    "    \"title\": 20\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"],  # Legend\n",
    "    \"axes.titlesize\": font_size[\"title\"] # Title\n",
    "})\n",
    "\n",
    "\n",
    "tot = []\n",
    "data = pd.DataFrame()\n",
    "\n",
    "def test(fb):\n",
    "    # checking if there are any none values\n",
    "    mask = ak.is_none(fb['met_tst_et'])\n",
    "    n_none = ak.sum(mask)\n",
    "    print(\"Number of none values: \", n_none)\n",
    "    # if n_none > 0:\n",
    "    #     fb = fb[~mask]\n",
    "    # print(\"Events after removing none values: \", len(fb), ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "\n",
    "def print_cut(ntuple_name, fb, label):\n",
    "    print(f\"{ntuple_name} Unweighted Events {label}: \", len(fb))\n",
    "    print(f\"{ntuple_name} Weighted Events {label}: \", sum(getWeight(fb, ntuple_name)))\n",
    "        \n",
    "for i in range(len(ntuple_names)):\n",
    "    start_time = time.time()\n",
    "    ntuple_name = ntuple_names[i]\n",
    "    path = f\"/data/fpiazza/ggHyyd/NtuplesWithBDTSkim/{ntuple_name}_nominal_bdt.root\"\n",
    "    f = uproot.open(path)['nominal']\n",
    "    if ntuple_name.startswith(\"mc\"):\n",
    "        fb = f.arrays(variables+variables_mc, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "        \n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "        fb = fb[fb['n_ph'] == 1]\n",
    "        fb = fb[fb['n_el_baseline'] == 0]\n",
    "\n",
    "        # goodPV on signal only\n",
    "        if ntuple_name == 'ggHyyd':\n",
    "            fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "            good_pv_tmp = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "            fb = fb[good_pv_tmp]\n",
    "            \n",
    "        \n",
    "    if (ntuple_name == \"data23_y\") or (ntuple_name == \"data24_y\"):  # jet-faking \n",
    "        fb = f.arrays(variables, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]\n",
    "        mask1 = (ak.firsts(fb['ph_topoetcone40'])-2450.)/ak.firsts(fb['ph_pt']) > 0.1   # jet_faking_photon cut\n",
    "        fb = fb[mask1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 1]\n",
    "        fb = fb[fb['n_el_baseline'] == 0]\n",
    "\n",
    "\n",
    "    if (ntuple_name == \"data23_eprobe\") or (ntuple_name == \"data24_eprobe\"): # electron-faking\n",
    "        fb = f.arrays(variables, library='ak')\n",
    "        print_cut(ntuple_name, fb, 'before cut')\n",
    "        \n",
    "        fb = fb[fb['n_el'] == 1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 0]\n",
    "\n",
    "        # using electron info for photon info\n",
    "        fb['ph_pt'] = fb['el_pt']\n",
    "        fb['ph_eta'] = fb['el_eta']\n",
    "        fb['ph_phi'] = fb['el_phi']\n",
    "        fb['dphi_met_phterm'] = fb['dphi_met_eleterm']  \n",
    "\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0] # prevent none values in Tbranch\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) >= 50000] # ph_pt cut (basic cut)\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M']==1]\n",
    "    fb = fb[fb['met_tst_et'] >= 100000] # MET cut (basic cut)\n",
    "    fb = fb[fb['n_jet_central'] <= 3] # n_jet_central cut (basic cut)\n",
    "    \n",
    "    fb['VertexBDTScore'] = fb['BDTScore'] # renaming BDTScore to ensure this is recognized as Vertex BDT Score\n",
    "    fb = fb[fb['VertexBDTScore'] > 0.1]\n",
    "    \n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "                    (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    mask1 = mt_tmp > 100\n",
    "    mask2 = mt_tmp < 140\n",
    "    fb = fb[mask1 * mask2]\n",
    "\n",
    "    fb['weights'] = getWeight(fb, ntuple_name)\n",
    "    \n",
    "    print_cut(ntuple_name, fb, 'after basic')\n",
    "\n",
    "    test(fb) # check for none value\n",
    "\n",
    "    print(f\"Reading Time for {ntuple_name}: {(time.time()-start_time)} seconds\\n\")\n",
    "\n",
    "    tot.append(fb)\n",
    "\n",
    "    del fb \n",
    "\n",
    "# combining 23d + 23e {Zgamma (1, 6), Wgamma (2, 7), gammajet_direct (3, 8)}\n",
    "# combining 2023 + 2024 {data_y (4, 9), data_eprobe (5, 10)}\n",
    "tot_tmp = tot\n",
    "tot = [tot_tmp[0]]\n",
    "for i in tqdm(range(5)):\n",
    "    tot.append(ak.concatenate([tot_tmp[i+1], tot_tmp[i+6]]))\n",
    "ntuple_names = [\"ggHyyd\", \"Zgamma\", \"Wgamma\", \"gammajet_direct\", \"data_y\", \"data_eprobe\"]\n",
    "del tot_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e63ca-7090-43fa-bafe-fbd3d16e545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_name = 'ggHyyd'\n",
    "tot2 = []\n",
    "for i in range(len(tot)):\n",
    "    fb = tot[i]\n",
    "    # ---------- INTERNAL SELECTION CUT ------------\n",
    "    fb = fb[fb['VertexBDTScore'] > 0.1]\n",
    "    \n",
    "    metsig_tmp = fb['met_tst_sig'] \n",
    "    mask1 = metsig_tmp > 7\n",
    "    fb = fb[mask1]\n",
    "    \n",
    "    ph_eta_tmp = np.abs(ak.firsts(fb['ph_eta']))\n",
    "    fb = fb[ph_eta_tmp < 1.75]\n",
    "\n",
    "    dphi_met_phterm_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])) # added cut 3\n",
    "    fb = fb[dphi_met_phterm_tmp > 1.35]\n",
    "\n",
    "    dmet_tmp = fb['met_tst_noJVT_et'] - fb['met_tst_et']\n",
    "    mask1 = dmet_tmp > -20000\n",
    "    fb = fb[mask1]\n",
    "\n",
    "    dphi_jj_tmp = fb['dphi_central_jj']\n",
    "    dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "    dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "    dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "    fb = fb[dphi_jj_tmp < 2.5]\n",
    "\n",
    "    dphi_met_jetterm_tmp = np.where(fb['met_jetterm_et'] != 0,   # added cut 5\n",
    "                        np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                        -999)\n",
    "    fb = fb[dphi_met_jetterm_tmp < 0.75]\n",
    "    \n",
    "    '''\n",
    "    # ---------- SELECTION CUT ------------\n",
    "\n",
    "    metsig_tmp = fb['met_tst_sig'] \n",
    "    mask1 = metsig_tmp > 7\n",
    "    # fb = fb[mask1]\n",
    "    mask2 = metsig_tmp < 16\n",
    "    fb = fb[mask1 * mask2]\n",
    "    \n",
    "    ph_eta_tmp = np.abs(ak.firsts(fb['ph_eta']))\n",
    "    fb = fb[ph_eta_tmp < 1.74]\n",
    "\n",
    "    dphi_met_phterm_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])) # added cut 3\n",
    "    fb = fb[dphi_met_phterm_tmp > 1.35]\n",
    "\n",
    "    dmet_tmp = fb['met_tst_noJVT_et'] - fb['met_tst_et']\n",
    "    mask1 = dmet_tmp > -17900\n",
    "    # fb = fb[mask1]\n",
    "    mask2 = dmet_tmp < 41900\n",
    "    fb = fb[mask1 * mask2]\n",
    "\n",
    "    dphi_jj_tmp = fb['dphi_central_jj']\n",
    "    dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "    dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "    dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "    fb = fb[dphi_jj_tmp < 2.58]\n",
    "\n",
    "    dphi_met_jetterm_tmp = np.where(fb['met_jetterm_et'] != 0,   # added cut 5\n",
    "                        np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                        -999)\n",
    "    fb = fb[dphi_met_jetterm_tmp < 0.73]\n",
    "'''\n",
    "    # # ---------- FURTHER SELECTION CUT ------------\n",
    "    jet_sum_tmp = ak.sum(fb['jet_central_pt'], axis=-1)\n",
    "    expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "    balance_tmp = ak.where(jet_sum_tmp != 0, expr, -999)\n",
    "    mask_nan = balance_tmp == -999\n",
    "    mask = mask_nan | (balance_tmp > 0.90)\n",
    "    fb = fb[mask]\n",
    "\n",
    "\n",
    "    # ------------ mT cut ---------------\n",
    "    # mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "    #                     (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    # mask1 = mt_tmp > 80\n",
    "    # fb = fb[mask1]\n",
    "    # mask1 = mt_tmp > 100\n",
    "    # mask2 = mt_tmp < 140 \n",
    "    # fb = fb[mask1 * mask2]\n",
    "\n",
    "    tot2.append(fb)\n",
    "\n",
    "\n",
    "def compute_total_significance(tot2, ntuple_names, signal_name, getVarDict, getWeight):\n",
    "    signal_sum = 0\n",
    "    bkg_sum = 0\n",
    "    for i in range(len(ntuple_names)):\n",
    "        fb = tot2[i]\n",
    "        process = ntuple_names[i]\n",
    "        weights = getWeight(fb, process)\n",
    "        if process == signal_name:\n",
    "            signal_sum += ak.sum(weights)\n",
    "        else:\n",
    "            bkg_sum += ak.sum(weights)\n",
    "    return signal_sum / np.sqrt(bkg_sum) if bkg_sum > 0 else 0\n",
    "\n",
    "sig_tmp = compute_total_significance(tot2, ntuple_names, signal_name, getVarDict, getWeight)\n",
    "print(\"significance: \", sig_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "701aeca3-838d-4d2b-b707-8dde8b8c0f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VertexBDTScore 0 7\n",
      "{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -20000, 'best_sig_x_acc': 0.4325414732250103, 'significance': 0.4364016725833591, 'acceptance': 99.11544808352872}\n",
      "{'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6, 'best_sig_x_acc': 0.5569338651576675, 'significance': 0.6051434400535217, 'acceptance': 92.03336404149233}\n",
      "{'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.05, 'best_sig_x_acc': 0.1555000259188734, 'significance': 0.3124220904077554, 'acceptance': 49.77241708994511}\n",
      "{'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.8500000000000003, 'best_sig_x_acc': 0.4191315049051084, 'significance': 0.41913216929752917, 'acceptance': 99.99984148379212}\n",
      "{'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 2.4000000000000012, 'best_sig_x_acc': 0.41897347140166113, 'significance': 0.41897413554357277, 'acceptance': 99.99984148379212}\n",
      "dphi_jj 42 43\n",
      "CPU times: user 13.8 s, sys: 55.9 ms, total: 13.8 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tot2 = tot\n",
    "signal_name = 'ggHyyd'  # Define signal dataset\n",
    "cut_name = 'basic'\n",
    "\n",
    "def getCutDict(): # same cut as the internal note\n",
    "    cut_dict = {}\n",
    "    cut_dict['VertexBDTScore'] = {\n",
    "        'lowercut': np.arange(0.1, 0.24, 0.02),\n",
    "    }\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 10000 + 5000, 5000), # dmet > cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(1, 2 + 0.05, 0.05), # dphi_met_phterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'uppercut': np.arange(0.5, 1, 0.05), # dphi_met_jetterm < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.05, 0.05), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.1 + 0.05, 0.05) # dphi_jj < cut\n",
    "    }\n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "\n",
    "'''\n",
    "def getCutDict():\n",
    "    cut_dict = {}\n",
    "    # Selection 1: same variables as in the internal note\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 10000 + 100, 100), # dmet > cut\n",
    "        'uppercut': np.arange(10000, 100000 + 100, 100), # -10000 < dmet < cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(1, 2 + 0.01, 0.01), # dphi_met_phterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'uppercut': np.arange(0.5, 1, 0.01), # dphi_met_jetterm < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.01, 0.01), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\n",
    "    }\n",
    "\n",
    "    # Selection 2\n",
    "    cut_dict['balance'] = {\n",
    "        'lowercut': np.arange(0.3, 1.5 + 0.05, 0.05), # balance > cut\n",
    "    }\n",
    "    cut_dict['jetterm'] = {\n",
    "        'lowercut': np.arange(0, 150000+10000, 10000) # jetterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.1, 0.1), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['metsigres'] = {\n",
    "        'uppercut': np.arange(12000, 60000, 10000)\n",
    "    }\n",
    "    cut_dict['met_noJVT'] = {\n",
    "        'lowercut': np.arange(50000, 120000, 10000),\n",
    "    }\n",
    "    \n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "'''\n",
    "\n",
    "signal_name='ggHyyd'\n",
    "initial_cut = []\n",
    "# tot2 = tot  # return the initial cut\n",
    "\n",
    "# < -- Initial Cut on all variables (maximize the significance * acceptance) -- > \n",
    "for cut_var, cut_types in cut_config.items():\n",
    "    for cut_type, cut_values in cut_types.items():\n",
    "        sig_simple_list, sigacc_simple_list, acceptance_values = calculate_significance(\n",
    "            cut_var, cut_type, cut_values, tot2, ntuple_names, signal_name, getVarDict\n",
    "        )\n",
    "\n",
    "        best_cut, best_sig, idx = get_best_cut(cut_values, sigacc_simple_list) \n",
    "        \n",
    "        if idx == 0 or idx == len(sigacc_simple_list) - 1: # I chose to use index to indicate not to make unnecessary cut (for initial cut)\n",
    "            print(cut_var, idx, len(sigacc_simple_list))\n",
    "            continue\n",
    "            \n",
    "        result = {\n",
    "            \"cut_var\": cut_var,\n",
    "            \"cut_type\": cut_type,\n",
    "            \"best_cut\": best_cut,\n",
    "            \"best_sig_x_acc\": best_sig,\n",
    "            \"significance\": sig_simple_list[idx],\n",
    "            \"acceptance\": acceptance_values[idx]\n",
    "        }\n",
    "\n",
    "        print(result)\n",
    "        initial_cut.append(dict(list(result.items())[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7d15f70-27f9-4ad7-82ee-4cb9c93f0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal note cut (just in case)\n",
    "initial_cut = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -20000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6e9d45-ced3-4179-ac43-65aa2394e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after initial cutting, signficance:  0.48805892167727066\n"
     ]
    }
   ],
   "source": [
    "tot2_initial_cut = apply_all_cuts(tot2, ntuple_names, initial_cut, getVarDict)\n",
    "final_significance = compute_total_significance(tot2_initial_cut, ntuple_names, signal_name, getVarDict)\n",
    "print('after initial cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435c829b-a8dd-45eb-a394-b3fb350ebacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "Updating metsig (lowercut): 6 → 8  (N-1 0.354 → with-cut 0.501)\n",
      "Updating ph_eta (uppercut): 1.75 → 1.7000000000000006  (N-1 0.485 → with-cut 0.501)\n",
      "Dropping dphi_met_phterm (lowercut): N-1 0.681 >= best-with-cut 0.503\n",
      "Updating dmet (lowercut): -20000 → -10000  (N-1 0.485 → with-cut 0.503)\n",
      "Updating dphi_jj (uppercut): 2.5 → 2.100000000000001  (N-1 0.494 → with-cut 0.505)\n",
      "Updating dphi_met_jetterm (uppercut): 0.75 → 0.5  (N-1 0.505 → with-cut 0.505)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Updating VertexBDTScore (lowercut): 0.1 → 0.12000000000000001  (N-1 0.653 → with-cut 0.655)\n",
      "Updating ph_eta (uppercut): 1.7000000000000006 → 1.7500000000000007  (N-1 0.630 → with-cut 0.658)\n",
      "Updating dmet (lowercut): -10000.0 → -15000  (N-1 0.644 → with-cut 0.659)\n",
      "Updating dphi_jj (uppercut): 2.100000000000001 → 2.3500000000000014  (N-1 0.650 → with-cut 0.662)\n",
      "Updating dphi_met_jetterm (uppercut): 0.5 → 0.8500000000000003  (N-1 0.690 → with-cut 0.690)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Updating metsig (lowercut): 8.0 → 7  (N-1 0.485 → with-cut 0.690)\n",
      "Updating dphi_jj (uppercut): 2.3500000000000014 → 2.300000000000001  (N-1 0.676 → with-cut 0.691)\n",
      "Updating dphi_met_jetterm (uppercut): 0.8500000000000003 → 0.8000000000000003  (N-1 0.690 → with-cut 0.691)\n",
      "\n",
      "--- Iteration 4 ---\n",
      "optimized cuts, end of iteration\n",
      "after optimized cutting, signficance:  0.6907654338266067\n",
      "CPU times: user 36.8 s, sys: 125 ms, total: 36.9 s\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def n_minus_1_optimizer(\n",
    "    initial_cut,\n",
    "    cut_config,\n",
    "    tot2,\n",
    "    ntuple_names,\n",
    "    signal_name,\n",
    "    getVarDict,\n",
    "    final_significance,\n",
    "    max_iter=10,\n",
    "    tolerance=1e-4,\n",
    "    allow_drop=True,\n",
    "    drop_tolerance=1e-6\n",
    "):\n",
    "    \"\"\"\n",
    "    allow_drop: if True, remove a cut when N-1 significance beats the best-with-cut significance.\n",
    "    drop_tolerance: minimal margin by which N-1 must exceed best-with-cut to drop the cut.\n",
    "    \"\"\"\n",
    "    best_cuts = [dict(c) for c in initial_cut]  # copy\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < max_iter:\n",
    "        converged = True\n",
    "        to_remove = []\n",
    "\n",
    "        print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "\n",
    "        for i, cut in enumerate(best_cuts):\n",
    "            # Apply all OTHER cuts (N-1)\n",
    "            n_minus_1_cuts = best_cuts[:i] + best_cuts[i+1:]\n",
    "            tot2_cut = apply_all_cuts(tot2, ntuple_names, n_minus_1_cuts, getVarDict)\n",
    "\n",
    "            # Significance WITHOUT this cut\n",
    "            sig_without = compute_total_significance(\n",
    "                tot2_cut, ntuple_names, signal_name, getVarDict\n",
    "            )\n",
    "\n",
    "            # Re-scan this variable ON TOP of N-1\n",
    "            cut_var  = cut[\"cut_var\"]\n",
    "            cut_type = cut[\"cut_type\"]\n",
    "            scan_vals = cut_config[cut_var][cut_type]\n",
    "\n",
    "            sig_simple_list, sigacc_simple_list, _ = calculate_significance(\n",
    "                cut_var, cut_type, scan_vals, tot2_cut, ntuple_names,\n",
    "                signal_name, getVarDict\n",
    "            )\n",
    "            best_cut_val, best_sig, best_idx = get_best_cut(scan_vals, sig_simple_list)\n",
    "\n",
    "            # Decide to drop or to keep/update\n",
    "            if allow_drop and (sig_without >= best_sig + drop_tolerance):\n",
    "                print(f\"Dropping {cut_var} ({cut_type}): \"\n",
    "                      f\"N-1 {sig_without:.3f} >= best-with-cut {best_sig:.3f}\")\n",
    "                to_remove.append(i)\n",
    "                final_significance = sig_without\n",
    "                converged = False\n",
    "                continue  # move to next cut\n",
    "\n",
    "            # Keep: update threshold if it moved\n",
    "            if abs(best_cut_val - cut[\"best_cut\"]) > tolerance:\n",
    "                print(f\"Updating {cut_var} ({cut_type}): \"\n",
    "                      f\"{cut['best_cut']} → {best_cut_val}  \"\n",
    "                      f\"(N-1 {sig_without:.3f} → with-cut {best_sig:.3f})\")\n",
    "                best_cuts[i][\"best_cut\"] = float(best_cut_val)\n",
    "                final_significance = best_sig\n",
    "                converged = False\n",
    "\n",
    "        # Remove cuts marked for deletion (highest index first)\n",
    "        if to_remove:\n",
    "            for j in sorted(to_remove, reverse=True):\n",
    "                del best_cuts[j]\n",
    "\n",
    "        iteration += 1\n",
    "        if converged:\n",
    "            break\n",
    "\n",
    "    # Recompute final significance with the surviving cuts\n",
    "    tot2_final = apply_all_cuts(tot2, ntuple_names, best_cuts, getVarDict)\n",
    "    final_significance = compute_total_significance(\n",
    "        tot2_final, ntuple_names, signal_name, getVarDict\n",
    "    )\n",
    "\n",
    "    print('optimized cuts, end of iteration')\n",
    "    return best_cuts, final_significance\n",
    "    \n",
    "# < -- n-1 iterations until no further improvement (max significance) -- >\n",
    "optimized_cuts, final_significance = n_minus_1_optimizer(\n",
    "    initial_cut, cut_config, tot2, ntuple_names, signal_name, getVarDict, final_significance\n",
    ")\n",
    "print('after optimized cutting, signficance: ', final_significance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046f0a65-fada-4152-9fdb-b68f5222ede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " < -- Final Optimized Cuts -- > \n",
      "VertexBDTScore > 0.12000000000000001\n",
      "metsig > 7.0\n",
      "ph_eta < 1.7500000000000007\n",
      "dmet > -15000.0\n",
      "dphi_jj < 2.300000000000001\n",
      "dphi_met_jetterm < 0.8000000000000003\n",
      "after optimized cutting, signficance:  0.6907654338266067\n"
     ]
    }
   ],
   "source": [
    "print( ' < -- Final Optimized Cuts -- > ')\n",
    "# print(optimized_cuts)\n",
    "\n",
    "for cut in optimized_cuts:\n",
    "    var = cut['cut_var']\n",
    "    val = cut['best_cut']\n",
    "    if cut['cut_type'] == 'uppercut':\n",
    "        print(f\"{var} < {val}\")\n",
    "    elif cut['cut_type'] == 'lowercut':\n",
    "        print(f\"{var} > {val}\")\n",
    "        \n",
    "print('after optimized cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a5df7e9-0dbd-4b83-9c54-3e3fb9ef2184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< -- Sum of weight each process -- >\n",
      "ggHyyd 48.623592\n",
      "Zgamma 547.8553\n",
      "Wgamma 1011.38275\n",
      "gammajet_direct 164.19606\n",
      "data_y 1439.022999999994\n",
      "data_eprobe 1792.42003447059\n"
     ]
    }
   ],
   "source": [
    "tot2_optimized_cuts = apply_all_cuts(tot2, ntuple_names, optimized_cuts, getVarDict)\n",
    "\n",
    "print('< -- Sum of weight each process -- >')\n",
    "\n",
    "for i in range(len(tot2_optimized_cuts)):\n",
    "    print(ntuple_names[i], ak.sum(tot2_optimized_cuts[i]['weights']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8342146-c9e5-4012-bfc9-d51dd8b48241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after initial cutting, signficance:  0.6907654338266067\n"
     ]
    }
   ],
   "source": [
    "# internal note cut (just in case)\n",
    "initial_cut = [\n",
    "    {'cut_var': 'VertexBDTScore', 'cut_type': 'lowercut', 'best_cut': 0.1},\n",
    "    {'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 7},\n",
    "    {'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 1.75},\n",
    "    {'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.25},\n",
    "    {'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -20000},\n",
    "    {'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 2.5},\n",
    "    {'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.75},\n",
    "]\n",
    "# final_significance = compute_total_significance(apply_all_cuts(tot2, ntuple_names, initial_cut, getVarDict), ntuple_names, signal_name, getVarDict)\n",
    "final_significance = compute_total_significance(apply_all_cuts(tot2, ntuple_names, optimized_cuts, getVarDict), ntuple_names, signal_name, getVarDict)\n",
    "print('after initial cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84d051b6-b485-4ec5-a815-ff440ac67d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/n_ph.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/n_ph_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/n_el.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/n_el_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/n_mu_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/n_tau_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/mt.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/metsig.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n",
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/metsigres.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/met.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/met_noJVT.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/dmet.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/ph_pt.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/ph_eta.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/ph_phi.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/pv_ntracks.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/jet_central_eta.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/jet_central_vecSumPt.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/jet_central_pt1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/jet_central_pt2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/dphi_met_phterm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/dphi_met_jetterm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/dphi_phterm_jetterm.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/failJVT_jet_pt1.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/failJVT_jet_vecSumPt.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/softerm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/jetterm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/jetterm_sumet.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/n_jet.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/n_jet_central.png\n",
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/n_jet_fwd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/central_jets_fraction.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/balance.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/dphi_jj.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /home/jlai/dark_photon/main/mt100_140/basiccut/VertexBDTScore.png\n"
     ]
    }
   ],
   "source": [
    "tot2 = tot2_optimized_cuts\n",
    "# tot2 = tot\n",
    "cut_name = 'selection'\n",
    "var_config = getVarDict(tot2[0], 'ggHyyd')\n",
    "\n",
    "# path for plot storage\n",
    "mt_val_dir = 'mt100_140'\n",
    "\n",
    "for var in var_config:\n",
    "    # print(var)\n",
    "    bg_values = []     \n",
    "    bg_weights = []    \n",
    "    bg_colors = []     \n",
    "    bg_labels = []     \n",
    "\n",
    "    signal_values = [] \n",
    "    signal_weights = []\n",
    "    signal_color = None \n",
    "    signal_label = None\n",
    "\n",
    "    for j in range(len(ntuple_names)):\n",
    "        process = ntuple_names[j]\n",
    "        fb = tot2[j]  # TTree\n",
    "        var_config = getVarDict(fb, process, var_name=var)\n",
    "\n",
    "        x = var_config[var]['var'] # TBranch\n",
    "        bins = var_config[var]['bins'] \n",
    "        weights = fb['weights']\n",
    "        \n",
    "        sample_info = sample_dict[process]\n",
    "        color = sample_info['color']\n",
    "        legend = sample_info['legend']\n",
    "\n",
    "        \n",
    "        if process == 'ggHyyd':  # signal\n",
    "            signal_values.append(x)\n",
    "            signal_weights.append(weights)\n",
    "            signal_color = color\n",
    "            signal_label = legend\n",
    "        else:   # background\n",
    "            bg_values.append(x)\n",
    "            bg_weights.append(weights)\n",
    "            bg_colors.append(color)\n",
    "            bg_labels.append(legend)\n",
    "\n",
    "    fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(12, 13), gridspec_kw={'height_ratios': [9, 4]})\n",
    "\n",
    "    ax_top.hist(bg_values, bins=bins, weights=bg_weights, color=bg_colors,\n",
    "                label=bg_labels, stacked=True)\n",
    "\n",
    "    ax_top.hist(signal_values, bins=bins, weights=signal_weights, color=signal_color,\n",
    "                label=signal_label, histtype='step', linewidth=2)\n",
    "\n",
    "    signal_all = np.concatenate(signal_values) if len(signal_values) > 0 else np.array([])\n",
    "    signal_weights_all = np.concatenate(signal_weights) if len(signal_weights) > 0 else np.array([])\n",
    "\n",
    "    # Add error bar for signal (top plot)\n",
    "    if len(signal_all) > 0:\n",
    "        signal_counts, bin_edges = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "        sum_weights_sq, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all**2)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        signal_errors = np.sqrt(sum_weights_sq)  # Poisson error sqrt(N)\n",
    "\n",
    "        ax_top.errorbar(bin_centers, signal_counts, yerr=signal_errors, fmt='.', linewidth=2,\n",
    "                        color=signal_color, capsize=0)\n",
    "\n",
    "    ax_top.set_yscale('log')\n",
    "    ax_top.set_ylim(0.0001, 1e11)\n",
    "    ax_top.set_xlim(bins[0], bins[-1])\n",
    "    ax_top.minorticks_on()\n",
    "    ax_top.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "    ax_top.set_ylabel(\"Events\")\n",
    "    ax_top.legend(ncol=2)\n",
    "\n",
    "    bg_all = np.concatenate(bg_values) if len(bg_values) > 0 else np.array([])\n",
    "    bg_weights_all = np.concatenate(bg_weights) if len(bg_weights) > 0 else np.array([])\n",
    "\n",
    "    # Compute the weighted histogram counts using np.histogram\n",
    "    S_counts, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "    B_counts, _ = np.histogram(bg_all, bins=bins, weights=bg_weights_all)     \n",
    "\n",
    "    # Compute per-bin significance\n",
    "    sig_simple = np.zeros_like(S_counts, dtype=float)\n",
    "    sig_s_plus_b = np.zeros_like(S_counts, dtype=float)\n",
    "    sig_s_plus_1p3b = np.zeros_like(S_counts, dtype=float)\n",
    "\n",
    "    sqrt_B = np.sqrt(B_counts)\n",
    "    sqrt_SplusB = np.sqrt(S_counts + B_counts)\n",
    "    sqrt_Splus1p3B = np.sqrt(S_counts + 1.3 * B_counts)\n",
    "\n",
    "    # Avoid division by zero safely\n",
    "    sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0)\n",
    "    sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0)\n",
    "    sig_s_plus_1p3b = np.where((S_counts + 1.3 * B_counts) > 0, S_counts / sqrt_Splus1p3B, 0)\n",
    "\n",
    "    # Add Binomial ExpZ per bin\n",
    "    zbi_per_bin = np.array([\n",
    "        zbi(S_counts[i], B_counts[i], sigma_b_frac=0.3)\n",
    "        for i in range(len(S_counts))\n",
    "    ])\n",
    "\n",
    "    # Compute the bin centers for plotting\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "    # Compute the total significance: total S / sqrt(total B)\n",
    "    total_signal = np.sum(S_counts)\n",
    "    total_bkg = np.sum(B_counts)\n",
    "\n",
    "    if total_bkg > 0:\n",
    "        total_sig_simple = total_signal / np.sqrt(total_bkg)\n",
    "        total_sig_s_plus_b = total_signal / np.sqrt(total_signal + total_bkg)\n",
    "        total_sig_s_plus_1p3b = total_signal / np.sqrt(total_signal + 1.3 * total_bkg)\n",
    "        total_sig_binomial = zbi(total_signal, total_bkg, sigma_b_frac=0.3)\n",
    "    else:\n",
    "        total_sig_simple = total_sig_s_plus_b = total_sig_s_plus_1p3b = total_sig_binomial = 0\n",
    "\n",
    "    # --- Plot all significance curves ---\n",
    "    ax_bot.step(bin_centers, sig_simple, where='mid', color='chocolate', linewidth=2,\n",
    "                label=f\"S/√B = {total_sig_simple:.4f}\")\n",
    "    ax_bot.step(bin_centers, sig_s_plus_b, where='mid', color='tomato', linewidth=2,\n",
    "                label=f\"S/√(S+B) = {total_sig_s_plus_b:.4f}\")\n",
    "    ax_bot.step(bin_centers, sig_s_plus_1p3b, where='mid', color='orange', linewidth=2,\n",
    "                label=f\"S/√(S+1.3B) = {total_sig_s_plus_1p3b:.4f}\")\n",
    "    ax_bot.step(bin_centers, zbi_per_bin, where='mid', color='plum', linewidth=2,\n",
    "                label=f\"Binomial ExpZ = {total_sig_binomial:.4f}\")\n",
    "\n",
    "    ax_bot.set_xlabel(var_config[var]['title'])\n",
    "    # ax_bot.set_xticks(np.linspace(bins[0], bins[-1], 11))\n",
    "    ax_bot.set_ylabel(\"Significance\")\n",
    "    # ax_bot.set_ylim(-0.8, 2)\n",
    "    ax_top.set_xlim(bins[0], bins[-1])\n",
    "\n",
    "    # Do not set a title on the bottom plot.\n",
    "    ax_bot.set_title(\"\")\n",
    "\n",
    "    # Draw a legend with purple text.\n",
    "    leg = ax_bot.legend()\n",
    "    for text in leg.get_texts():\n",
    "        text.set_color('purple')\n",
    "\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/home/jlai/dark_photon/main/{mt_val_dir}/basiccut/{var}.png\")\n",
    "    print(f\"successfully saved to /home/jlai/dark_photon/main/{mt_val_dir}/basiccut/{var}.png\")\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "\n",
    "    y_true = np.concatenate([np.ones_like(signal_all), np.zeros_like(bg_all)])\n",
    "    y_scores = np.concatenate([signal_all, bg_all])\n",
    "    # Combine the weights for all events.\n",
    "    y_weights = np.concatenate([signal_weights_all, bg_weights_all])\n",
    "\n",
    "    # Compute the weighted ROC curve.\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores, sample_weight=y_weights)\n",
    "    sorted_indices = np.argsort(fpr)\n",
    "    fpr_sorted = fpr[sorted_indices]\n",
    "    tpr_sorted = tpr[sorted_indices]\n",
    "\n",
    "    roc_auc = auc(fpr_sorted, tpr_sorted)\n",
    "\n",
    "    # Create a new figure for the ROC curve.\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, lw=2, color='red', label=f'ROC curve (AUC = {roc_auc:.5f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random chance')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve for {var}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.tight_layout()    \n",
    "    plt.savefig(f\"/home/jlai/dark_photon/main/{mt_val_dir}/basiccut/roc_curve_{var}.png\")\n",
    "    plt.close()\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc52ad9-8d11-4f5e-ba5f-291b4cdee4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1_config = [\"VertexBDTScore\", \"metsig\", \"ph_eta\", \"dmet\", \"dphi_jj\",  \"dphi_met_jetterm\"]\n",
    "\n",
    "def sel(tot, n_1_name=None):\n",
    "    tot2 = []\n",
    "    for i in range(len(tot)):\n",
    "        fb2 = tot[i]\n",
    "    \n",
    "        if n_1_name != \"VertexBDTScore\":\n",
    "            fb2 = fb2[fb2['VertexBDTScore'] >= 0.12]\n",
    "\n",
    "        # if n_1_name != \"dphi_met_phterm\":\n",
    "        #     fb2 = fb2[fb2['dphi_met_phterm'] >= 1.35]\n",
    "\n",
    "        # if n_1_name != \"balance\":\n",
    "            # fb2 = fb2[fb2['balance'] >= 1.35]\n",
    "\n",
    "        if n_1_name != \"metsig\":\n",
    "            metsig_tmp = fb2['met_tst_sig'] \n",
    "            mask1 = metsig_tmp >= 7\n",
    "            # fb2 = fb2[mask1]\n",
    "            mask2 = metsig_tmp <= 16\n",
    "            fb2 = fb2[mask1]\n",
    "        \n",
    "        if n_1_name != \"ph_eta\":\n",
    "            ph_eta_tmp = np.abs(ak.firsts(fb2['ph_eta']))\n",
    "            fb2 = fb2[ph_eta_tmp <= 1.75]\n",
    "\n",
    "        if n_1_name != \"dmet\":\n",
    "            dmet_tmp = fb2['dmet']\n",
    "            mask1 = dmet_tmp >= -15000\n",
    "            mask2 = dmet_tmp <= 50000\n",
    "            fb2 = fb2[mask1]\n",
    "\n",
    "        if n_1_name != \"dphi_met_jetterm\":\n",
    "            dphi_met_jetterm_tmp = fb2['dphi_met_jetterm']\n",
    "            fb2 = fb2[dphi_met_jetterm_tmp <= 0.8]\n",
    "\n",
    "        if n_1_name != \"dphi_jj\":\n",
    "            dphi_jj_tmp = fb['dphi_central_jj']\n",
    "            dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "            dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "            dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "            fb2 = fb2[dphi_jj_tmp <= 2.3]\n",
    "\n",
    "        \n",
    "        tot2.append(fb2)\n",
    "    return tot2\n",
    "\n",
    "tot2 = sel(tot)\n",
    "# tot2 = tot\n",
    "\n",
    "signal_name = 'ggHyyd'  # Define signal dataset\n",
    "cut_name = 'n-1'\n",
    "\n",
    "def getCutDict(n_1_name=None):\n",
    "    cut_dict = {}\n",
    "\n",
    "    if n_1_name is None or n_1_name == \"BDTScore\":\n",
    "        cut_dict['BDTScore'] = {\n",
    "            'lowercut': np.arange(0, 0.4+0.1, 0.1) # BDTScore > cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"balance\":\n",
    "        cut_dict['balance'] = {\n",
    "            'lowercut': np.arange(0, 1.5 + 0.05, 0.05), # balance > cut\n",
    "            'uppercut': np.arange(5, 8 + 0.2, 0.2) # balance < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dmet\":\n",
    "        cut_dict['dmet'] = {\n",
    "            'lowercut': np.arange(-30000, 0 + 5000, 5000), # dmet > cut\n",
    "            'uppercut': np.arange(10000, 100000 + 5000, 5000), # -10000 < dmet < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_jj\":\n",
    "        cut_dict['dphi_jj'] = {\n",
    "            'uppercut': np.arange(1, 3.1 + 0.1, 0.1) # dphi_jj < cut\n",
    "        }\n",
    "    # if n_1_name is None or n_1_name == \"dphi_met_phterm_minus_dphi_met_jetterm\":\n",
    "    #     cut_dict['dphi_met_phterm_minus_dphi_met_jetterm'] = {\n",
    "    #         'lowercut': np.arange(0, 1.5+0.05, 0.05),\n",
    "    #         'uppercut': np.arange(1.5, 3.1+0.05, 0.05)\n",
    "    #     }\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_jetterm\":\n",
    "        cut_dict['dphi_met_jetterm'] = {\n",
    "            'lowercut': np.arange(0, 1 + 0.05, 0.05), # dphi_met_jetterm > cut \n",
    "            'uppercut': np.arange(0.5, 2 + 0.05, 0.05), # dphi_met_jetterm < cut \n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_phterm\":\n",
    "        cut_dict['dphi_met_phterm'] = {\n",
    "            'lowercut': np.arange(1, 2 + 0.05, 0.05), # dphi_met_phterm > cut\n",
    "            'uppercut': np.arange(2, 3.1 + 0.1, 0.1), # dphi_met_phterm < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_ph_centraljet1\":\n",
    "        cut_dict['dphi_ph_centraljet1'] = {\n",
    "            'lowercut': np.arange(0, 2.5 + 0.1, 0.1), # dphi_ph_centraljet1 > cut\n",
    "            'uppercut': np.arange(1.5, 3.1 + 0.1, 0.1) # dphi_ph_centraljet1 < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_phterm_jetterm\":\n",
    "        cut_dict['dphi_phterm_jetterm'] = {\n",
    "            'lowercut': np.arange(1, 2.5 + 0.05, 0.05), # dphi_phterm_jetterm > cut\n",
    "            'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"met\":\n",
    "        cut_dict['met'] = {\n",
    "            'lowercut': np.arange(100000, 140000 + 5000, 5000),  # met > cut\n",
    "            'uppercut': np.arange(140000, 300000 + 5000, 5000),  # met < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"metsig\":\n",
    "        cut_dict['metsig'] = {\n",
    "            'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "            'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"mt\":\n",
    "        cut_dict['mt'] = {\n",
    "            'lowercut': np.arange(80, 130+5, 5), # mt > cut\n",
    "            'uppercut': np.arange(120, 230+5, 5) # mt < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"n_jet_central\":\n",
    "        cut_dict['n_jet_central'] = {\n",
    "            'uppercut': np.arange(0, 8+1, 1) # njet < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"ph_eta\":\n",
    "        cut_dict['ph_eta'] = {\n",
    "            'uppercut': np.arange(1, 2.5 + 0.05, 0.05), # ph_eta < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"ph_pt\":\n",
    "        cut_dict['ph_pt'] = {\n",
    "            'lowercut': np.arange(50000, 100000 + 5000, 5000),  # ph_pt > cut\n",
    "            'uppercut': np.arange(100000, 300000 + 10000, 10000),  # ph_pt > cut\n",
    "        }\n",
    "\n",
    "    return cut_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
