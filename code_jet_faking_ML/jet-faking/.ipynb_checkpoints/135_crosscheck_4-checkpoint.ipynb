{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b353b7-b507-4881-9f15-bc69b0de3806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file:  /data/tmathew/ntups/mc23d/ggHyyd_y.root\n",
      "Unweighted Events before cut:  86910\n",
      "Weighted Events before cut:  8732.987955115426\n",
      "Unweighted Events after basic:  2646\n",
      "Weighted Events after basic:  268.2449529933159\n",
      "Number of none values:  0\n",
      "Reading Time for ggHyyd: 1.7772290706634521 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Zjets_y.root\n",
      "Unweighted Events before cut:  3242488\n",
      "Weighted Events before cut:  676616.903247458\n",
      "Unweighted Events after basic:  383\n",
      "Weighted Events after basic:  16.82812304884456\n",
      "Number of none values:  0\n",
      "Reading Time for Zjets: 90.09477019309998 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Zgamma_y.root\n",
      "Unweighted Events before cut:  3423357\n",
      "Weighted Events before cut:  249851.55031619867\n",
      "Unweighted Events after basic:  19491\n",
      "Weighted Events after basic:  1002.7013259970018\n",
      "Number of none values:  0\n",
      "Reading Time for Zgamma: 22.769730806350708 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Wgamma_y.root\n",
      "Unweighted Events before cut:  1308982\n",
      "Weighted Events before cut:  427927.31994993926\n",
      "Unweighted Events after basic:  14042\n",
      "Weighted Events after basic:  1992.7117943080088\n",
      "Number of none values:  0\n",
      "Reading Time for Wgamma: 10.64186143875122 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Wjets_y.root\n",
      "Unweighted Events before cut:  1962593\n",
      "Weighted Events before cut:  2815306.4335920406\n",
      "Unweighted Events after basic:  13282\n",
      "Weighted Events after basic:  3077.4733461058995\n",
      "Number of none values:  0\n",
      "Reading Time for Wjets: 32.64683747291565 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/gammajet_direct_y.root\n",
      "Unweighted Events before cut:  12921098\n",
      "Weighted Events before cut:  147918307.09228534\n",
      "Unweighted Events after basic:  27203\n",
      "Weighted Events after basic:  4024.1548354766715\n",
      "Number of none values:  0\n",
      "Reading Time for gammajet_direct: 85.25697374343872 seconds\n",
      "\n",
      "processing file:  /data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/data23_y_BDT_score.root\n",
      "Unweighted Events before cut:  3354286\n",
      "Weighted Events before cut:  36165772.75273502\n",
      "Unweighted Events after basic:  1231\n",
      "Weighted Events after basic:  13349.217036965108\n",
      "Number of none values:  0\n",
      "Reading Time for data23: 73.04426217079163 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math, pickle, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "\n",
    "# import config functions\n",
    "sys.path.append(\"/home/jlai/jet-faking/config\")\n",
    "from jet_faking_plot_config import getWeight, zbi, sample_dict, getVarDict\n",
    "from plot_var import variables, variables_data, ntuple_names, ntuple_names_BDT\n",
    "from n_1_iteration_functions import get_best_cut, calculate_significance, apply_cut_to_fb, apply_all_cuts, compute_total_significance, n_minus_1_optimizer\n",
    "# from cut_config import cut_config\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high  \n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"]  # Legend\n",
    "})\n",
    "\n",
    "tot = []\n",
    "data = pd.DataFrame()\n",
    "ntuple_names = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct', 'data23']\n",
    "\n",
    "def test(fb):\n",
    "    # checking if there are any none values\n",
    "    mask = ak.is_none(fb['met_tst_et'])\n",
    "    n_none = ak.sum(mask)\n",
    "    print(\"Number of none values: \", n_none)\n",
    "    # if n_none > 0:\n",
    "    #     fb = fb[~mask]\n",
    "    # print(\"Events after removing none values: \", len(fb), ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "\n",
    "def print_cut(ntuple_name, fb, label):\n",
    "    print(f\"Unweighted Events {label}: \", len(fb))\n",
    "    if ntuple_name == 'data23':\n",
    "        print(f\"Weighted Events {label}: \", sum(getWeight(fb, ntuple_name, jet_faking=True)))\n",
    "    else: \n",
    "        print(f\"Weighted Events {label}: \", sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "for i in range(len(ntuple_names)):\n",
    "    start_time = time.time()\n",
    "    ntuple_name = ntuple_names[i]\n",
    "    if ntuple_name == 'data23': # data\n",
    "        path = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/data23_y_BDT_score.root\" \n",
    "        print('processing file: ', path)\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables_data, library=\"ak\")\n",
    "        fb['VertexBDTScore'] = fb['BDTScore'] # renaming BDTScore to ensure this is recognized as Vertex BDT Score\n",
    "        \n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "                \n",
    "        mask1 = (ak.firsts(fb['ph_topoetcone40'])-2450.)/ak.firsts(fb['ph_pt']) > 0.1   # jet_faking_photon cut\n",
    "        fb = fb[mask1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 1]\n",
    "\n",
    "    else: # MC\n",
    "        path = f\"/data/tmathew/ntups/mc23d/{ntuple_name}_y.root\" \n",
    "        path_BDT = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/mc23d_{ntuple_name}_y_BDT_score.root\" \n",
    "        print('processing file: ', path)\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables, library=\"ak\")\n",
    "\n",
    "        # add BDT score to fb\n",
    "        f_BDT = uproot.open(path_BDT)['nominal']\n",
    "        fb_BDT = f_BDT.arrays([\"event\", \"BDTScore\"], library=\"ak\")\n",
    "        tmp = fb[\"event\"] == fb_BDT[\"event\"]\n",
    "        if np.all(tmp) == True:\n",
    "            fb[\"VertexBDTScore\"] = fb_BDT[\"BDTScore\"]\n",
    "        else: \n",
    "            print(\"Something is wrong, need arranging\")\n",
    "\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "        fb = fb[fb['n_ph'] == 1]\n",
    "        \n",
    "        # Zjets and Wjets (rule out everything except for e->gamma)\n",
    "        if ntuple_name == 'Zjets' or ntuple_name == 'Wjets':\n",
    "            mask = ak.firsts(fb['ph_truth_type']) == 2\n",
    "            fb = fb[mask]\n",
    "        \n",
    "        # goodPV on signal only\n",
    "        if ntuple_name == 'ggHyyd':\n",
    "            fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "            good_pv_tmp = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "            fb = fb[good_pv_tmp]\n",
    "\n",
    "    print_cut(ntuple_name, fb, 'before cut')\n",
    "\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    fb = fb[fb['n_el_baseline'] == 0]\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M']==1]\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0] # prevent none values in Tbranch\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) >= 50000] # ph_pt cut (basic cut)\n",
    "    fb = fb[fb['met_tst_et'] >= 100000] # MET cut (basic cut)\n",
    "    fb = fb[fb['n_jet_central'] <= 3] # n_jet_central cut (basic cut)\n",
    "\n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "                            (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    mask1 = mt_tmp > 100\n",
    "    mask2 = mt_tmp < 140 \n",
    "    fb = fb[mask1 * mask2]\n",
    "\n",
    "    fb = fb[fb['VertexBDTScore'] > 0.1]\n",
    "\n",
    "    '''\n",
    "    # Selection cut\n",
    "    metsig_tmp = fb['met_tst_sig'] \n",
    "    mask1 = metsig_tmp > 7\n",
    "    mask2 = metsig_tmp < 20\n",
    "    fb = fb[mask1 * mask2]\n",
    "    \n",
    "    ph_eta_tmp = np.abs(ak.firsts(fb['ph_eta']))\n",
    "    fb = fb[ph_eta_tmp < 1.74]\n",
    "\n",
    "    dphi_met_phterm_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])) # added cut 3\n",
    "    fb = fb[dphi_met_phterm_tmp > 1.23]\n",
    "\n",
    "    dmet_tmp = fb['met_tst_noJVT_et'] - fb['met_tst_et']\n",
    "    mask1 = dmet_tmp > -21000\n",
    "    mask2 = dmet_tmp < 41600\n",
    "    fb = fb[mask1 * mask2]\n",
    "\n",
    "    dphi_jj_tmp = fb['dphi_central_jj']\n",
    "    dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "    dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "    dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "    fb = fb[dphi_jj_tmp < 2.37]\n",
    "\n",
    "    dphi_met_jetterm_tmp = np.where(fb['met_jetterm_et'] != 0,   # added cut 5\n",
    "                        np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                        -999)\n",
    "    fb = fb[dphi_met_jetterm_tmp < 0.73]\n",
    "\n",
    "    # print_cut(ntuple_name, fb, 'after basic + selection cut')\n",
    "    '''\n",
    "    print_cut(ntuple_name, fb, 'after basic')\n",
    "\n",
    "    test(fb) # check for none value\n",
    "\n",
    "    print(f\"Reading Time for {ntuple_name}: {(time.time()-start_time)} seconds\\n\")\n",
    "\n",
    "\n",
    "    tot.append(fb)\n",
    "\n",
    "    fb = 0\n",
    "    fb_BDT = 0\n",
    "    tmp = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c56a867-2cb8-4eba-ad46-5ac101d46b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_name = 'ggHyyd'  # Define signal dataset\n",
    "cut_name = 'basic'  \n",
    "\n",
    "def getCutDict():\n",
    "    cut_dict = {}\n",
    "    # Selection 1: same variables as in the internal note\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 10000 + 100, 100), # dmet > cut\n",
    "        'uppercut': np.arange(10000, 100000 + 100, 100), # -10000 < dmet < cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(1, 2 + 0.01, 0.01), # dphi_met_phterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'uppercut': np.arange(0.5, 1, 0.01), # dphi_met_jetterm < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.01, 0.01), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\n",
    "    }\n",
    "\n",
    "    # Selection 2\n",
    "    cut_dict['balance'] = {\n",
    "        'lowercut': np.arange(0.2, 1.5 + 0.01, 0.01), # balance > cut\n",
    "        'uppercut': np.arange(0.5, 3, 0.01) # balance < cut\n",
    "    }\n",
    "    cut_dict['jetterm'] = {\n",
    "        'lowercut': np.arange(0, 150000+1000, 1000) # jetterm > cut\n",
    "    }\n",
    "    cut_dict['ph_pt'] = {\n",
    "        'lowercut': np.arange(50000, 100000 + 1000, 1000),  # ph_pt > cut\n",
    "        'uppercut': np.arange(100000, 300000 + 1000, 1000),  # ph_pt > cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.05, 0.05), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['metsigres'] = {\n",
    "        'uppercut': np.arange(12000, 60000, 1000)\n",
    "    }\n",
    "    cut_dict['met_noJVT'] = {\n",
    "        'lowercut': np.arange(50000, 120000, 1000),\n",
    "    }\n",
    "    \n",
    "    return cut_dict\n",
    "cut_config = getCutDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be48719-8c9e-4e53-93ce-d47b794e63e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -19400, 'best_sig_x_acc': 1.8218156666685783, 'significance': 1.8370676880976597, 'acceptance': 99.1697626860513}\n",
      "{'cut_var': 'dmet', 'cut_type': 'uppercut', 'best_cut': 41800, 'best_sig_x_acc': 1.7533151838946883, 'significance': 1.7537552502018237, 'acceptance': 99.97490719944618}\n",
      "{'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6, 'best_sig_x_acc': 2.3725553020181507, 'significance': 2.5828703809512277, 'acceptance': 91.85731190832652}\n",
      "{'cut_var': 'metsig', 'cut_type': 'uppercut', 'best_cut': 20, 'best_sig_x_acc': 1.7512994164399953, 'significance': 1.7512983444608226, 'acceptance': 100.00006121053995}\n",
      "{'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.03, 'best_sig_x_acc': 1.7935629035994418, 'significance': 1.8177016513714308, 'acceptance': 98.67201816349913}\n",
      "{'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.8800000000000003, 'best_sig_x_acc': 1.7517103097746178, 'significance': 1.7517092375439351, 'acceptance': 100.00006121053995}\n",
      "{'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 2.3500000000000014, 'best_sig_x_acc': 1.7530576561309936, 'significance': 1.7558692160199285, 'acceptance': 99.83987646327623}\n",
      "{'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 3.120000000000002, 'best_sig_x_acc': 0.9262633578182147, 'significance': 1.402227650975061, 'acceptance': 66.0565605858737}\n",
      "{'cut_var': 'balance', 'cut_type': 'lowercut', 'best_cut': 0.6300000000000003, 'best_sig_x_acc': 1.8372184620247347, 'significance': 1.870341868661218, 'acceptance': 98.22901859860555}\n",
      "{'cut_var': 'balance', 'cut_type': 'uppercut', 'best_cut': 2.030000000000001, 'best_sig_x_acc': 1.8047076436031868, 'significance': 1.8732969713541772, 'acceptance': 96.33857691546855}\n",
      "{'cut_var': 'jetterm', 'cut_type': 'lowercut', 'best_cut': 83000, 'best_sig_x_acc': 1.7764865265145708, 'significance': 1.788677131943356, 'acceptance': 99.31845690812067}\n",
      "ph_pt 0 51\n",
      "{'cut_var': 'ph_pt', 'cut_type': 'uppercut', 'best_cut': 297000, 'best_sig_x_acc': 1.7301562084158948, 'significance': 1.7433918556764225, 'acceptance': 99.24081053737672}\n",
      "{'cut_var': 'dphi_phterm_jetterm', 'cut_type': 'lowercut', 'best_cut': 1.4500000000000004, 'best_sig_x_acc': 1.7991566522693307, 'significance': 1.8041193207845243, 'acceptance': 99.72492570430234}\n",
      "{'cut_var': 'dphi_phterm_jetterm', 'cut_type': 'uppercut', 'best_cut': 3.100000000000001, 'best_sig_x_acc': 1.7513762340324044, 'significance': 1.7513751620062112, 'acceptance': 100.00006121053995}\n",
      "{'cut_var': 'metsigres', 'cut_type': 'uppercut', 'best_cut': 27000, 'best_sig_x_acc': 2.165956737985269, 'significance': 2.2550092115443054, 'acceptance': 96.05090422233573}\n",
      "{'cut_var': 'met_noJVT', 'cut_type': 'lowercut', 'best_cut': 98000, 'best_sig_x_acc': 1.829436539065188, 'significance': 1.8452919642745114, 'acceptance': 99.1407633308826}\n",
      "CPU times: user 10min 17s, sys: 2.39 s, total: 10min 19s\n",
      "Wall time: 10min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "signal_name='ggHyyd'\n",
    "initial_cut = []\n",
    "tot2 = tot\n",
    "\n",
    "# < -- Initial Cut on all variables (maximize the significance * acceptance) -- > \n",
    "for cut_var, cut_types in cut_config.items():\n",
    "    for cut_type, cut_values in cut_types.items():\n",
    "        sig_simple_list, sigacc_simple_list, acceptance_values = calculate_significance(\n",
    "            cut_var, cut_type, cut_values, tot2, ntuple_names, signal_name, getVarDict, getWeight\n",
    "        )\n",
    "\n",
    "        best_cut, best_sig, idx = get_best_cut(cut_values, sigacc_simple_list) \n",
    "        \n",
    "        if idx == 0 or idx == len(sigacc_simple_list) - 1: # I chose to use index to indicate not to make unnecessary cut (for initial cut)\n",
    "            print(cut_var, idx, len(sigacc_simple_list))\n",
    "            continue\n",
    "            \n",
    "        result = {\n",
    "            \"cut_var\": cut_var,\n",
    "            \"cut_type\": cut_type,\n",
    "            \"best_cut\": best_cut,\n",
    "            \"best_sig_x_acc\": best_sig,\n",
    "            \"significance\": sig_simple_list[idx],\n",
    "            \"acceptance\": acceptance_values[idx]\n",
    "        }\n",
    "\n",
    "        print(result)\n",
    "        initial_cut.append(dict(list(result.items())[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9fa4546-3a23-4915-a9c6-96e8fd16e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after initial cutting, signficance:  2.733286501616026\n"
     ]
    }
   ],
   "source": [
    "tot2_initial_cut = apply_all_cuts(tot2, ntuple_names, initial_cut, getVarDict)\n",
    "final_significance = compute_total_significance(tot2_initial_cut, ntuple_names, signal_name, getVarDict, getWeight)\n",
    "print('after initial cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4bd9ee6-5854-42d9-bcc5-82f4f08a347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "Updating dmet (uppercut): 41800 → 41700  (N-1 2.732 → with-cut 2.733)\n",
      "Updating metsig (lowercut): 6 → 7  (N-1 2.559 → with-cut 2.804)\n",
      "Updating metsig (uppercut): 20 → 17  (N-1 2.804 → with-cut 2.805)\n",
      "Updating dphi_met_phterm (lowercut): 1.03 → 1.2000000000000002  (N-1 2.815 → with-cut 2.852)\n",
      "Updating dphi_met_jetterm (uppercut): 0.8800000000000003 → 0.7300000000000002  (N-1 2.851 → with-cut 2.854)\n",
      "Updating ph_eta (uppercut): 2.3500000000000014 → 1.7400000000000007  (N-1 2.838 → with-cut 3.055)\n",
      "Dropping dphi_jj (uppercut): N-1 3.057 >= best-with-cut 2.401\n",
      "Updating balance (lowercut): 0.6300000000000003 → 0.9100000000000006  (N-1 2.976 → with-cut 3.162)\n",
      "Dropping balance (uppercut): N-1 3.227 >= best-with-cut 3.218\n",
      "Updating jetterm (lowercut): 83000 → 81000  (N-1 3.164 → with-cut 3.164)\n",
      "Dropping ph_pt (uppercut): N-1 3.177 >= best-with-cut 3.164\n",
      "Updating dphi_phterm_jetterm (lowercut): 1.4500000000000004 → 1.6000000000000005  (N-1 3.164 → with-cut 3.166)\n",
      "Updating dphi_phterm_jetterm (uppercut): 3.100000000000001 → 3.000000000000001  (N-1 3.166 → with-cut 3.166)\n",
      "Updating metsigres (uppercut): 27000 → 36000  (N-1 3.196 → with-cut 3.198)\n",
      "Updating met_noJVT (lowercut): 98000 → 90000  (N-1 3.201 → with-cut 3.205)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Updating dmet (uppercut): 41700.0 → 41600  (N-1 3.276 → with-cut 3.280)\n",
      "Updating metsig (uppercut): 17.0 → 20  (N-1 3.285 → with-cut 3.285)\n",
      "Updating dphi_met_phterm (lowercut): 1.2000000000000002 → 1.2300000000000002  (N-1 3.267 → with-cut 3.292)\n",
      "Updating dphi_met_jetterm (uppercut): 0.7300000000000002 → 0.7500000000000002  (N-1 3.290 → with-cut 3.292)\n",
      "Updating jetterm (lowercut): 81000.0 → 92000  (N-1 3.291 → with-cut 3.292)\n",
      "Updating dphi_phterm_jetterm (uppercut): 3.000000000000001 → 3.100000000000001  (N-1 3.304 → with-cut 3.304)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "optimized cuts, end of iteration\n",
      "after optimized cutting, signficance:  3.303890341832656\n",
      "CPU times: user 20min 46s, sys: 5.14 s, total: 20min 51s\n",
      "Wall time: 21min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def n_minus_1_optimizer(\n",
    "    initial_cut,\n",
    "    cut_config,\n",
    "    tot2,\n",
    "    ntuple_names,\n",
    "    signal_name,\n",
    "    getVarDict,\n",
    "    getWeight,\n",
    "    final_significance,\n",
    "    max_iter=10,\n",
    "    tolerance=1e-4,\n",
    "    allow_drop=True,\n",
    "    drop_tolerance=1e-6\n",
    "):\n",
    "    \"\"\"\n",
    "    allow_drop: if True, remove a cut when N-1 significance beats the best-with-cut significance.\n",
    "    drop_tolerance: minimal margin by which N-1 must exceed best-with-cut to drop the cut.\n",
    "    \"\"\"\n",
    "    best_cuts = [dict(c) for c in initial_cut]  # copy\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < max_iter:\n",
    "        converged = True\n",
    "        to_remove = []\n",
    "\n",
    "        print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "\n",
    "        for i, cut in enumerate(best_cuts):\n",
    "            # Apply all OTHER cuts (N-1)\n",
    "            n_minus_1_cuts = best_cuts[:i] + best_cuts[i+1:]\n",
    "            tot2_cut = apply_all_cuts(tot2, ntuple_names, n_minus_1_cuts, getVarDict)\n",
    "\n",
    "            # Significance WITHOUT this cut\n",
    "            sig_without = compute_total_significance(\n",
    "                tot2_cut, ntuple_names, signal_name, getVarDict, getWeight\n",
    "            )\n",
    "\n",
    "            # Re-scan this variable ON TOP of N-1\n",
    "            cut_var  = cut[\"cut_var\"]\n",
    "            cut_type = cut[\"cut_type\"]\n",
    "            scan_vals = cut_config[cut_var][cut_type]\n",
    "\n",
    "            sig_simple_list, sigacc_simple_list, _ = calculate_significance(\n",
    "                cut_var, cut_type, scan_vals, tot2_cut, ntuple_names,\n",
    "                signal_name, getVarDict, getWeight\n",
    "            )\n",
    "            best_cut_val, best_sig, best_idx = get_best_cut(scan_vals, sig_simple_list)\n",
    "\n",
    "            # Decide to drop or to keep/update\n",
    "            if allow_drop and (sig_without >= best_sig + drop_tolerance):\n",
    "                print(f\"Dropping {cut_var} ({cut_type}): \"\n",
    "                      f\"N-1 {sig_without:.3f} >= best-with-cut {best_sig:.3f}\")\n",
    "                to_remove.append(i)\n",
    "                final_significance = sig_without\n",
    "                converged = False\n",
    "                continue  # move to next cut\n",
    "\n",
    "            # Keep: update threshold if it moved\n",
    "            if abs(best_cut_val - cut[\"best_cut\"]) > tolerance:\n",
    "                print(f\"Updating {cut_var} ({cut_type}): \"\n",
    "                      f\"{cut['best_cut']} → {best_cut_val}  \"\n",
    "                      f\"(N-1 {sig_without:.3f} → with-cut {best_sig:.3f})\")\n",
    "                best_cuts[i][\"best_cut\"] = float(best_cut_val)\n",
    "                final_significance = best_sig\n",
    "                converged = False\n",
    "\n",
    "        # Remove cuts marked for deletion (highest index first)\n",
    "        if to_remove:\n",
    "            for j in sorted(to_remove, reverse=True):\n",
    "                del best_cuts[j]\n",
    "\n",
    "        iteration += 1\n",
    "        if converged:\n",
    "            break\n",
    "\n",
    "    # Recompute final significance with the surviving cuts\n",
    "    tot2_final = apply_all_cuts(tot2, ntuple_names, best_cuts, getVarDict)\n",
    "    final_significance = compute_total_significance(\n",
    "        tot2_final, ntuple_names, signal_name, getVarDict, getWeight\n",
    "    )\n",
    "\n",
    "    print('optimized cuts, end of iteration')\n",
    "    return best_cuts, final_significance\n",
    "\n",
    "# < -- n-1 iterations until no further improvement (max significance) -- >\n",
    "optimized_cuts, final_significance = n_minus_1_optimizer(\n",
    "    initial_cut, cut_config, tot2, ntuple_names, signal_name, getVarDict, getWeight, final_significance\n",
    ")\n",
    "print('after optimized cutting, signficance: ', final_significance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc19fe8-0dbe-4441-8a77-b03d462bf77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " < -- Final Optimized Cuts -- > \n",
      "dmet > -19400\n",
      "dmet < 41600.0\n",
      "metsig > 7.0\n",
      "metsig < 20.0\n",
      "dphi_met_phterm > 1.2300000000000002\n",
      "dphi_met_jetterm < 0.7500000000000002\n",
      "ph_eta < 1.7400000000000007\n",
      "balance > 0.9100000000000006\n",
      "jetterm > 92000.0\n",
      "dphi_phterm_jetterm > 1.6000000000000005\n",
      "dphi_phterm_jetterm < 3.100000000000001\n",
      "metsigres < 36000.0\n",
      "met_noJVT > 90000.0\n",
      "after optimized cutting, signficance:  3.303890341832656\n"
     ]
    }
   ],
   "source": [
    "print( ' < -- Final Optimized Cuts -- > ')\n",
    "# print(optimized_cuts)\n",
    "\n",
    "for cut in optimized_cuts:\n",
    "    var = cut['cut_var']\n",
    "    val = cut['best_cut']\n",
    "    if cut['cut_type'] == 'uppercut':\n",
    "        print(f\"{var} < {val}\")\n",
    "    elif cut['cut_type'] == 'lowercut':\n",
    "        print(f\"{var} > {val}\")\n",
    "        \n",
    "print('after optimized cutting, signficance: ', final_significance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "008e0282-8079-4f6b-bf6b-804cab6464a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< -- Sum of weight each process -- >\n",
      "ggHyyd 167.68508374299802\n",
      "Zjets 1.249980680862791\n",
      "Zgamma 419.8129254336955\n",
      "Wgamma 798.4444671642431\n",
      "Wjets 710.7393202873664\n",
      "gammajet_direct 6.537942385999486\n",
      "data23 666.2637042786454\n"
     ]
    }
   ],
   "source": [
    "tot2_optimized_cuts = apply_all_cuts(tot2, ntuple_names, optimized_cuts, getVarDict)\n",
    "\n",
    "print('< -- Sum of weight each process -- >')\n",
    "\n",
    "for i in range(len(tot2_optimized_cuts)):\n",
    "    print(ntuple_names[i], sum(getWeight(tot2_optimized_cuts[i], ntuple_names[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
