{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b353b7-b507-4881-9f15-bc69b0de3806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file:  /data/tmathew/ntups/mc23d/ggHyyd_y.root\n",
      "Unweighted Events before cut:  86910\n",
      "Weighted Events before cut:  8732.987955115426\n",
      "Unweighted Events after basic:  3886\n",
      "Weighted Events after basic:  394.5242670979061\n",
      "Number of none values:  0\n",
      "Reading Time for ggHyyd: 1.654658317565918 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Zjets_y.root\n",
      "Unweighted Events before cut:  3242488\n",
      "Weighted Events before cut:  676616.903247458\n",
      "Unweighted Events after basic:  3638\n",
      "Weighted Events after basic:  103.81466139199914\n",
      "Number of none values:  0\n",
      "Reading Time for Zjets: 92.38290119171143 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Zgamma_y.root\n",
      "Unweighted Events before cut:  3423357\n",
      "Weighted Events before cut:  249851.55031619867\n",
      "Unweighted Events after basic:  636216\n",
      "Weighted Events after basic:  15453.095393066718\n",
      "Number of none values:  0\n",
      "Reading Time for Zgamma: 52.324854135513306 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Wgamma_y.root\n",
      "Unweighted Events before cut:  1308982\n",
      "Weighted Events before cut:  427927.31994993926\n",
      "Unweighted Events after basic:  150346\n",
      "Weighted Events after basic:  14462.122866353382\n",
      "Number of none values:  0\n",
      "Reading Time for Wgamma: 26.808656930923462 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Wjets_y.root\n",
      "Unweighted Events before cut:  1962593\n",
      "Weighted Events before cut:  2815306.4335920406\n",
      "Unweighted Events after basic:  48111\n",
      "Weighted Events after basic:  18166.124170503186\n",
      "Number of none values:  0\n",
      "Reading Time for Wjets: 42.08075261116028 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/gammajet_direct_y.root\n",
      "Unweighted Events before cut:  12921098\n",
      "Weighted Events before cut:  147918307.09228534\n",
      "Unweighted Events after basic:  877582\n",
      "Weighted Events after basic:  52429.03338146549\n",
      "Number of none values:  0\n",
      "Reading Time for gammajet_direct: 74.32949900627136 seconds\n",
      "\n",
      "processing file:  /data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/data23_y_BDT_score.root\n",
      "Unweighted Events before cut:  3354286\n",
      "Weighted Events before cut:  36165772.75273502\n",
      "Unweighted Events after basic:  17148\n",
      "Weighted Events after basic:  184316.0880954626\n",
      "Number of none values:  0\n",
      "Reading Time for data23: 71.60574626922607 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math, pickle, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "\n",
    "# import config functions\n",
    "sys.path.append(\"/home/jlai/jet-faking/config\")\n",
    "from jet_faking_plot_config import getWeight, zbi, sample_dict, getVarDict # 135 lumi\n",
    "# from jet_faking_26_config import getWeight, zbi, sample_dict, getVarDict # 26 lumi\n",
    "from plot_var import variables, variables_data, ntuple_names, ntuple_names_BDT\n",
    "from n_1_iteration_functions import get_best_cut, calculate_significance, apply_cut_to_fb, apply_all_cuts, compute_total_significance, n_minus_1_optimizer\n",
    "# from cut_config import cut_config\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high  \n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"]  # Legend\n",
    "})\n",
    "\n",
    "tot = []\n",
    "data = pd.DataFrame()\n",
    "ntuple_names = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct', 'data23']\n",
    "\n",
    "def test(fb):\n",
    "    # checking if there are any none values\n",
    "    mask = ak.is_none(fb['met_tst_et'])\n",
    "    n_none = ak.sum(mask)\n",
    "    print(\"Number of none values: \", n_none)\n",
    "    # if n_none > 0:\n",
    "    #     fb = fb[~mask]\n",
    "    # print(\"Events after removing none values: \", len(fb), ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "\n",
    "def print_cut(ntuple_name, fb, label):\n",
    "    print(f\"Unweighted Events {label}: \", len(fb))\n",
    "    if ntuple_name == 'data23':\n",
    "        print(f\"Weighted Events {label}: \", sum(getWeight(fb, ntuple_name, jet_faking=True)))\n",
    "    else: \n",
    "        print(f\"Weighted Events {label}: \", sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "for i in range(len(ntuple_names)):\n",
    "    start_time = time.time()\n",
    "    ntuple_name = ntuple_names[i]\n",
    "    if ntuple_name == 'data23': # data\n",
    "        path = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/data23_y_BDT_score.root\" \n",
    "        print('processing file: ', path)\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables_data, library=\"ak\")\n",
    "        fb['VertexBDTScore'] = fb['BDTScore'] # renaming BDTScore to ensure this is recognized as Vertex BDT Score\n",
    "        \n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "                \n",
    "        mask1 = (ak.firsts(fb['ph_topoetcone40'])-2450.)/ak.firsts(fb['ph_pt']) > 0.1   # jet_faking_photon cut\n",
    "        fb = fb[mask1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 1]\n",
    "\n",
    "    else: # MC\n",
    "        path = f\"/data/tmathew/ntups/mc23d/{ntuple_name}_y.root\" \n",
    "        path_BDT = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/mc23d_{ntuple_name}_y_BDT_score.root\" \n",
    "        print('processing file: ', path)\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables, library=\"ak\")\n",
    "\n",
    "        # add BDT score to fb\n",
    "        f_BDT = uproot.open(path_BDT)['nominal']\n",
    "        fb_BDT = f_BDT.arrays([\"event\", \"BDTScore\"], library=\"ak\")\n",
    "        tmp = fb[\"event\"] == fb_BDT[\"event\"]\n",
    "        if np.all(tmp) == True:\n",
    "            fb[\"VertexBDTScore\"] = fb_BDT[\"BDTScore\"]\n",
    "        else: \n",
    "            print(\"Something is wrong, need arranging\")\n",
    "\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "        fb = fb[fb['n_ph'] == 1]\n",
    "        \n",
    "        # Zjets and Wjets (rule out everything except for e->gamma)\n",
    "        if ntuple_name == 'Zjets' or ntuple_name == 'Wjets':\n",
    "            mask = ak.firsts(fb['ph_truth_type']) == 2\n",
    "            fb = fb[mask]\n",
    "        \n",
    "        # goodPV on signal only\n",
    "        if ntuple_name == 'ggHyyd':\n",
    "            fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "            good_pv_tmp = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "            fb = fb[good_pv_tmp]\n",
    "\n",
    "    print_cut(ntuple_name, fb, 'before cut')\n",
    "\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    fb = fb[fb['n_el_baseline'] == 0]\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M']==1]\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0] # prevent none values in Tbranch\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) >= 50000] # ph_pt cut (basic cut)\n",
    "    fb = fb[fb['met_tst_et'] >= 100000] # MET cut (basic cut)\n",
    "    fb = fb[fb['n_jet_central'] <= 3] # n_jet_central cut (basic cut)\n",
    "\n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "                            (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    mask1 = mt_tmp > 80\n",
    "    fb = fb[mask1]\n",
    "    # mask1 = mt_tmp > 100\n",
    "    # mask2 = mt_tmp < 140 \n",
    "    # fb = fb[mask1 * mask2]\n",
    "\n",
    "    fb = fb[fb['VertexBDTScore'] > 0.1]\n",
    "\n",
    "    \n",
    "    ''' # Selection cut\n",
    "    metsig_tmp = fb['met_tst_sig'] \n",
    "    mask1 = metsig_tmp > 7\n",
    "    mask2 = metsig_tmp < 20\n",
    "    fb = fb[mask1 * mask2]\n",
    "    \n",
    "    ph_eta_tmp = np.abs(ak.firsts(fb['ph_eta']))\n",
    "    fb = fb[ph_eta_tmp < 1.74]\n",
    "\n",
    "    dphi_met_phterm_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])) # added cut 3\n",
    "    fb = fb[dphi_met_phterm_tmp > 1.23]\n",
    "\n",
    "    dmet_tmp = fb['met_tst_noJVT_et'] - fb['met_tst_et']\n",
    "    mask1 = dmet_tmp > -21200\n",
    "    mask2 = dmet_tmp < 41600\n",
    "    fb = fb[mask1 * mask2]\n",
    "\n",
    "    dphi_jj_tmp = fb['dphi_central_jj']\n",
    "    dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "    dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "    dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "    fb = fb[dphi_jj_tmp < 2.37]\n",
    "\n",
    "    dphi_met_jetterm_tmp = np.where(fb['met_jetterm_et'] != 0,   # added cut 5\n",
    "                        np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                        -999)\n",
    "    fb = fb[dphi_met_jetterm_tmp < 0.73]\n",
    "\n",
    "    # print_cut(ntuple_name, fb, 'after basic + selection cut')\n",
    "    '''\n",
    "    print_cut(ntuple_name, fb, 'after basic')\n",
    "\n",
    "    test(fb) # check for none value\n",
    "\n",
    "    print(f\"Reading Time for {ntuple_name}: {(time.time()-start_time)} seconds\\n\")\n",
    "\n",
    "\n",
    "    tot.append(fb)\n",
    "\n",
    "    fb = 0\n",
    "    fb_BDT = 0\n",
    "    tmp = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "666494f2-5650-4cf8-80c2-15c03d88129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: divide by zero encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         cut       S         B  S/sqrt(B)  ZBi(30%)\n",
      "              (no extra cut) 181.500 3,402.285      3.112    -0.022\n",
      "                balance>0.91 168.548 2,666.603      3.264     0.009\n",
      "        met_jetterm_et>92GeV 181.026 3,373.627      3.117    -0.021\n",
      "1.6<dphi(phterm,jetterm)<3.1 181.452 3,382.475      3.120    -0.021\n",
      "             metsigres<36GeV 181.382 3,386.578      3.117    -0.022\n",
      "             met_noJVT>90GeV 181.372 3,384.797      3.117    -0.022\n"
     ]
    }
   ],
   "source": [
    "signal_name = 'ggHyyd'\n",
    "\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- helpers ---\n",
    "def weight_sum(fb, ntuple_name):\n",
    "    if ntuple_name == 'data23':\n",
    "        return float(ak.sum(getWeight(fb, ntuple_name, jet_faking=True)))\n",
    "    else:\n",
    "        return float(ak.sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "def s_over_sqrt_b(S, B):\n",
    "    return S/np.sqrt(B) if B > 0 else 0.0\n",
    "\n",
    "def zbi(S, B, sigma_b_frac=0.30):\n",
    "    # Binomial significance with background uncertainty\n",
    "    if B <= 0:\n",
    "        return 0.0\n",
    "    tau   = 1.0 / (B * sigma_b_frac * sigma_b_frac)\n",
    "    n_on  = S + B\n",
    "    n_off = B * tau\n",
    "    P_Bi  = betainc(n_on, n_off + 1, 1.0 / (1.0 + tau))\n",
    "    if P_Bi <= 0:\n",
    "        return 0.0\n",
    "    return float(norm.ppf(1.0 - P_Bi))\n",
    "\n",
    "# Minimal, branchless Δφ in [0, π]\n",
    "def dphi(a, b):\n",
    "    return np.abs((a - b + np.pi) % (2*np.pi) - np.pi)\n",
    "\n",
    "# --- define the \"further selection\" cuts as functions that return a boolean mask ---\n",
    "def cut_balance_gt_0p91(fb):\n",
    "    # balance = (MET + photon pT) / sum(pt_jets); if denom==0 treat as missing → pass\n",
    "    jet_sum = ak.sum(fb['jet_central_pt'], axis=-1)\n",
    "    has_denom = (jet_sum != 0)\n",
    "    # Only compute ratio where denom exists\n",
    "    ratio = ak.where(has_denom, (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / jet_sum, 0.0)\n",
    "    return (~has_denom) | (ratio > 0.91)\n",
    "\n",
    "def cut_met_jetterm_et_gt_92GeV(fb):\n",
    "    return fb['met_jetterm_et'] > 92_000\n",
    "\n",
    "def cut_dphi_phterm_jetterm_window(fb, low=1.6, high=3.1):\n",
    "    # angle defined only if met_jetterm_et>0; missing → pass\n",
    "    cond  = fb['met_jetterm_et'] > 0\n",
    "    angle = ak.where(cond, dphi(fb['met_phterm_phi'], fb['met_jetterm_phi']), 0.0)\n",
    "    return (~cond) | ((angle > low) & (angle < high))\n",
    "\n",
    "def cut_metsigres_lt_36GeV(fb):\n",
    "    # metsigres = MET / METsig  (in MeV; 36 GeV = 36000 MeV)\n",
    "    # Guard against nonpositive sig; if sig<=0, we conservatively fail the cut.\n",
    "    sig_ok = fb['met_tst_sig'] > 0\n",
    "    ratio  = ak.where(sig_ok, fb['met_tst_et'] / fb['met_tst_sig'], np.inf)\n",
    "    return ratio < 36_000\n",
    "\n",
    "def cut_met_noJVT_gt_90GeV(fb):\n",
    "    return fb['met_tst_noJVT_et'] > 90_000\n",
    "\n",
    "# Bundle all the single-cut masks you want to test\n",
    "CUTS = [\n",
    "    (\"balance>0.91\",              cut_balance_gt_0p91),\n",
    "    (\"met_jetterm_et>92GeV\",      cut_met_jetterm_et_gt_92GeV),\n",
    "    (\"1.6<dphi(phterm,jetterm)<3.1\", cut_dphi_phterm_jetterm_window),\n",
    "    (\"metsigres<36GeV\",           cut_metsigres_lt_36GeV),\n",
    "    (\"met_noJVT>90GeV\",           cut_met_noJVT_gt_90GeV),\n",
    "]\n",
    "\n",
    "def significance_by_single_cuts(tot, ntuple_names, signal_name=\"ggHyyd\", sigma_b_frac=0.30, include_zbi=True):\n",
    "    \"\"\"\n",
    "    For each cut in CUTS: apply only that cut on top of the baseline 'tot',\n",
    "    then compute S, B, S/sqrt(B) (and ZBi).\n",
    "    Returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Precompute per-sample weights once (so we don't rebuild weights inside each cut)\n",
    "    weights = []\n",
    "    for i, fb in enumerate(tot):\n",
    "        name = ntuple_names[i]\n",
    "        if name == 'data23':\n",
    "            w = getWeight(fb, name, jet_faking=True)\n",
    "        else:\n",
    "            w = getWeight(fb, name)\n",
    "        weights.append(w)\n",
    "\n",
    "    rows = []\n",
    "    # Also compute baseline (no extra cut) significance for reference\n",
    "    S0 = 0.0\n",
    "    B0 = 0.0\n",
    "    for i, fb in enumerate(tot):\n",
    "        name = ntuple_names[i]\n",
    "        wsum = float(ak.sum(weights[i]))\n",
    "        if name == signal_name:\n",
    "            S0 += wsum\n",
    "        else:      # exclude data from B\n",
    "            B0 += wsum\n",
    "    base = {\n",
    "        \"cut\": \"(no extra cut)\",\n",
    "        \"S\": S0,\n",
    "        \"B\": B0,\n",
    "        \"S/sqrt(B)\": s_over_sqrt_b(S0, B0)\n",
    "    }\n",
    "    if include_zbi:\n",
    "        base[\"ZBi(30%)\"] = zbi(S0, B0, sigma_b_frac)\n",
    "    rows.append(base)\n",
    "\n",
    "    # Now evaluate each single cut\n",
    "    for label, cut_fn in CUTS:\n",
    "        S = 0.0\n",
    "        B = 0.0\n",
    "        for i, fb in enumerate(tot):\n",
    "            name = ntuple_names[i]\n",
    "            m = cut_fn(fb)                      # boolean mask (Awkward-friendly)\n",
    "            w = weights[i][m]                   # apply mask to precomputed event weights\n",
    "            wsum = float(ak.sum(w))\n",
    "            if name == signal_name:\n",
    "                S += wsum\n",
    "            else:\n",
    "                B += wsum\n",
    "\n",
    "        row = {\n",
    "            \"cut\": label,\n",
    "            \"S\": S,\n",
    "            \"B\": B,\n",
    "            \"S/sqrt(B)\": s_over_sqrt_b(S, B)\n",
    "        }\n",
    "        if include_zbi:\n",
    "            row[\"ZBi(30%)\"] = zbi(S, B, sigma_b_frac)\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Nicely formatted view (optional)\n",
    "    with pd.option_context('display.float_format', '{:,.3f}'.format):\n",
    "        print(df.to_string(index=False))\n",
    "    return df\n",
    "\n",
    "# --- RUN IT ---\n",
    "# Assume you already filled `tot` with your baseline (after basic cuts) per-process arrays\n",
    "# and `ntuple_names` matches that order.\n",
    "sig_table = significance_by_single_cuts(tot, ntuple_names, signal_name='ggHyyd', sigma_b_frac=0.30, include_zbi=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "435eaa53-aa5c-4238-95ec-dd72906b6571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.111651247575169"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weight_sum(fb, ntuple_name):\n",
    "    if ntuple_name == 'data23':\n",
    "        return float(np.sum(getWeight(fb, ntuple_name, jet_faking=True)))\n",
    "    else:\n",
    "        return float(np.sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # ---------- FURTHER SELECTION CUT ------------\n",
    "    jet_sum_tmp = ak.sum(fb['jet_central_pt'], axis=-1)\n",
    "    expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "    balance_tmp = ak.where(jet_sum_tmp != 0, expr, -999)\n",
    "    mask_nan = balance_tmp == -999\n",
    "    mask = mask_nan | (balance_tmp > 0.91)\n",
    "    fb = fb[mask]\n",
    "\n",
    "    fb = fb[fb['met_jetterm_et'] > 92000]\n",
    "\n",
    "    dphi_phterm_jetterm_tmp = np.where(fb['met_jetterm_et'] > 0,\n",
    "                                        np.arccos(np.cos(fb['met_phterm_phi'] - fb['met_jetterm_phi'])),\n",
    "                                        -999)\n",
    "    mask1 = dphi_phterm_jetterm_tmp == -999\n",
    "    mask2 = dphi_phterm_jetterm_tmp > 1.6 \n",
    "    mask3 = dphi_phterm_jetterm_tmp < 3.1 \n",
    "    in_window = mask2 & mask3\n",
    "    mask = mask1 | in_window\n",
    "    fb = fb[mask]\n",
    "    log_step(ntuple_name, step, \"3.1>dphi_phterm_jetterm>1.6\", fb, start_time); step += 1\n",
    "\n",
    "    metsigres_tmp = fb['met_tst_et'] / fb['met_tst_sig']\n",
    "    fb = fb[metsigres_tmp < 36000]\n",
    "    log_step(ntuple_name, step, \"metsigres<36000\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['met_tst_noJVT_et'] > 90000]\n",
    "    log_step(ntuple_name, step, \"met_noJVT>90GeV\", fb, start_time); step += 1\n",
    "\n",
    "    \n",
    "s, b = [], []\n",
    "for i in range(len(tot)):\n",
    "    fb = tot[i]\n",
    "    process = ntuple_names[i]\n",
    "    sum_weight = weight_sum(fb, process)\n",
    "    if process == signal_name:\n",
    "        s.append(sum_weight)\n",
    "    else:\n",
    "        b.append(sum_weight)\n",
    "sum(s)/np.sqrt(sum(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "906edc41-b1f5-4332-9bd3-ccc6342c2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "def get_best_cut(cut_values, significance_list):\n",
    "    max_idx = np.argmax(significance_list)\n",
    "    best_cut = cut_values[max_idx]\n",
    "    best_sig = significance_list[max_idx]\n",
    "    return best_cut, best_sig, max_idx\n",
    "\n",
    "def calculate_significance(cut_var, cut_type, cut_values, tot2, ntuple_names, signal_name, getVarDict, getWeight):\n",
    "    sig_simple_list = []\n",
    "    sigacc_simple_list = []\n",
    "    acceptance_values = []\n",
    "    tot_tmp = []\n",
    "\n",
    "    for cut in cut_values:\n",
    "        sig_after_cut = 0\n",
    "        bkg_after_cut = []\n",
    "        sig_events = 0\n",
    "\n",
    "        for i in range(len(ntuple_names)):\n",
    "            fb = tot2[i]\n",
    "            process = ntuple_names[i]\n",
    "            var_config = getVarDict(fb, process, var_name=cut_var)\n",
    "            x = var_config[cut_var]['var']\n",
    "            mask_nan = x == -999\n",
    "            \n",
    "            if process == signal_name:\n",
    "                sig_events = getWeight(fb, process)\n",
    "                mask_cut = x > cut if cut_type == 'lowercut' else x < cut\n",
    "                mask = mask_nan | mask_cut\n",
    "                sig_after_cut = ak.sum(sig_events[mask])\n",
    "            else:\n",
    "                bkg_events = getWeight(fb, process)\n",
    "                mask_cut = x > cut if cut_type == 'lowercut' else x < cut\n",
    "                mask = mask_nan | mask_cut\n",
    "                bkg_after_cut.append(ak.sum(bkg_events[mask]))\n",
    "            \n",
    "            tot_tmp.append(fb)\n",
    "\n",
    "        total_bkg = sum(bkg_after_cut)\n",
    "        total_signal = sig_after_cut\n",
    "\n",
    "        sig_simple = total_signal / np.sqrt(total_bkg) if total_bkg > 0 else 0\n",
    "        acceptance = total_signal / sum(sig_events) if sum(sig_events) > 0 else 0\n",
    "\n",
    "        sig_simple_list.append(sig_simple)\n",
    "        sigacc_simple_list.append(sig_simple * acceptance)\n",
    "        acceptance_values.append(acceptance * 100)\n",
    "\n",
    "    return sig_simple_list, sigacc_simple_list, acceptance_values\n",
    "\n",
    "def apply_cut_to_fb(fb, process, var, cut_val, cut_type, getVarDict):\n",
    "    var_config = getVarDict(fb, process, var_name=var)\n",
    "    x = var_config[var]['var']\n",
    "    mask = x == -999\n",
    "\n",
    "    if cut_type == 'lowercut':\n",
    "        mask = mask | (x > cut_val)\n",
    "    elif cut_type == 'uppercut':\n",
    "        mask = mask | (x < cut_val)\n",
    "\n",
    "    return fb[mask]\n",
    "\n",
    "def apply_all_cuts(tot2, ntuple_names, cut_list, getVarDict):\n",
    "    new_tot2 = []\n",
    "    for i, fb in enumerate(tot2):\n",
    "        process = ntuple_names[i]\n",
    "        for cut in cut_list:\n",
    "            fb = apply_cut_to_fb(fb, process, cut[\"cut_var\"], cut[\"best_cut\"], cut[\"cut_type\"], getVarDict)\n",
    "        new_tot2.append(fb)\n",
    "    return new_tot2\n",
    "    \n",
    "def compute_total_significance(tot2, ntuple_names, signal_name, getVarDict, getWeight):\n",
    "    signal_sum = 0\n",
    "    bkg_sum = 0\n",
    "    for i in range(len(ntuple_names)):\n",
    "        fb = tot2[i]\n",
    "        process = ntuple_names[i]\n",
    "        weights = getWeight(fb, process)\n",
    "        if process == signal_name:\n",
    "            signal_sum += ak.sum(weights)\n",
    "        else:\n",
    "            bkg_sum += ak.sum(weights)\n",
    "    return signal_sum / np.sqrt(bkg_sum) if bkg_sum > 0 else 0\n",
    "\n",
    "def n_minus_1_optimizer(initial_cut, cut_config, tot2, ntuple_names, signal_name, getVarDict, getWeight, final_significance, max_iter=10, tolerance=1e-4, allow_drop=True):\n",
    "    '''\n",
    "    allow_drop: if True, remove a cut when N-1 significance beats the best-with-cut significance.\n",
    "    '''\n",
    "    best_cuts = initial_cut.copy()\n",
    "    iteration = 0\n",
    "    converged = False\n",
    "\n",
    "    while not converged and iteration < max_iter:\n",
    "        converged = True\n",
    "        print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "        for i, cut in enumerate(best_cuts):\n",
    "            # Apply all other cuts\n",
    "            n_minus_1_cuts = best_cuts[:i] + best_cuts[i+1:]\n",
    "            tot2_cut = apply_all_cuts(tot2, ntuple_names, n_minus_1_cuts, getVarDict)\n",
    "\n",
    "            # Re-scan this variable\n",
    "            cut_var = cut[\"cut_var\"]\n",
    "            cut_type = cut[\"cut_type\"]\n",
    "            cut_values = cut_config[cut_var][cut_type]\n",
    "\n",
    "            sig_simple_list, sigacc_simple_list, _ = calculate_significance(\n",
    "                cut_var, cut_type, cut_values, tot2_cut, ntuple_names\n",
    "                , signal_name, getVarDict, getWeight\n",
    "            )\n",
    "            best_cut, best_sig, idx = get_best_cut(cut_values, sig_simple_list)\n",
    "\n",
    "            if abs(best_cut - cut[\"best_cut\"]) > tolerance:\n",
    "            # if best_sig - final_significance > tolerance:\n",
    "                print(f\"Updating {cut_var} ({cut_type}): {cut['best_cut']} → {best_cut}  (sig {final_significance:.2f} → {best_sig:.2f})\")\n",
    "                best_cuts[i][\"best_cut\"] = best_cut\n",
    "                final_significance = best_sig\n",
    "                converged = False  # Found at least one improvement\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    print( ' optimized cuts, end of iteration ' )\n",
    "    return best_cuts, final_significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e4dc941-d976-470a-9358-fee780a7e9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39441435303979566 1.9390190119901982\n",
      "0.42500919233546663 1.4636710940241544\n",
      "0.30030457910746494 2.970968805620667\n",
      "0.2720821532151797 2.383233328752971\n",
      "0.21071048413551643 2.092933993540544\n",
      "0.892493695424075 1.4784713946581178\n",
      "0.2512871266343672 1.7726996395004793\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tot)):\n",
    "    fb = tot[i]\n",
    "    sumet_tmp = fb['met_jetterm_sumet']\n",
    "    expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(sumet_tmp != 0, sumet_tmp, 1)\n",
    "    balance_sumet = ak.where(sumet_tmp != 0, expr, -999)\n",
    "    balance_sumet = balance_sumet[balance_sumet != -999]\n",
    "    print(ak.min(balance_sumet), ak.max(balance_sumet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c56a867-2cb8-4eba-ad46-5ac101d46b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\n\\ndef getCutDict():\\n    cut_dict = {}\\n    # Selection 1: same variables as in the internal note\\n    cut_dict['dmet'] = {\\n        'lowercut': np.arange(-30000, 10000 + 100, 100), # dmet > cut\\n        'uppercut': np.arange(10000, 100000 + 100, 100), # -10000 < dmet < cut\\n    }\\n    cut_dict['metsig'] = {\\n        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\\n        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \\n    }\\n    cut_dict['dphi_met_phterm'] = {\\n        'lowercut': np.arange(1, 2 + 0.01, 0.01), # dphi_met_phterm > cut\\n    }\\n    cut_dict['dphi_met_jetterm'] = {\\n        'uppercut': np.arange(0.5, 1, 0.01), # dphi_met_jetterm < cut\\n    }\\n    cut_dict['ph_eta'] = {\\n        'uppercut': np.arange(1, 2.5 + 0.01, 0.01), # ph_eta < cut\\n    }\\n    cut_dict['dphi_jj'] = {\\n        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\\n    }\\n\\n    # Selection 2\\n    cut_dict['balance'] = {\\n        'lowercut': np.arange(0.2, 1.5 + 0.01, 0.01), # balance > cut\\n        'uppercut': np.arange(0.5, 3, 0.01) # balance < cut\\n    }\\n    cut_dict['jetterm'] = {\\n        'lowercut': np.arange(0, 150000+1000, 1000) # jetterm > cut\\n    }\\n    cut_dict['ph_pt'] = {\\n        'lowercut': np.arange(50000, 100000 + 1000, 1000),  # ph_pt > cut\\n        'uppercut': np.arange(100000, 300000 + 1000, 1000),  # ph_pt > cut\\n    }\\n    cut_dict['dphi_phterm_jetterm'] = {\\n        'lowercut': np.arange(1, 2.5 + 0.05, 0.05), # dphi_phterm_jetterm > cut\\n        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\\n    }\\n    cut_dict['metsigres'] = {\\n        'uppercut': np.arange(12000, 60000, 1000)\\n    }\\n    cut_dict['met_noJVT'] = {\\n        'lowercut': np.arange(50000, 120000, 1000),\\n    }\\n    \\n    return cut_dict\\ncut_config = getCutDict()\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_name = 'ggHyyd'  # Define signal dataset\n",
    "cut_name = 'basic'\n",
    "\n",
    "\n",
    "def getCutDict(): # same cut as the internal note\n",
    "    cut_dict = {}\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 10000 + 100, 100), # dmet > cut\n",
    "        'uppercut': np.arange(10000, 100000 + 100, 100), # dmet < cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(1, 2 + 0.01, 0.01), # dphi_met_phterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'uppercut': np.arange(0.5, 1, 0.01), # dphi_met_jetterm < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.01, 0.01), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\n",
    "    }\n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "'''    \n",
    "\n",
    "def getCutDict():\n",
    "    cut_dict = {}\n",
    "    # Selection 1: same variables as in the internal note\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 10000 + 100, 100), # dmet > cut\n",
    "        'uppercut': np.arange(10000, 100000 + 100, 100), # -10000 < dmet < cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(1, 2 + 0.01, 0.01), # dphi_met_phterm > cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'uppercut': np.arange(0.5, 1, 0.01), # dphi_met_jetterm < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.01, 0.01), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\n",
    "    }\n",
    "\n",
    "    # Selection 2\n",
    "    cut_dict['balance'] = {\n",
    "        'lowercut': np.arange(0.2, 1.5 + 0.01, 0.01), # balance > cut\n",
    "        'uppercut': np.arange(0.5, 3, 0.01) # balance < cut\n",
    "    }\n",
    "    cut_dict['jetterm'] = {\n",
    "        'lowercut': np.arange(0, 150000+1000, 1000) # jetterm > cut\n",
    "    }\n",
    "    cut_dict['ph_pt'] = {\n",
    "        'lowercut': np.arange(50000, 100000 + 1000, 1000),  # ph_pt > cut\n",
    "        'uppercut': np.arange(100000, 300000 + 1000, 1000),  # ph_pt > cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.05, 0.05), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['metsigres'] = {\n",
    "        'uppercut': np.arange(12000, 60000, 1000)\n",
    "    }\n",
    "    cut_dict['met_noJVT'] = {\n",
    "        'lowercut': np.arange(50000, 120000, 1000),\n",
    "    }\n",
    "    \n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7be48719-8c9e-4e53-93ce-d47b794e63e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cut_var': 'dmet', 'cut_type': 'lowercut', 'best_cut': -19500, 'best_sig_x_acc': 0.755402341557735, 'significance': 0.7634273393744937, 'acceptance': 98.94881969732262}\n",
      "{'cut_var': 'dmet', 'cut_type': 'uppercut', 'best_cut': 41800, 'best_sig_x_acc': 0.7399216787598291, 'significance': 0.7400477423689201, 'acceptance': 99.98296547616137}\n",
      "{'cut_var': 'metsig', 'cut_type': 'lowercut', 'best_cut': 6, 'best_sig_x_acc': 0.9483600743984438, 'significance': 1.0697858263087006, 'acceptance': 88.64952694977866}\n",
      "{'cut_var': 'metsig', 'cut_type': 'uppercut', 'best_cut': 16, 'best_sig_x_acc': 0.7454420718234099, 'significance': 0.7474567476503684, 'acceptance': 99.73046255408201}\n",
      "{'cut_var': 'dphi_met_phterm', 'cut_type': 'lowercut', 'best_cut': 1.1900000000000002, 'best_sig_x_acc': 1.504530954158777, 'significance': 1.6668890800105223, 'acceptance': 90.25981225753064}\n",
      "{'cut_var': 'dphi_met_jetterm', 'cut_type': 'uppercut', 'best_cut': 0.8400000000000003, 'best_sig_x_acc': 0.8906506369209962, 'significance': 0.9111495518398147, 'acceptance': 97.75021401509481}\n",
      "{'cut_var': 'ph_eta', 'cut_type': 'uppercut', 'best_cut': 2.3800000000000012, 'best_sig_x_acc': 0.7394988661638586, 'significance': 0.739498419085689, 'acceptance': 100.00006045694731}\n",
      "{'cut_var': 'dphi_jj', 'cut_type': 'uppercut', 'best_cut': 3.1300000000000017, 'best_sig_x_acc': 0.7399955721158995, 'significance': 0.7404320145858215, 'acceptance': 99.94105569973684}\n",
      "CPU times: user 15min 40s, sys: 14.1 s, total: 15min 55s\n",
      "Wall time: 16min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "signal_name='ggHyyd'\n",
    "initial_cut = []\n",
    "tot2 = tot\n",
    "\n",
    "# < -- Initial Cut on all variables (maximize the significance * acceptance) -- > \n",
    "for cut_var, cut_types in cut_config.items():\n",
    "    for cut_type, cut_values in cut_types.items():\n",
    "        sig_simple_list, sigacc_simple_list, acceptance_values = calculate_significance(\n",
    "            cut_var, cut_type, cut_values, tot2, ntuple_names, signal_name, getVarDict, getWeight\n",
    "        )\n",
    "\n",
    "        best_cut, best_sig, idx = get_best_cut(cut_values, sigacc_simple_list) \n",
    "        \n",
    "        if idx == 0 or idx == len(sigacc_simple_list) - 1: # I chose to use index to indicate not to make unnecessary cut (for initial cut)\n",
    "            print(cut_var, idx, len(sigacc_simple_list))\n",
    "            continue\n",
    "            \n",
    "        result = {\n",
    "            \"cut_var\": cut_var,\n",
    "            \"cut_type\": cut_type,\n",
    "            \"best_cut\": best_cut,\n",
    "            \"best_sig_x_acc\": best_sig,\n",
    "            \"significance\": sig_simple_list[idx],\n",
    "            \"acceptance\": acceptance_values[idx]\n",
    "        }\n",
    "\n",
    "        print(result)\n",
    "        initial_cut.append(dict(list(result.items())[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9fa4546-3a23-4915-a9c6-96e8fd16e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after initial cutting, signficance:  2.271092414179442\n"
     ]
    }
   ],
   "source": [
    "tot2_initial_cut = apply_all_cuts(tot2, ntuple_names, initial_cut, getVarDict)\n",
    "final_significance = compute_total_significance(tot2_initial_cut, ntuple_names, signal_name, getVarDict, getWeight)\n",
    "print('after initial cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4bd9ee6-5854-42d9-bcc5-82f4f08a347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "Updating dmet (lowercut): -19500 → -19400  (N-1 2.237 → with-cut 2.272)\n",
      "Updating dmet (uppercut): 41800 → 41700  (N-1 2.270 → with-cut 2.272)\n",
      "Updating metsig (lowercut): 6 → 7  (N-1 1.808 → with-cut 2.286)\n",
      "Updating metsig (uppercut): 16 → 14  (N-1 2.263 → with-cut 2.289)\n",
      "Updating dphi_met_phterm (lowercut): 1.1900000000000002 → 1.3500000000000003  (N-1 1.401 → with-cut 2.300)\n",
      "Updating dphi_met_jetterm (uppercut): 0.8400000000000003 → 0.7300000000000002  (N-1 2.258 → with-cut 2.315)\n",
      "Updating ph_eta (uppercut): 2.3800000000000012 → 1.7400000000000007  (N-1 2.314 → with-cut 2.529)\n",
      "Updating dphi_jj (uppercut): 3.1300000000000017 → 2.5800000000000014  (N-1 2.528 → with-cut 2.551)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Updating dmet (lowercut): -19400.0 → -17900  (N-1 2.507 → with-cut 2.557)\n",
      "Updating dmet (uppercut): 41700.0 → 41900  (N-1 2.553 → with-cut 2.557)\n",
      "Updating metsig (uppercut): 14.0 → 16  (N-1 2.535 → with-cut 2.557)\n",
      "Updating dphi_met_phterm (lowercut): 1.3500000000000003 → 1.3400000000000003  (N-1 1.481 → with-cut 2.557)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "optimized cuts, end of iteration\n",
      "after optimized cutting, signficance:  2.5573230569311334\n",
      "CPU times: user 17min 26s, sys: 4.72 s, total: 17min 30s\n",
      "Wall time: 17min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def n_minus_1_optimizer(\n",
    "    initial_cut,\n",
    "    cut_config,\n",
    "    tot2,\n",
    "    ntuple_names,\n",
    "    signal_name,\n",
    "    getVarDict,\n",
    "    getWeight,\n",
    "    final_significance,\n",
    "    max_iter=10,\n",
    "    tolerance=1e-4,\n",
    "    allow_drop=True,\n",
    "    drop_tolerance=1e-6\n",
    "):\n",
    "    \"\"\"\n",
    "    allow_drop: if True, remove a cut when N-1 significance beats the best-with-cut significance.\n",
    "    drop_tolerance: minimal margin by which N-1 must exceed best-with-cut to drop the cut.\n",
    "    \"\"\"\n",
    "    best_cuts = [dict(c) for c in initial_cut]  # copy\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < max_iter:\n",
    "        converged = True\n",
    "        to_remove = []\n",
    "\n",
    "        print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "\n",
    "        for i, cut in enumerate(best_cuts):\n",
    "            # Apply all OTHER cuts (N-1)\n",
    "            n_minus_1_cuts = best_cuts[:i] + best_cuts[i+1:]\n",
    "            tot2_cut = apply_all_cuts(tot2, ntuple_names, n_minus_1_cuts, getVarDict)\n",
    "\n",
    "            # Significance WITHOUT this cut\n",
    "            sig_without = compute_total_significance(\n",
    "                tot2_cut, ntuple_names, signal_name, getVarDict, getWeight\n",
    "            )\n",
    "\n",
    "            # Re-scan this variable ON TOP of N-1\n",
    "            cut_var  = cut[\"cut_var\"]\n",
    "            cut_type = cut[\"cut_type\"]\n",
    "            scan_vals = cut_config[cut_var][cut_type]\n",
    "\n",
    "            sig_simple_list, sigacc_simple_list, _ = calculate_significance(\n",
    "                cut_var, cut_type, scan_vals, tot2_cut, ntuple_names,\n",
    "                signal_name, getVarDict, getWeight\n",
    "            )\n",
    "            best_cut_val, best_sig, best_idx = get_best_cut(scan_vals, sig_simple_list)\n",
    "\n",
    "            # Decide to drop or to keep/update\n",
    "            if allow_drop and (sig_without >= best_sig + drop_tolerance):\n",
    "                print(f\"Dropping {cut_var} ({cut_type}): \"\n",
    "                      f\"N-1 {sig_without:.3f} >= best-with-cut {best_sig:.3f}\")\n",
    "                to_remove.append(i)\n",
    "                final_significance = sig_without\n",
    "                converged = False\n",
    "                continue  # move to next cut\n",
    "\n",
    "            # Keep: update threshold if it moved\n",
    "            if abs(best_cut_val - cut[\"best_cut\"]) > tolerance:\n",
    "                print(f\"Updating {cut_var} ({cut_type}): \"\n",
    "                      f\"{cut['best_cut']} → {best_cut_val}  \"\n",
    "                      f\"(N-1 {sig_without:.3f} → with-cut {best_sig:.3f})\")\n",
    "                best_cuts[i][\"best_cut\"] = float(best_cut_val)\n",
    "                final_significance = best_sig\n",
    "                converged = False\n",
    "\n",
    "        # Remove cuts marked for deletion (highest index first)\n",
    "        if to_remove:\n",
    "            for j in sorted(to_remove, reverse=True):\n",
    "                del best_cuts[j]\n",
    "\n",
    "        iteration += 1\n",
    "        if converged:\n",
    "            break\n",
    "\n",
    "    # Recompute final significance with the surviving cuts\n",
    "    tot2_final = apply_all_cuts(tot2, ntuple_names, best_cuts, getVarDict)\n",
    "    final_significance = compute_total_significance(\n",
    "        tot2_final, ntuple_names, signal_name, getVarDict, getWeight\n",
    "    )\n",
    "\n",
    "    print('optimized cuts, end of iteration')\n",
    "    return best_cuts, final_significance\n",
    "\n",
    "# < -- n-1 iterations until no further improvement (max significance) -- >\n",
    "optimized_cuts, final_significance = n_minus_1_optimizer(\n",
    "    initial_cut, cut_config, tot2, ntuple_names, signal_name, getVarDict, getWeight, final_significance\n",
    ")\n",
    "print('after optimized cutting, signficance: ', final_significance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acc19fe8-0dbe-4441-8a77-b03d462bf77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " < -- Final Optimized Cuts -- > \n",
      "dmet > -17900.0\n",
      "dmet < 41900.0\n",
      "metsig > 7.0\n",
      "metsig < 16.0\n",
      "dphi_met_phterm > 1.3400000000000003\n",
      "dphi_met_jetterm < 0.7300000000000002\n",
      "ph_eta < 1.7400000000000007\n",
      "dphi_jj < 2.5800000000000014\n",
      "after optimized cutting, signficance:  2.5573230569311334\n"
     ]
    }
   ],
   "source": [
    "print( ' < -- Final Optimized Cuts -- > ')\n",
    "# print(optimized_cuts)\n",
    "\n",
    "for cut in optimized_cuts:\n",
    "    var = cut['cut_var']\n",
    "    val = cut['best_cut']\n",
    "    if cut['cut_type'] == 'uppercut':\n",
    "        print(f\"{var} < {val}\")\n",
    "    elif cut['cut_type'] == 'lowercut':\n",
    "        print(f\"{var} > {val}\")\n",
    "        \n",
    "print('after optimized cutting, signficance: ', final_significance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "008e0282-8079-4f6b-bf6b-804cab6464a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< -- Sum of weight each process -- >\n",
      "ggHyyd 230.16648730407553\n",
      "Zjets 3.6878033816756215\n",
      "Zgamma 1024.081506402299\n",
      "Wgamma 1984.8735506825312\n",
      "Wjets 2807.3829221127135\n",
      "gammajet_direct 85.19436736218859\n",
      "data23 2195.3119239351918\n"
     ]
    }
   ],
   "source": [
    "tot2_optimized_cuts = apply_all_cuts(tot2, ntuple_names, optimized_cuts, getVarDict)\n",
    "\n",
    "print('< -- Sum of weight each process -- >')\n",
    "\n",
    "for i in range(len(tot2_optimized_cuts)):\n",
    "    print(ntuple_names[i], sum(getWeight(tot2_optimized_cuts[i], ntuple_names[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e72fee-fa82-4d49-91e3-8571f5bcbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# < -- Save data after cuts to a csv file for BDT input -- >\n",
    "Vars = [\n",
    "    'balance', \n",
    "    'VertexBDTScore',\n",
    "    'dmet',\n",
    "    'dphi_jj',\n",
    "    'dphi_met_central_jet',\n",
    "    'dphi_met_phterm',\n",
    "    'dphi_met_ph',\n",
    "    'dphi_met_jetterm',\n",
    "    'dphi_phterm_jetterm',\n",
    "    'dphi_ph_centraljet1',\n",
    "    'ph_pt',\n",
    "    'ph_eta',\n",
    "    'ph_phi',\n",
    "    'jet_central_eta',\n",
    "    'jet_central_pt1',\n",
    "    'jet_central_pt2',\n",
    "    'jetterm',\n",
    "    'jetterm_sumet',\n",
    "    'metsig',\n",
    "    'metsigres',\n",
    "    'met',\n",
    "    'met_noJVT',\n",
    "    'metplusph',\n",
    "    'failJVT_jet_pt1',\n",
    "    'softerm',\n",
    "    'n_jet_central'\n",
    "]\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for j in range(len(ntuple_names)):\n",
    "    process = ntuple_names[j]\n",
    "    fb = tot2_optimized_cuts[j] \n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    for var in Vars:\n",
    "        var_config = getVarDict(fb, process, var_name=var)\n",
    "        data_dict[var] = var_config[var]['var']\n",
    "    \n",
    "    weights = getWeight(fb, process)\n",
    "    data_dict['weights'] = weights\n",
    "    \n",
    "    n_events = len(weights)\n",
    "    data_dict['process'] = [process] * n_events\n",
    "    label = 1 if process == 'ggHyyd' else 0\n",
    "    data_dict['label'] = [label] * n_events\n",
    "    \n",
    "    df_temp = pd.DataFrame(data_dict)\n",
    "    data_list.append(df_temp)\n",
    "\n",
    "df_all = pd.concat(data_list, ignore_index=True)\n",
    "df_all.head()\n",
    "\n",
    "df_all.to_csv(\"/data/jlai/ntups/csv/jet_faking_BDT_input_basic_reduced2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f42931-67d4-4780-8e78-ac44994bafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot2 = tot\n",
    "cut_name = 'basic'\n",
    "var_config = getVarDict(tot2[0], 'ggHyyd')\n",
    "\n",
    "\n",
    "for var in var_config:\n",
    "    # print(var)\n",
    "    bg_values = []     \n",
    "    bg_weights = []    \n",
    "    bg_colors = []     \n",
    "    bg_labels = []     \n",
    "\n",
    "    signal_values = [] \n",
    "    signal_weights = []\n",
    "    signal_color = None \n",
    "    signal_label = None\n",
    "\n",
    "    for j in range(len(ntuple_names)):\n",
    "    # for j in range(len(ntuple_names)-1): # leave dijet out\n",
    "        process = ntuple_names[j]\n",
    "        fb = tot2[j]  # TTree\n",
    "        var_config = getVarDict(fb, process, var_name=var)\n",
    "\n",
    "        x = var_config[var]['var'] # TBranch\n",
    "        bins = var_config[var]['bins'] \n",
    "\n",
    "        if 'weight' in var_config[var]:  # If weight is there\n",
    "            weights = var_config[var]['weight']\n",
    "        else:\n",
    "            weights = getWeight(fb, process)\n",
    "        \n",
    "        sample_info = sample_dict[process]\n",
    "        color = sample_info['color']\n",
    "        legend = sample_info['legend']\n",
    "\n",
    "        \n",
    "        if process == 'ggHyyd':  # signal\n",
    "            signal_values.append(x)\n",
    "            signal_weights.append(weights)\n",
    "            signal_color = color\n",
    "            signal_label = legend\n",
    "        else:   # background\n",
    "            bg_values.append(x)\n",
    "            bg_weights.append(weights)\n",
    "            bg_colors.append(color)\n",
    "            bg_labels.append(legend)\n",
    "\n",
    "    fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(12, 13), gridspec_kw={'height_ratios': [9, 4]})\n",
    "\n",
    "    ax_top.hist(bg_values, bins=bins, weights=bg_weights, color=bg_colors,\n",
    "                label=bg_labels, stacked=True)\n",
    "\n",
    "    ax_top.hist(signal_values, bins=bins, weights=signal_weights, color=signal_color,\n",
    "                label=signal_label, histtype='step', linewidth=2)\n",
    "\n",
    "    signal_all = np.concatenate(signal_values) if len(signal_values) > 0 else np.array([])\n",
    "    signal_weights_all = np.concatenate(signal_weights) if len(signal_weights) > 0 else np.array([])\n",
    "\n",
    "    # Add error bar for signal (top plot)\n",
    "    if len(signal_all) > 0:\n",
    "        signal_counts, bin_edges = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "        sum_weights_sq, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all**2)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        signal_errors = np.sqrt(sum_weights_sq)  # Poisson error sqrt(N)\n",
    "\n",
    "        ax_top.errorbar(bin_centers, signal_counts, yerr=signal_errors, fmt='.', linewidth=2,\n",
    "                        color=signal_color, capsize=0)\n",
    "\n",
    "    ax_top.set_yscale('log')\n",
    "    ax_top.set_ylim(0.0001, 1e11)\n",
    "    ax_top.set_xlim(bins[0], bins[-1])\n",
    "    ax_top.minorticks_on()\n",
    "    ax_top.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "    ax_top.set_ylabel(\"Events\")\n",
    "    ax_top.legend(ncol=2)\n",
    "    # ax_top.set_title(\"vtx_sumPt distribution\")\n",
    "\n",
    "    bg_all = np.concatenate(bg_values) if len(bg_values) > 0 else np.array([])\n",
    "    bg_weights_all = np.concatenate(bg_weights) if len(bg_weights) > 0 else np.array([])\n",
    "\n",
    "    # Compute the weighted histogram counts using np.histogram\n",
    "    S_counts, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "    B_counts, _ = np.histogram(bg_all, bins=bins, weights=bg_weights_all)     \n",
    "\n",
    "    # Compute per-bin significance\n",
    "    sig_simple = np.zeros_like(S_counts, dtype=float)\n",
    "    sig_s_plus_b = np.zeros_like(S_counts, dtype=float)\n",
    "    sig_s_plus_1p3b = np.zeros_like(S_counts, dtype=float)\n",
    "\n",
    "    sqrt_B = np.sqrt(B_counts)\n",
    "    sqrt_SplusB = np.sqrt(S_counts + B_counts)\n",
    "    sqrt_Splus1p3B = np.sqrt(S_counts + 1.3 * B_counts)\n",
    "\n",
    "    # Avoid division by zero safely\n",
    "    sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0)\n",
    "    sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0)\n",
    "    sig_s_plus_1p3b = np.where((S_counts + 1.3 * B_counts) > 0, S_counts / sqrt_Splus1p3B, 0)\n",
    "\n",
    "    # Add Binomial ExpZ per bin\n",
    "    zbi_per_bin = np.array([\n",
    "        zbi(S_counts[i], B_counts[i], sigma_b_frac=0.3)\n",
    "        for i in range(len(S_counts))\n",
    "    ])\n",
    "\n",
    "    # Compute the bin centers for plotting\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "    # Compute the total significance: total S / sqrt(total B)\n",
    "    total_signal = np.sum(S_counts)\n",
    "    total_bkg = np.sum(B_counts)\n",
    "\n",
    "    if total_bkg > 0:\n",
    "        total_sig_simple = total_signal / np.sqrt(total_bkg)\n",
    "        total_sig_s_plus_b = total_signal / np.sqrt(total_signal + total_bkg)\n",
    "        total_sig_s_plus_1p3b = total_signal / np.sqrt(total_signal + 1.3 * total_bkg)\n",
    "        total_sig_binomial = zbi(total_signal, total_bkg, sigma_b_frac=0.3)\n",
    "    else:\n",
    "        total_sig_simple = total_sig_s_plus_b = total_sig_s_plus_1p3b = total_sig_binomial = 0\n",
    "\n",
    "    # --- Plot all significance curves ---\n",
    "    ax_bot.step(bin_centers, sig_simple, where='mid', color='chocolate', linewidth=2,\n",
    "                label=f\"S/√B = {total_sig_simple:.4f}\")\n",
    "    ax_bot.step(bin_centers, sig_s_plus_b, where='mid', color='tomato', linewidth=2,\n",
    "                label=f\"S/√(S+B) = {total_sig_s_plus_b:.4f}\")\n",
    "    ax_bot.step(bin_centers, sig_s_plus_1p3b, where='mid', color='orange', linewidth=2,\n",
    "                label=f\"S/√(S+1.3B) = {total_sig_s_plus_1p3b:.4f}\")\n",
    "    ax_bot.step(bin_centers, zbi_per_bin, where='mid', color='plum', linewidth=2,\n",
    "                label=f\"Binomial ExpZ = {total_sig_binomial:.4f}\")\n",
    "\n",
    "    ax_bot.set_xlabel(var_config[var]['title'])\n",
    "    # ax_bot.set_xticks(np.linspace(bins[0], bins[-1], 11))\n",
    "    ax_bot.set_ylabel(\"Significance\")\n",
    "    ax_bot.set_ylim(-0.8, 2)\n",
    "    ax_top.set_xlim(bins[0], bins[-1])\n",
    "\n",
    "    # Do not set a title on the bottom plot.\n",
    "    ax_bot.set_title(\"\")\n",
    "\n",
    "    # Draw a legend with purple text.\n",
    "    leg = ax_bot.legend()\n",
    "    for text in leg.get_texts():\n",
    "        text.set_color('purple')\n",
    "\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "    plt.tight_layout()\n",
    "    print(f\"{var}_nodijet.png\")\n",
    "    print(f\"roc_curve_{var}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c7f3179-ac24-4b32-8ec2-2d32b2dcd3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/vtx_sumPt_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_vtx_sumPt.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/n_ph_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_n_ph.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/n_ph_baseline_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_n_ph_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/n_el_baseline_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_n_el_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/n_mu_baseline_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_n_mu_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/n_tau_baseline_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_n_tau_baseline.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/mt_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_mt.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/metsig_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_metsig.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/metsigres_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_metsigres.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/met_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_met.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/met_noJVT_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_met_noJVT.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/met_cst_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_met_cst.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/met_track_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_met_track.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/dmet_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_dmet.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/ph_pt_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_ph_pt.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/ph_eta_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_ph_eta.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/ph_phi_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_ph_phi.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/jet_central_eta_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_jet_central_eta.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/jet_central_pt1_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_jet_central_pt1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/jet_central_pt2_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_jet_central_pt2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/jet_central_pt_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_jet_central_pt.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/dphi_met_phterm_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_dphi_met_phterm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/dphi_met_ph_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_dphi_met_ph.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/dphi_met_jetterm_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_dphi_met_jetterm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/dphi_phterm_jetterm_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_dphi_phterm_jetterm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/dphi_ph_centraljet1_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_dphi_ph_centraljet1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/dphi_ph_jet1_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_dphi_ph_jet1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/metplusph_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_metplusph.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/failJVT_jet_pt_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_failJVT_jet_pt.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/failJVT_jet_pt1_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_failJVT_jet_pt1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/softerm_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_softerm.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/jetterm_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_jetterm.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/jetterm_sumet_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_jetterm_sumet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/n_jet_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_n_jet.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/n_jet_central_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_n_jet_central.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/n_jet_fwd_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_n_jet_fwd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/dphi_met_central_jet_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_dphi_met_central_jet.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n",
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/jet_central_timing1_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_jet_central_timing1.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/jet_central_timing_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_jet_central_timing.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/jet_central_emfrac_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_jet_central_emfrac.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/balance_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_balance.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n",
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/balance_sumet_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_balance_sumet.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/central_jets_fraction_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_central_jets_fraction.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/trigger_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_trigger.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/dphi_jj_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_dphi_jj.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.8/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/VertexBDTScore_nodijet.png\n",
      "successfully saved to /data/jlai/dark_photon/jets_faking_photons3/basic_80/roc_curve_VertexBDTScore.png\n"
     ]
    }
   ],
   "source": [
    "# tot2 = tot2_optimized_cuts\n",
    "tot2 = tot\n",
    "cut_name = 'basic'\n",
    "var_config = getVarDict(tot2[0], 'ggHyyd')\n",
    "\n",
    "\n",
    "for var in var_config:\n",
    "    # print(var)\n",
    "    bg_values = []     \n",
    "    bg_weights = []    \n",
    "    bg_colors = []     \n",
    "    bg_labels = []     \n",
    "\n",
    "    signal_values = [] \n",
    "    signal_weights = []\n",
    "    signal_color = None \n",
    "    signal_label = None\n",
    "\n",
    "    for j in range(len(ntuple_names)):\n",
    "    # for j in range(len(ntuple_names)-1): # leave dijet out\n",
    "        process = ntuple_names[j]\n",
    "        fb = tot2[j]  # TTree\n",
    "        var_config = getVarDict(fb, process, var_name=var)\n",
    "\n",
    "        x = var_config[var]['var'] # TBranch\n",
    "        bins = var_config[var]['bins'] \n",
    "\n",
    "        if 'weight' in var_config[var]:  # If weight is there\n",
    "            weights = var_config[var]['weight']\n",
    "        else:\n",
    "            weights = getWeight(fb, process)\n",
    "        \n",
    "        sample_info = sample_dict[process]\n",
    "        color = sample_info['color']\n",
    "        legend = sample_info['legend']\n",
    "\n",
    "        \n",
    "        if process == 'ggHyyd':  # signal\n",
    "            signal_values.append(x)\n",
    "            signal_weights.append(weights)\n",
    "            signal_color = color\n",
    "            signal_label = legend\n",
    "        else:   # background\n",
    "            bg_values.append(x)\n",
    "            bg_weights.append(weights)\n",
    "            bg_colors.append(color)\n",
    "            bg_labels.append(legend)\n",
    "\n",
    "    fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(12, 13), gridspec_kw={'height_ratios': [9, 4]})\n",
    "\n",
    "    ax_top.hist(bg_values, bins=bins, weights=bg_weights, color=bg_colors,\n",
    "                label=bg_labels, stacked=True)\n",
    "\n",
    "    ax_top.hist(signal_values, bins=bins, weights=signal_weights, color=signal_color,\n",
    "                label=signal_label, histtype='step', linewidth=2)\n",
    "\n",
    "    signal_all = np.concatenate(signal_values) if len(signal_values) > 0 else np.array([])\n",
    "    signal_weights_all = np.concatenate(signal_weights) if len(signal_weights) > 0 else np.array([])\n",
    "\n",
    "    # Add error bar for signal (top plot)\n",
    "    if len(signal_all) > 0:\n",
    "        signal_counts, bin_edges = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "        sum_weights_sq, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all**2)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        signal_errors = np.sqrt(sum_weights_sq)  # Poisson error sqrt(N)\n",
    "\n",
    "        ax_top.errorbar(bin_centers, signal_counts, yerr=signal_errors, fmt='.', linewidth=2,\n",
    "                        color=signal_color, capsize=0)\n",
    "\n",
    "    ax_top.set_yscale('log')\n",
    "    ax_top.set_ylim(0.0001, 1e11)\n",
    "    ax_top.set_xlim(bins[0], bins[-1])\n",
    "    ax_top.minorticks_on()\n",
    "    ax_top.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "    ax_top.set_ylabel(\"Events\")\n",
    "    ax_top.legend(ncol=2)\n",
    "    # ax_top.set_title(\"vtx_sumPt distribution\")\n",
    "\n",
    "    bg_all = np.concatenate(bg_values) if len(bg_values) > 0 else np.array([])\n",
    "    bg_weights_all = np.concatenate(bg_weights) if len(bg_weights) > 0 else np.array([])\n",
    "\n",
    "    # Compute the weighted histogram counts using np.histogram\n",
    "    S_counts, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "    B_counts, _ = np.histogram(bg_all, bins=bins, weights=bg_weights_all)     \n",
    "\n",
    "    # Compute per-bin significance\n",
    "    sig_simple = np.zeros_like(S_counts, dtype=float)\n",
    "    sig_s_plus_b = np.zeros_like(S_counts, dtype=float)\n",
    "    sig_s_plus_1p3b = np.zeros_like(S_counts, dtype=float)\n",
    "\n",
    "    sqrt_B = np.sqrt(B_counts)\n",
    "    sqrt_SplusB = np.sqrt(S_counts + B_counts)\n",
    "    sqrt_Splus1p3B = np.sqrt(S_counts + 1.3 * B_counts)\n",
    "\n",
    "    # Avoid division by zero safely\n",
    "    sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0)\n",
    "    sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0)\n",
    "    sig_s_plus_1p3b = np.where((S_counts + 1.3 * B_counts) > 0, S_counts / sqrt_Splus1p3B, 0)\n",
    "\n",
    "    # Add Binomial ExpZ per bin\n",
    "    zbi_per_bin = np.array([\n",
    "        zbi(S_counts[i], B_counts[i], sigma_b_frac=0.3)\n",
    "        for i in range(len(S_counts))\n",
    "    ])\n",
    "\n",
    "    # Compute the bin centers for plotting\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "    # Compute the total significance: total S / sqrt(total B)\n",
    "    total_signal = np.sum(S_counts)\n",
    "    total_bkg = np.sum(B_counts)\n",
    "\n",
    "    if total_bkg > 0:\n",
    "        total_sig_simple = total_signal / np.sqrt(total_bkg)\n",
    "        total_sig_s_plus_b = total_signal / np.sqrt(total_signal + total_bkg)\n",
    "        total_sig_s_plus_1p3b = total_signal / np.sqrt(total_signal + 1.3 * total_bkg)\n",
    "        total_sig_binomial = zbi(total_signal, total_bkg, sigma_b_frac=0.3)\n",
    "    else:\n",
    "        total_sig_simple = total_sig_s_plus_b = total_sig_s_plus_1p3b = total_sig_binomial = 0\n",
    "\n",
    "    # --- Plot all significance curves ---\n",
    "    ax_bot.step(bin_centers, sig_simple, where='mid', color='chocolate', linewidth=2,\n",
    "                label=f\"S/√B = {total_sig_simple:.4f}\")\n",
    "    ax_bot.step(bin_centers, sig_s_plus_b, where='mid', color='tomato', linewidth=2,\n",
    "                label=f\"S/√(S+B) = {total_sig_s_plus_b:.4f}\")\n",
    "    ax_bot.step(bin_centers, sig_s_plus_1p3b, where='mid', color='orange', linewidth=2,\n",
    "                label=f\"S/√(S+1.3B) = {total_sig_s_plus_1p3b:.4f}\")\n",
    "    ax_bot.step(bin_centers, zbi_per_bin, where='mid', color='plum', linewidth=2,\n",
    "                label=f\"Binomial ExpZ = {total_sig_binomial:.4f}\")\n",
    "\n",
    "    ax_bot.set_xlabel(var_config[var]['title'])\n",
    "    # ax_bot.set_xticks(np.linspace(bins[0], bins[-1], 11))\n",
    "    ax_bot.set_ylabel(\"Significance\")\n",
    "    ax_bot.set_ylim(-0.8, 2)\n",
    "    ax_top.set_xlim(bins[0], bins[-1])\n",
    "\n",
    "    # Do not set a title on the bottom plot.\n",
    "    ax_bot.set_title(\"\")\n",
    "\n",
    "    # Draw a legend with purple text.\n",
    "    leg = ax_bot.legend()\n",
    "    for text in leg.get_texts():\n",
    "        text.set_color('purple')\n",
    "\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/data/jlai/dark_photon/jets_faking_photons3/{cut_name}_80/{var}_nodijet.png\")\n",
    "    print(f\"successfully saved to /data/jlai/dark_photon/jets_faking_photons3/{cut_name}_80/{var}_nodijet.png\")\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "\n",
    "    y_true = np.concatenate([np.ones_like(signal_all), np.zeros_like(bg_all)])\n",
    "    # Use the vtx_sumPt values as the classifier output.\n",
    "    y_scores = np.concatenate([signal_all, bg_all])\n",
    "    # Combine the weights for all events.\n",
    "    y_weights = np.concatenate([signal_weights_all, bg_weights_all])\n",
    "\n",
    "    # Compute the weighted ROC curve.\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores, sample_weight=y_weights)\n",
    "    sorted_indices = np.argsort(fpr)\n",
    "    fpr_sorted = fpr[sorted_indices]\n",
    "    tpr_sorted = tpr[sorted_indices]\n",
    "\n",
    "    roc_auc = auc(fpr_sorted, tpr_sorted)\n",
    "\n",
    "    # Create a new figure for the ROC curve.\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, lw=2, color='red', label=f'ROC curve (AUC = {roc_auc:.5f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random chance')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve for {var}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.tight_layout()    \n",
    "    plt.savefig(f\"/data/jlai/dark_photon/jets_faking_photons3/{cut_name}_80/roc_curve_{var}.png\")\n",
    "    print(f\"successfully saved to /data/jlai/dark_photon/jets_faking_photons3/{cut_name}_80/roc_curve_{var}.png\")\n",
    "    plt.close()\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161528d-8722-484c-8df6-6682f2ab1d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
