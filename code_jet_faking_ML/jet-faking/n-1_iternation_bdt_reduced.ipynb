{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68b353b7-b507-4881-9f15-bc69b0de3806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[csv_to_tot] Rows per process:\n",
      "  ggHyyd           n=  1938  sum_w=198.869\n",
      "  Zjets            n=    22  sum_w=1.79321\n",
      "  Zgamma           n= 10698  sum_w=620.066\n",
      "  Wgamma           n=  7113  sum_w=1229.33\n",
      "  Wjets            n=  2356  sum_w=1043.09\n",
      "  gammajet_direct  n=   506  sum_w=24.4602\n",
      "  data23           n=    10  sum_w=104.259\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math, pickle, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "\n",
    "# import config functions\n",
    "from jet_faking_plot_config import getWeight, zbi, sample_dict, getVarDict\n",
    "from plot_var import variables, variables_data, ntuple_names, ntuple_names_BDT\n",
    "from n_1_iteration_functions import get_best_cut, calculate_significance, apply_cut_to_fb, apply_all_cuts, compute_total_significance, n_minus_1_optimizer\n",
    "# from cut_config import cut_config\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high  \n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"]  # Legend\n",
    "})\n",
    "\n",
    "tot = []\n",
    "ntuple_names = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct', 'data23']\n",
    "\n",
    "def csv_to_tot(csv_path, ntuple_names=ntuple_names, process_col='process'):\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[df.MLBDTScore >= 0.03]\n",
    "    df['weights'] = np.abs(df['weights'])\n",
    "\n",
    "    all_cols = [c for c in df.columns if c != process_col]\n",
    "\n",
    "    # Build tot: one ak.Array per process, in the given order\n",
    "    tot = []\n",
    "    for proc in ntuple_names:\n",
    "        sub = df[df[process_col] == proc]\n",
    "        # Awkward record array with consistent fields (even if empty)\n",
    "        fb = ak.Array({col: sub[col].to_numpy() for col in all_cols})\n",
    "        tot.append(fb)\n",
    "\n",
    "    # Optional: quick summary printout\n",
    "    print(\"[csv_to_tot] Rows per process:\")\n",
    "    for proc, fb in zip(ntuple_names, tot):\n",
    "        n = len(fb)  # same as ak.num(fb['weights']) if present\n",
    "        wsum = float(np.sum(fb['weights'])) if n > 0 else 0.0\n",
    "        print(f\"  {proc:15s}  n={n:6d}  sum_w={wsum:.6g}\")\n",
    "\n",
    "    return tot\n",
    "\n",
    "# ---- usage ----\n",
    "csv_path = \"/data/jlai/ntups/csv/bdt_output_reduced.csv\"\n",
    "tot = csv_to_tot(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c56a867-2cb8-4eba-ad46-5ac101d46b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCutDict():\n",
    "    cut_dict = {}\n",
    "\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.14 + 0.01, 0.01) # dphi_jj < cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.05, 0.05), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['jet_central_eta'] = {\n",
    "        'lowercut': np.arange(-2.5, 0+0.01, 0.01), # jet_central_eta > cut\n",
    "        'uppercut': np.arange(0, 2.5+0.01, 0.01) # jet_central_eta < cut\n",
    "    }\n",
    "    cut_dict['jet_central_pt2'] = {\n",
    "        'lowercut': np.arange(20000, 100000+1000, 1000) # jet_central_pt2 > cut\n",
    "    }\n",
    "    cut_dict['metsigres'] = {\n",
    "        'lowercut': np.arange(8600, 15000, 100),\n",
    "        'uppercut': np.arange(12000, 60000, 100)\n",
    "    }\n",
    "    cut_dict['met_noJVT'] = {\n",
    "        'lowercut': np.arange(50000, 120000, 100),\n",
    "        'uppercut': np.arange(100000, 250000, 100)\n",
    "    }\n",
    "    cut_dict['softerm'] = {\n",
    "        'uppercut': np.arange(10000, 40000, 100)\n",
    "    }\n",
    "    cut_dict['n_jet_central'] = {\n",
    "        'uppercut': np.arange(0, 8+1, 1) # njet < cut\n",
    "    }\n",
    "\n",
    "    return cut_dict\n",
    "cut_config = getCutDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f94b1f7-956b-4674-aa07-5d17e942e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_significance(cut_var, cut_type, cut_values, tot2, ntuple_names, signal_name, getVarDict, getWeight):\n",
    "    sig_simple_list = []\n",
    "    sigacc_simple_list = []\n",
    "    acceptance_values = []\n",
    "\n",
    "    for cut in cut_values:\n",
    "        sig_after_cut = 0\n",
    "        bkg_after_cut = []\n",
    "        sig_events = 0\n",
    "\n",
    "        for i in range(len(ntuple_names)):\n",
    "            process = ntuple_names[i]\n",
    "            x = tot2[i][cut_var]\n",
    "            mask = x != -999\n",
    "            x = x[mask]\n",
    "\n",
    "            if process == signal_name:\n",
    "                sig_events = tot2[i]['weights']\n",
    "                sig_events = sig_events[mask]\n",
    "                mask = x >= cut if cut_type == 'lowercut' else x <= cut\n",
    "                sig_after_cut = ak.sum(sig_events[mask])\n",
    "            else:\n",
    "                bkg_events = tot2[i]['weights']\n",
    "                bkg_events = bkg_events[mask]\n",
    "                mask = x >= cut if cut_type == 'lowercut' else x <= cut\n",
    "                bkg_after_cut.append(ak.sum(bkg_events[mask]))\n",
    "\n",
    "\n",
    "        total_bkg = sum(bkg_after_cut)\n",
    "        total_signal = sig_after_cut\n",
    "\n",
    "        sig_simple = total_signal / np.sqrt(total_bkg) if total_bkg > 0 else 0\n",
    "        acceptance = total_signal / sum(sig_events) if sum(sig_events) > 0 else 0\n",
    "\n",
    "        sig_simple_list.append(sig_simple)\n",
    "        sigacc_simple_list.append(sig_simple * acceptance)\n",
    "        acceptance_values.append(acceptance * 100)\n",
    "\n",
    "    return sig_simple_list, sigacc_simple_list, acceptance_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7be48719-8c9e-4e53-93ce-d47b794e63e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dphi_jj 214 215\n",
      "{'cut_var': 'dphi_phterm_jetterm', 'cut_type': 'lowercut', 'best_cut': 1.4500000000000004, 'best_sig_x_acc': 3.619275247678468, 'significance': 3.619275247678468, 'acceptance': 100.0}\n",
      "{'cut_var': 'dphi_phterm_jetterm', 'cut_type': 'uppercut', 'best_cut': 3.100000000000001, 'best_sig_x_acc': 3.6170973308859207, 'significance': 3.6170973308859207, 'acceptance': 100.0}\n",
      "{'cut_var': 'jet_central_eta', 'cut_type': 'lowercut', 'best_cut': -2.450000000000001, 'best_sig_x_acc': 3.6203402689685253, 'significance': 3.6203412907869934, 'acceptance': 99.99997177563147}\n",
      "jet_central_eta 250 251\n",
      "jet_central_pt2 0 81\n",
      "{'cut_var': 'metsigres', 'cut_type': 'lowercut', 'best_cut': 9900, 'best_sig_x_acc': 3.617082689663944, 'significance': 3.617082689663944, 'acceptance': 100.0}\n",
      "{'cut_var': 'metsigres', 'cut_type': 'uppercut', 'best_cut': 35100, 'best_sig_x_acc': 3.6235521247548155, 'significance': 3.624906210248336, 'acceptance': 99.96264495093163}\n",
      "met_noJVT 0 700\n",
      "{'cut_var': 'met_noJVT', 'cut_type': 'uppercut', 'best_cut': 248600, 'best_sig_x_acc': 3.3773700849432546, 'significance': 3.541564082129982, 'acceptance': 95.36379990933335}\n",
      "softerm 299 300\n",
      "{'cut_var': 'n_jet_central', 'cut_type': 'uppercut', 'best_cut': 4, 'best_sig_x_acc': 3.6169944293441754, 'significance': 3.6169944293441754, 'acceptance': 100.0}\n",
      "CPU times: user 1min 18s, sys: 37.4 ms, total: 1min 18s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "signal_name='ggHyyd'\n",
    "initial_cut = []\n",
    "tot2 = tot\n",
    "\n",
    "# < -- Initial Cut on all variables (maximize the significance * acceptance) -- > \n",
    "for cut_var, cut_types in cut_config.items():\n",
    "    for cut_type, cut_values in cut_types.items():\n",
    "        sig_simple_list, sigacc_simple_list, acceptance_values = calculate_significance(\n",
    "            cut_var, cut_type, cut_values, tot2, ntuple_names, signal_name, getVarDict, getWeight\n",
    "        )\n",
    "\n",
    "        best_cut, best_sig, idx = get_best_cut(cut_values, sigacc_simple_list) \n",
    "        \n",
    "        if idx == 0 or idx == len(sigacc_simple_list) - 1: # I chose to use index to indicate not to make unnecessary cut (for initial cut)\n",
    "            print(cut_var, idx, len(sigacc_simple_list))\n",
    "            continue\n",
    "            \n",
    "        result = {\n",
    "            \"cut_var\": cut_var,\n",
    "            \"cut_type\": cut_type,\n",
    "            \"best_cut\": best_cut,\n",
    "            \"best_sig_x_acc\": best_sig,\n",
    "            \"significance\": sig_simple_list[idx],\n",
    "            \"acceptance\": acceptance_values[idx]\n",
    "        }\n",
    "\n",
    "        print(result)\n",
    "        initial_cut.append(dict(list(result.items())[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df9e9d4f-7a40-4db9-a65c-097a7e492910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cut_to_fb(fb, process, var, cut_val, cut_type, getVarDict):\n",
    "    x = fb[var]\n",
    "    mask = x != -999\n",
    "\n",
    "    if cut_type == 'lowercut':\n",
    "        mask = mask & (x >= cut_val)\n",
    "    elif cut_type == 'uppercut':\n",
    "        mask = mask & (x <= cut_val)\n",
    "    return fb[mask]\n",
    "\n",
    "\n",
    "def apply_all_cuts(tot2, ntuple_names, cut_list, getVarDict):\n",
    "    new_tot2 = []\n",
    "    for i, fb in enumerate(tot2):\n",
    "        process = ntuple_names[i]\n",
    "        for cut in cut_list:\n",
    "            fb = apply_cut_to_fb(fb, process, cut[\"cut_var\"], cut[\"best_cut\"], cut[\"cut_type\"], getVarDict)\n",
    "        new_tot2.append(fb)\n",
    "    return new_tot2\n",
    "\n",
    "def compute_total_significance(tot2, ntuple_names, signal_name, getVarDict, getWeight):\n",
    "    signal_sum = 0\n",
    "    bkg_sum = 0\n",
    "    for i in range(len(ntuple_names)):\n",
    "        fb = tot2[i]\n",
    "        print(fb)\n",
    "        process = ntuple_names[i]\n",
    "        weights = fb['weights']\n",
    "        if process == signal_name:\n",
    "            signal_sum += ak.sum(weights)\n",
    "        else:\n",
    "            bkg_sum += ak.sum(weights)\n",
    "    return signal_sum / np.sqrt(bkg_sum) if bkg_sum > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cb97504-71df-41e5-b776-09d0ce3ac10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{balance: 1.78, VertexBDTScore: 0.151, dmet: 0, dphi_jj: -999, ...}, ...]\n",
      "[{balance: 1.26, VertexBDTScore: 0.177, dmet: 0, dphi_jj: 1.51, ...}, ...]\n",
      "[{balance: 7.23, VertexBDTScore: 0.013, dmet: 0, dphi_jj: -999, ...}, ...]\n",
      "[{balance: 1.35, VertexBDTScore: 0.301, dmet: 0, dphi_jj: 0.441, ...}, ...]\n",
      "[{balance: 1.28, VertexBDTScore: 0.288, dmet: 0, dphi_jj: -999, ...}, ...]\n",
      "[{balance: 1.15, VertexBDTScore: 0.301, dmet: 1.4e+03, dphi_jj: 1.12, ...}, ...]\n",
      "[{balance: 1.18, VertexBDTScore: 0.145, dmet: 0, dphi_jj: 0.468, ...}, ...]\n",
      "after initial cutting, signficance:  3.5483105323660187\n"
     ]
    }
   ],
   "source": [
    "tot2_initial_cut = apply_all_cuts(tot2, ntuple_names, initial_cut, getVarDict)\n",
    "final_significance = compute_total_significance(tot2_initial_cut, ntuple_names, signal_name, getVarDict, getWeight)\n",
    "print('after initial cutting, signficance: ', final_significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4bd9ee6-5854-42d9-bcc5-82f4f08a347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "Updating metsigres (uppercut): 35100 → 33600  (sig 3.55 → 3.55)\n",
      "Updating met_noJVT (uppercut): 248600 → 242400  (sig 3.55 → 3.55)\n",
      "\n",
      "--- Iteration 2 ---\n",
      " optimized cuts, end of iteration \n",
      "after optimized cutting, signficance:  3.548829904381028\n",
      "CPU times: user 2min 51s, sys: 1.94 s, total: 2min 53s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def n_minus_1_optimizer(initial_cut, cut_config, tot2, ntuple_names, signal_name, getVarDict, getWeight, final_significance, max_iter=10, tolerance=1e-4):\n",
    "    best_cuts = initial_cut.copy()\n",
    "    iteration = 0\n",
    "    converged = False\n",
    "\n",
    "    while not converged and iteration < max_iter:\n",
    "        converged = True\n",
    "        print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "        for i, cut in enumerate(best_cuts):\n",
    "            # Apply all other cuts\n",
    "            n_minus_1_cuts = best_cuts[:i] + best_cuts[i+1:]\n",
    "            tot2_cut = apply_all_cuts(tot2, ntuple_names, n_minus_1_cuts, getVarDict)\n",
    "\n",
    "            # Re-scan this variable\n",
    "            cut_var = cut[\"cut_var\"]\n",
    "            cut_type = cut[\"cut_type\"]\n",
    "            cut_values = cut_config[cut_var][cut_type]\n",
    "\n",
    "            sig_simple_list, sigacc_simple_list, _ = calculate_significance(\n",
    "                cut_var, cut_type, cut_values, tot2_cut, ntuple_names\n",
    "                , signal_name, getVarDict, getWeight\n",
    "            )\n",
    "            best_cut, best_sig, idx = get_best_cut(cut_values, sig_simple_list)\n",
    "\n",
    "            if abs(best_cut - cut[\"best_cut\"]) > tolerance:\n",
    "            # if best_sig - final_significance > tolerance:\n",
    "                print(f\"Updating {cut_var} ({cut_type}): {cut['best_cut']} → {best_cut}  (sig {final_significance:.2f} → {best_sig:.2f})\")\n",
    "                best_cuts[i][\"best_cut\"] = best_cut\n",
    "                final_significance = best_sig\n",
    "                converged = False  # Found at least one improvement\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    print( ' optimized cuts, end of iteration ' )\n",
    "    return best_cuts, final_significance\n",
    "    \n",
    "# < -- n-1 iterations until no further improvement (max significance) -- >\n",
    "optimized_cuts, final_significance = n_minus_1_optimizer(\n",
    "    initial_cut, cut_config, tot2, ntuple_names, signal_name, getVarDict, getWeight, final_significance\n",
    ")\n",
    "print('after optimized cutting, signficance: ', final_significance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acc19fe8-0dbe-4441-8a77-b03d462bf77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " < -- Final Optimized Cuts -- > \n",
      "dphi_phterm_jetterm >= 1.4500000000000004\n",
      "dphi_phterm_jetterm <= 3.100000000000001\n",
      "jet_central_eta >= -2.450000000000001\n",
      "metsigres >= 9900\n",
      "metsigres <= 33600\n",
      "met_noJVT <= 242400\n",
      "n_jet_central <= 4\n",
      "after optimized cutting, signficance:  3.548829904381028\n"
     ]
    }
   ],
   "source": [
    "print( ' < -- Final Optimized Cuts -- > ')\n",
    "# print(optimized_cuts)\n",
    "\n",
    "for cut in optimized_cuts:\n",
    "    var = cut['cut_var']\n",
    "    val = cut['best_cut']\n",
    "    if cut['cut_type'] == 'uppercut':\n",
    "        print(f\"{var} <= {val}\")\n",
    "    elif cut['cut_type'] == 'lowercut':\n",
    "        print(f\"{var} >= {val}\")\n",
    "        \n",
    "print('after optimized cutting, signficance: ', final_significance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0608ca9-e414-4aa7-9718-bb6a17c402ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot2_optimized_cuts = apply_all_cuts(tot2, ntuple_names, optimized_cuts, getVarDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99a8599f-1d93-45a4-8ab7-ed36bf5a4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# < -- Save data after cuts to a csv file for BDT input -- >\n",
    "Vars = [\n",
    "    'balance', \n",
    "    'VertexBDTScore',\n",
    "    'dmet',\n",
    "    'dphi_jj',\n",
    "    'dphi_met_central_jet',\n",
    "    'dphi_met_phterm',\n",
    "    'dphi_met_ph',\n",
    "    'dphi_met_jetterm',\n",
    "    'dphi_phterm_jetterm',\n",
    "    'dphi_ph_centraljet1',\n",
    "    'ph_pt',\n",
    "    'ph_eta',\n",
    "    'ph_phi',\n",
    "    'jet_central_eta',\n",
    "    'jet_central_pt1',\n",
    "    'jet_central_pt2',\n",
    "    'jetterm',\n",
    "    'jetterm_sumet',\n",
    "    'metsig',\n",
    "    'metsigres',\n",
    "    'met',\n",
    "    'met_noJVT',\n",
    "    'metplusph',\n",
    "    'failJVT_jet_pt1',\n",
    "    'softerm',\n",
    "    'n_jet_central'\n",
    "]\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for j in range(len(ntuple_names)):\n",
    "    process = ntuple_names[j]\n",
    "    fb = tot2_optimized_cuts[j] \n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    for var in Vars:\n",
    "        var_config = getVarDict(fb, process, var_name=var)\n",
    "        data_dict[var] = var_config[var]['var']\n",
    "    \n",
    "    weights = getWeight(fb, process)\n",
    "    data_dict['weights'] = weights\n",
    "    \n",
    "    n_events = len(weights)\n",
    "    data_dict['process'] = [process] * n_events\n",
    "    label = 1 if process == 'ggHyyd' else 0\n",
    "    data_dict['label'] = [label] * n_events\n",
    "    \n",
    "    df_temp = pd.DataFrame(data_dict)\n",
    "    data_list.append(df_temp)\n",
    "\n",
    "df_all = pd.concat(data_list, ignore_index=True)\n",
    "df_all.head()\n",
    "\n",
    "df_all.to_csv(\"/data/jlai/ntups/csv/jet_faking_BDT_input_basic_reduced2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd8084-3a18-44ec-b9df-7aed63835f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
