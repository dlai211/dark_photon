{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d83f5db-f3ae-4feb-b09f-8fb74ea23dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math, pickle, os, csv, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# import config functions\n",
    "sys.path.append(\"/home/jlai/jet-faking/config\")\n",
    "from jet_faking_plot_config import getWeight, zbi, sample_dict, getVarDict\n",
    "from plot_var import variables, variables_data, ntuple_names, ntuple_names_BDT\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high  \n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"]  # Legend\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d09cde-73d1-4e91-af82-7b77bd5c32ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [04:11<00:00, 35.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logs written to:\n",
      " - ./cutlogs_135_internal/cutflow.log\n",
      " - ./cutlogs_135_internal/cutflow.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------- CONFIG --------\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# LOG_DIR = f\"./cutlogs_{RUN_TAG}\"\n",
    "LOG_DIR = \"./cutlogs_135_internal\"\n",
    "try:\n",
    "    shutil.rmtree(LOG_DIR)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "os.makedirs(LOG_DIR, exist_ok=False)\n",
    "TXT_LOG = os.path.join(LOG_DIR, \"cutflow.log\")\n",
    "CSV_LOG = os.path.join(LOG_DIR, \"cutflow.csv\")\n",
    "\n",
    "ntuple_names = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct', 'data23']\n",
    "\n",
    "def weight_sum(fb, ntuple_name):\n",
    "    if ntuple_name == 'data23':\n",
    "        return float(np.sum(getWeight(fb, ntuple_name, jet_faking=True)))\n",
    "    else:\n",
    "        return float(np.sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "# ---- logging helpers ----\n",
    "class CutLogger:\n",
    "    def __init__(self, txt_path, csv_path):\n",
    "        self.txt_path = txt_path\n",
    "        self.csv_path = csv_path\n",
    "        if not os.path.exists(csv_path):\n",
    "            with open(csv_path, \"w\", newline=\"\") as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"sample\",\"step_idx\",\"step\",\"events\",\"weighted\",\"elapsed_s\"])\n",
    "        # fresh txt header\n",
    "        with open(txt_path, \"a\") as f:\n",
    "            f.write(f\"\\n==== Cutflow run {RUN_TAG} ====\\n\")\n",
    "\n",
    "    def write(self, sample, step_idx, step, events, weighted, elapsed):\n",
    "        # text\n",
    "        with open(self.txt_path, \"a\") as f:\n",
    "            f.write(f\"[{sample:12s}] {step_idx:02d}  {step:30s}  \"\n",
    "                    f\"events={events:8d}  weighted={weighted:.6g}  dt={elapsed:.3f}s\\n\")\n",
    "        # csv\n",
    "        with open(self.csv_path, \"a\", newline=\"\") as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([sample, step_idx, step, int(events), f\"{weighted:.12g}\", f\"{elapsed:.6f}\"])\n",
    "\n",
    "logger = CutLogger(TXT_LOG, CSV_LOG)\n",
    "\n",
    "def log_step(sample, step_idx, step_label, fb, t0):\n",
    "    nevt = len(fb)\n",
    "    wsum = weight_sum(fb, sample)\n",
    "    logger.write(sample, step_idx, step_label, nevt, wsum, time.time() - t0)\n",
    "\n",
    "def require(mask, name):\n",
    "    \"\"\"Utility to guard awkward masks and give readable errors if shapes mismatch.\"\"\"\n",
    "    if isinstance(mask, (np.ndarray, ak.Array)) and ak.num(mask, axis=0) is not None:\n",
    "        return mask\n",
    "    raise RuntimeError(f\"Mask '{name}' has wrong shape/type: {type(mask)}\")\n",
    "\n",
    "# ---- your loop with logging ----\n",
    "for ntuple_name in tqdm(ntuple_names):\n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "\n",
    "    if ntuple_name == 'data23':  # data-driven\n",
    "        path = \"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/data23_y_BDT_score.root\"\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables_data, library=\"ak\")\n",
    "        fb['VertexBDTScore'] = fb['BDTScore']\n",
    "\n",
    "        log_step(ntuple_name, step, \"loaded\", fb, start_time); step += 1\n",
    "\n",
    "        # ensure photon arrays exist for reweighting usage downstream\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]\n",
    "        # jet-faking-photon cut (data control)\n",
    "        mask = (ak.firsts(fb['ph_topoetcone40']) - 2450.)/ak.firsts(fb['ph_pt']) > 0.1\n",
    "        fb = fb[require(mask, \"jetfake\")]\n",
    "        log_step(ntuple_name, step, \"jet_faking_photon\", fb, start_time); step += 1\n",
    "\n",
    "        fb = fb[fb['n_ph_baseline'] == 1]\n",
    "        log_step(ntuple_name, step, \"n_ph_baseline==1\", fb, start_time); step += 1\n",
    "\n",
    "    else:  # MC\n",
    "        path = f\"/data/tmathew/ntups/mc23d/{ntuple_name}_y.root\" \n",
    "        path_BDT = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/mc23d_{ntuple_name}_y_BDT_score.root\"\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables, library=\"ak\")\n",
    "\n",
    "        # add BDT score (same file path, same tree)\n",
    "        f_BDT = uproot.open(path_BDT)['nominal']\n",
    "        fb_BDT = f_BDT.arrays([\"event\", \"BDTScore\"], library=\"ak\")\n",
    "        if np.all(fb[\"event\"] == fb_BDT[\"event\"]):\n",
    "            fb[\"VertexBDTScore\"] = fb_BDT[\"BDTScore\"]\n",
    "        else:\n",
    "            print(f\"[WARN] Event mismatch in {ntuple_name}; BDT not attached\")\n",
    "\n",
    "        log_step(ntuple_name, step, \"loaded\", fb, start_time); step += 1\n",
    "\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]\n",
    "        fb = fb[fb['n_ph'] == 1]\n",
    "        log_step(ntuple_name, step, \"n_ph==1\", fb, start_time); step += 1\n",
    "\n",
    "        if ntuple_name in (\"Zjets\",\"Wjets\"):\n",
    "            mask = ak.firsts(fb['ph_truth_type']) == 2   # keep e->gamma only\n",
    "            fb = fb[require(mask, \"ph_truth_type==2\")]\n",
    "            log_step(ntuple_name, step, \"truth e->gamma\", fb, start_time); step += 1\n",
    "\n",
    "        if ntuple_name == \"ggHyyd\":\n",
    "            fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "            log_step(ntuple_name, step, \"pv_z exists\", fb, start_time); step += 1\n",
    "            good_pv = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "            fb = fb[require(good_pv, \"goodPV\")]\n",
    "            log_step(ntuple_name, step, \"goodPV\", fb, start_time); step += 1\n",
    "\n",
    "    # --------- BASIC CUTS (shared) ----------\n",
    "    # NOTE: If 'ggHyyd' is signal without a prompt μ, consider not requiring n_mu==1 for that sample.\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    log_step(ntuple_name, step, \"n_mu_baseline==0\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['n_el_baseline'] == 0]\n",
    "    log_step(ntuple_name, step, \"n_el_baseline==0\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    log_step(ntuple_name, step, \"n_tau_baseline==0\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M'] == 1]\n",
    "    log_step(ntuple_name, step, \"trigger==1\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0]\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) > 50_000]\n",
    "    log_step(ntuple_name, step, \"ph_pt>50GeV\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['met_tst_et'] > 100_000]\n",
    "    log_step(ntuple_name, step, \"MET>100GeV\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['n_jet_central'] <= 3]\n",
    "    log_step(ntuple_name, step, \"n_jet_central<=3\", fb, start_time); step += 1\n",
    "\n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) *\n",
    "                     (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000.0\n",
    "    mask1 = mt_tmp > 80\n",
    "    fb = fb[mask1]\n",
    "    log_step(ntuple_name, step, \"mT>80GeV\", fb, start_time); step += 1\n",
    "\n",
    "    fb = fb[fb['VertexBDTScore'] > 0.1]\n",
    "    log_step(ntuple_name, step, \"VertexBDTScore>0.1\", fb, start_time); step += 1\n",
    "\n",
    "    # ---------- INTERNAL SELECTION CUT ------------\n",
    "\n",
    "    metsig_tmp = fb['met_tst_sig'] \n",
    "    mask1 = metsig_tmp > 6\n",
    "    fb = fb[mask1]\n",
    "    log_step(ntuple_name, step, \"met_tst_sig>6\", fb, start_time); step += 1\n",
    "    \n",
    "    ph_eta_tmp = np.abs(ak.firsts(fb['ph_eta']))\n",
    "    fb = fb[ph_eta_tmp < 1.75]\n",
    "    log_step(ntuple_name, step, \"ph_eta<1.75\", fb, start_time); step += 1\n",
    "\n",
    "    dphi_met_phterm_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])) # added cut 3\n",
    "    fb = fb[dphi_met_phterm_tmp > 1.25]\n",
    "    log_step(ntuple_name, step, \"dphi_met_phterm>1.25\", fb, start_time); step += 1\n",
    "\n",
    "    dmet_tmp = fb['met_tst_noJVT_et'] - fb['met_tst_et']\n",
    "    mask1 = dmet_tmp > -10000\n",
    "    fb = fb[mask1]\n",
    "    log_step(ntuple_name, step, \"dmet>-10GeV\", fb, start_time); step += 1\n",
    "\n",
    "    dphi_jj_tmp = fb['dphi_central_jj']\n",
    "    dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, np.nan, dphi_jj_tmp)\n",
    "    dphi_jj_tmp = np.arccos(np.cos(dphi_jj_tmp))\n",
    "    dphi_jj_tmp = ak.where(np.isnan(dphi_jj_tmp), -999, dphi_jj_tmp)\n",
    "    fb = fb[dphi_jj_tmp < 2.5]\n",
    "    log_step(ntuple_name, step, \"dphi_jj_central<2.5\", fb, start_time); step += 1\n",
    "\n",
    "    dphi_met_jetterm_tmp = np.where(fb['met_jetterm_et'] != 0,   # added cut 5\n",
    "                        np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "                        -999)\n",
    "    fb = fb[dphi_met_jetterm_tmp < 0.75]\n",
    "    log_step(ntuple_name, step, \"dphi_met_jetterm<0.75\", fb, start_time); step += 1\n",
    "    \n",
    "    # tot.append(fb) # save the fb for further study\n",
    "\n",
    "    # ---- sanity check for None ----\n",
    "    n_none = int(ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "    with open(TXT_LOG, \"a\") as ftxt:\n",
    "        ftxt.write(f\"[{ntuple_name:12s}] None-check met_tst_et: {n_none}\\n\")\n",
    "\n",
    "    # optional: free memory\n",
    "    del fb\n",
    "\n",
    "print(f\"\\nLogs written to:\\n - {TXT_LOG}\\n - {CSV_LOG}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4827b439-c672-4e76-8851-45fba897ea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified cutflow written to:\n",
      "  - cutlogs_135_internal/cutflow_unified.csv\n",
      "  - cutlogs_135_internal/cutflow_unified.md\n",
      "                  cut   ggHyyd    Zjets   Zgamma   Wgamma    Wjets gammajet_direct   data23 S/sqrt(B) S/sqrt(S+B) S/sqrt(S+1.3B) ZBi (σ_b=30%)\n",
      "                 LOAD 2.29e+04 1.74e+06  3.1e+05 5.68e+05 3.97e+06        1.73e+08 2.13e+08     1.157       1.157          1.015        -0.199\n",
      "CUT 1 (preprocessing) 8732.756 6.74e+05  2.5e+05 4.28e+05 2.81e+06        1.46e+08 3.62e+07     0.640       0.640          0.561        -0.199\n",
      "     n_mu_baseline==0 8732.756 6.74e+05  2.5e+05 4.28e+05 2.81e+06        1.46e+08 3.62e+07     0.640       0.640          0.561        -0.199\n",
      "     n_el_baseline==0 8732.756 1.99e+05  2.5e+05 4.28e+05 2.81e+06        1.46e+08 3.62e+07     0.641       0.641          0.562        -0.199\n",
      "    n_tau_baseline==0 8630.402 1.96e+05  2.4e+05 3.95e+05 2.78e+06        1.43e+08 3.55e+07     0.639       0.639          0.560        -0.199\n",
      "           trigger==1 2584.305 6059.204  1.1e+05 9.75e+04 2.74e+05        6.37e+06 7.73e+06     0.677       0.677          0.593        -0.198\n",
      "          ph_pt>50GeV 2578.163 6016.867  1.1e+05 9.72e+04 2.72e+05        6.35e+06 7.67e+06     0.677       0.677          0.594        -0.198\n",
      "           MET>100GeV  568.633  775.327 5.42e+04 4.02e+04 5.05e+04        9.48e+05 1.01e+06     0.392       0.392          0.344        -0.198\n",
      "     n_jet_central<=3  491.889  681.041 5.11e+04 3.56e+04 4.62e+04        9.06e+05 8.57e+05     0.357       0.357          0.313        -0.198\n",
      "             mT>80GeV  479.373  669.827  5.1e+04 3.51e+04 4.31e+04        9.03e+05 8.53e+05     0.349       0.349          0.306        -0.198\n",
      "   VertexBDTScore>0.1  394.525  103.815 1.55e+04 1.45e+04 1.82e+04        5.21e+04 1.84e+05     0.739       0.739          0.648        -0.194\n",
      "        met_tst_sig>6  349.744   37.833 1.47e+04 1.31e+04 1.59e+04        1.77e+04 4.54e+04     1.070       1.068          0.937        -0.188\n",
      "          ph_eta<1.75  306.565   16.962 1.15e+04 1.02e+04 7865.680        1.41e+04 3.49e+04     1.093       1.091          0.957        -0.186\n",
      " dphi_met_phterm>1.25  276.255    7.001 1807.919 3281.860 3729.635         548.204 4899.503     2.312       2.290          2.013        -0.134\n",
      "          dmet>-10GeV  268.177    5.712 1745.188 3090.626 3547.749         451.119 4290.870     2.340       2.317          2.037        -0.131\n",
      "  dphi_jj_central<2.5  255.685    5.095 1553.635 2736.282 3262.786         429.473 3712.153     2.364       2.338          2.056        -0.126\n",
      "dphi_met_jetterm<0.75  252.028    4.905 1317.128 2381.756 3211.018         251.944 3243.982     2.470       2.441          2.146        -0.118\n"
     ]
    }
   ],
   "source": [
    "process_order = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct','data23']\n",
    "\n",
    "preselection_end = {\n",
    "    'ggHyyd':          'goodPV',               # pv_z exists -> goodPV (take the last one)\n",
    "    'Zjets':           'truth e->gamma',\n",
    "    'Wjets':           'truth e->gamma',\n",
    "    'Zgamma':          'n_ph==1',\n",
    "    'Wgamma':          'n_ph==1',\n",
    "    'gammajet_direct': 'n_ph==1',\n",
    "    'data23':          'n_ph_baseline==1',     # jet_faking_photon -> n_ph_baseline==1 (take the last one)\n",
    "}\n",
    "\n",
    "# Internal Notes\n",
    "shared_cuts = [\n",
    "    'n_mu_baseline==0',\n",
    "    'n_el_baseline==0',\n",
    "    'n_tau_baseline==0',\n",
    "    'trigger==1',\n",
    "    'ph_pt>50GeV',\n",
    "    'MET>100GeV',\n",
    "    'n_jet_central<=3',\n",
    "    'mT>80GeV',\n",
    "    'VertexBDTScore>0.1',\n",
    "    'met_tst_sig>6',\n",
    "    'ph_eta<1.75',\n",
    "    'dphi_met_phterm>1.25',\n",
    "    'dmet>-10GeV',\n",
    "    'dphi_jj_central<2.5',\n",
    "    'dphi_met_jetterm<0.75'\n",
    "]\n",
    "\n",
    "# Load and sanitize the log\n",
    "df = pd.read_csv(CSV_LOG)\n",
    "# Ensure numeric\n",
    "df['weighted'] = pd.to_numeric(df['weighted'], errors='coerce')\n",
    "df['step_idx'] = pd.to_numeric(df['step_idx'], errors='coerce')\n",
    "\n",
    "# Keep last entry per (sample, step)\n",
    "df = (df.sort_values(['sample','step_idx'])\n",
    "        .drop_duplicates(subset=['sample','step'], keep='last'))\n",
    "\n",
    "# Helper to fetch the weighted yield for a given (sample, step label)\n",
    "def get_yield(sample, step_label):\n",
    "    row = df[(df['sample'] == sample) & (df['step'] == step_label)]\n",
    "    if not row.empty:\n",
    "        return float(row['weighted'].iloc[0])\n",
    "    # Fallback: if a step is unexpectedly missing, try using the latest prior step by index\n",
    "    # (shouldn't happen after preselection, but keeps the pipeline resilient)\n",
    "    sample_rows = df[df['sample'] == sample].sort_values('step_idx')\n",
    "    prior = sample_rows[sample_rows['step_idx'] <= sample_rows['step_idx'].max()]\n",
    "    return float(prior['weighted'].iloc[-1]) if not prior.empty else np.nan\n",
    "\n",
    "# 1) LOAD row = 'loaded'\n",
    "rows = ['LOAD', 'CUT 1 (preprocessing)'] + shared_cuts\n",
    "table = pd.DataFrame(index=rows, columns=process_order, dtype=float)\n",
    "\n",
    "for p in process_order:\n",
    "    table.loc['LOAD', p] = get_yield(p, 'loaded')\n",
    "\n",
    "# 2) CUT 1 row = process-specific preselection_end\n",
    "for p in process_order:\n",
    "    end_step = preselection_end[p]\n",
    "    table.loc['CUT 1 (preprocessing)', p] = get_yield(p, end_step)\n",
    "\n",
    "# 3) Shared cuts: same step name for all processes\n",
    "for cut in shared_cuts:\n",
    "    for p in process_order:\n",
    "        table.loc[cut, p] = get_yield(p, cut)\n",
    "\n",
    "# Compute S/sqrt(B) for each row\n",
    "signal_col = 'ggHyyd'\n",
    "data_cols = ['data23']\n",
    "bkg_cols = [c for c in process_order if c not in ([signal_col])]\n",
    "\n",
    "S = table[signal_col].fillna(0.0)\n",
    "B = table[bkg_cols].sum(axis=1).astype(float)\n",
    "\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    ssb = S / np.sqrt(B)                     # S/sqrt(B)\n",
    "    ssb.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    ss_sb   = S / np.sqrt(S + B)             # S/sqrt(S+B)\n",
    "    ss_sb.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    ss_s13b = S / np.sqrt(S + 1.3*B)         # S/sqrt(S+1.3B)\n",
    "    ss_s13b.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "SIGMA_B_FRAC = 0.30  # 30% relative background uncertainty; change as needed\n",
    "# Vectorized ZBi over rows (robust if B<=0 -> 0.0)\n",
    "ZBi = pd.Series(\n",
    "    [zbi(float(s), float(b), sigma_b_frac=SIGMA_B_FRAC) for s, b in zip(S.values, B.values)],\n",
    "    index=table.index, dtype=float\n",
    ")\n",
    "\n",
    "# Pretty output\n",
    "disp = table.copy()\n",
    "def fmt(x):\n",
    "    if pd.isna(x): return 'n/a'\n",
    "    # scientific for very small/large; fixed otherwise\n",
    "    return f\"{x:.3g}\" if (x != 0 and (abs(x) < 1e-2 or abs(x) >= 1e4)) else f\"{x:.3f}\"\n",
    "\n",
    "disp_out = disp.applymap(fmt)\n",
    "disp_out['S/sqrt(B)']           = ssb.map(lambda v: 'n/a' if pd.isna(v) else f\"{v:.3f}\")\n",
    "disp_out['S/sqrt(S+B)']         = ss_sb.map(lambda v: 'n/a' if pd.isna(v) else f\"{v:.3f}\")\n",
    "disp_out['S/sqrt(S+1.3B)']      = ss_s13b.map(lambda v: 'n/a' if pd.isna(v) else f\"{v:.3f}\")\n",
    "disp_out[f'ZBi (σ_b={SIGMA_B_FRAC:.0%})'] = ZBi.map(lambda v: 'n/a' if pd.isna(v) else f\"{v:.3f}\")\n",
    "disp_out.insert(0, 'cut', disp_out.index)\n",
    "\n",
    "# Save + print (add the two new columns)\n",
    "out_csv = Path(LOG_DIR) / \"cutflow_unified.csv\"\n",
    "out_md  = Path(LOG_DIR) / \"cutflow_unified.md\"\n",
    "disp_out.to_csv(out_csv, index=False)\n",
    "with open(out_md, \"w\") as f:\n",
    "    f.write(disp_out.to_markdown(index=False))\n",
    "\n",
    "print(\"Unified cutflow written to:\")\n",
    "print(f\"  - {out_csv}\")\n",
    "print(f\"  - {out_md}\")\n",
    "print(disp_out[['cut'] + process_order + ['S/sqrt(B)','S/sqrt(S+B)','S/sqrt(S+1.3B)', f'ZBi (σ_b={SIGMA_B_FRAC:.0%})']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071e198-4631-4ea1-9abe-5d8b5f499213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80ac05-4a54-4313-ac7c-20e1ddb364bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
