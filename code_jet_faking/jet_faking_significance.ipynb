{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import uproot, sys, time, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.special import betainc\n",
    "from scipy.stats import norm\n",
    "\n",
    "# import config functions\n",
    "from jet_faking_plot_config import getWeight, zbi, sample_dict, getVarDict\n",
    "from plot_var import variables, variables_data, ntuple_names, ntuple_names_BDT\n",
    "\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 14.0,10.0  # Roughly 11 cm wde by 8 cm high\n",
    "mpl.rcParams['font.size'] = 20.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"]  # Legend\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ggHyyd\n",
      "Unweighted Events weighted after cut:  2059\n",
      "Weighted Events weighted after cut:  208.62827\n",
      "Zjets\n",
      "Unweighted Events weighted after cut:  53\n",
      "Weighted Events weighted after cut:  3.178844\n",
      "Zgamma\n",
      "Unweighted Events weighted after cut:  26918\n",
      "Weighted Events weighted after cut:  906.9535\n",
      "Wgamma\n",
      "Unweighted Events weighted after cut:  17097\n",
      "Weighted Events weighted after cut:  1713.7449\n",
      "Wjets\n",
      "Unweighted Events weighted after cut:  5038\n",
      "Weighted Events weighted after cut:  1144.4331\n",
      "gammajet_direct\n",
      "Unweighted Events weighted after cut:  803\n",
      "Weighted Events weighted after cut:  100.78318\n",
      "data23\n",
      "Unweighted Events weighted after cut:  1039\n",
      "Weighted Events weighted after cut:  2090.6700000000096\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tot2)):\n",
    "    print(ntuple_names[i])\n",
    "    print_cut(ntuple_names[i], tot2[i], \"weighted after cut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.7024580745916116)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "208.62827 / np.sqrt(3.17 + 906.9535 + 1713.7449 + 1144.4331 + 100.78318 + 2090.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file:  /data/tmathew/ntups/mc23d/ggHyyd_y.root\n",
      "Unweighted Events before cut:  195671\n",
      "Weighted Events before cut:  19979.121\n",
      "Unweighted Events after basic cut:  3729\n",
      "Weighted Events after basic cut:  375.93835\n",
      "Number of none values:  0\n",
      "Reading Time for ggHyyd: 2.854734420776367 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Zjets_y.root\n",
      "Unweighted Events before cut:  3242488\n",
      "Weighted Events before cut:  674497.9\n",
      "Unweighted Events after basic cut:  5164\n",
      "Weighted Events after basic cut:  124.29326\n",
      "Number of none values:  0\n",
      "Reading Time for Zjets: 99.14944171905518 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Zgamma_y.root\n",
      "Unweighted Events before cut:  3423357\n",
      "Weighted Events before cut:  249515.86\n",
      "Unweighted Events after basic cut:  704359\n",
      "Weighted Events after basic cut:  16750.656\n",
      "Number of none values:  0\n",
      "Reading Time for Zgamma: 39.75036358833313 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Wgamma_y.root\n",
      "Unweighted Events before cut:  1308982\n",
      "Weighted Events before cut:  427789.75\n",
      "Unweighted Events after basic cut:  169968\n",
      "Weighted Events after basic cut:  15736.289\n",
      "Number of none values:  0\n",
      "Reading Time for Wgamma: 16.76754117012024 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/Wjets_y.root\n",
      "Unweighted Events before cut:  1962593\n",
      "Weighted Events before cut:  2811573.2\n",
      "Unweighted Events after basic cut:  32512\n",
      "Weighted Events after basic cut:  14099.505\n",
      "Number of none values:  0\n",
      "Reading Time for Wjets: 34.869004249572754 seconds\n",
      "\n",
      "processing file:  /data/tmathew/ntups/mc23d/gammajet_direct_y.root\n",
      "Unweighted Events before cut:  12921098\n",
      "Weighted Events before cut:  145885300.0\n",
      "Unweighted Events after basic cut:  1072422\n",
      "Weighted Events after basic cut:  59503.31\n",
      "Number of none values:  0\n",
      "Reading Time for gammajet_direct: 116.33888459205627 seconds\n",
      "\n",
      "processing file:  /data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/data23_y_BDT_score.root\n",
      "Unweighted Events before cut:  16269333\n",
      "Weighted Events before cut:  33466244.772483986\n",
      "Unweighted Events after basic cut:  61241\n",
      "Weighted Events after basic cut:  125606.7300000043\n",
      "Number of none values:  0\n",
      "Reading Time for data23: 165.21777319908142 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tot = []\n",
    "data = pd.DataFrame()\n",
    "unweighted_bcut, weighted_bcut, unweighted_acut, weighted_acut = [], [], [], []\n",
    "ntuple_names = ['ggHyyd','Zjets','Zgamma','Wgamma','Wjets','gammajet_direct', 'data23']\n",
    "\n",
    "def test(fb):\n",
    "    # checking if there are any none values\n",
    "    mask = ak.is_none(fb['met_tst_et'])\n",
    "    n_none = ak.sum(mask)\n",
    "    print(\"Number of none values: \", n_none)\n",
    "    # if n_none > 0:\n",
    "    #     fb = fb[~mask]\n",
    "    # print(\"Events after removing none values: \", len(fb), ak.sum(ak.is_none(fb['met_tst_et'])))\n",
    "\n",
    "def print_cut(ntuple_name, fb, label):\n",
    "    print(f\"Unweighted Events {label}: \", len(fb))\n",
    "    if ntuple_name == 'data23':\n",
    "        print(f\"Weighted Events {label}: \", sum(getWeight(fb, ntuple_name, jet_faking=True)))\n",
    "    else: \n",
    "        print(f\"Weighted Events {label}: \", sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "for i in range(len(ntuple_names)):\n",
    "    ucut, wcut = [], []\n",
    "    start_time = time.time()\n",
    "    ntuple_name = ntuple_names[i]\n",
    "    if ntuple_name == 'data23': # data\n",
    "        path = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/data23_y_BDT_score.root\" \n",
    "        print('processing file: ', path)\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables_data, library=\"ak\")\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "                \n",
    "        mask1 = (ak.firsts(fb['ph_topoetcone40'])-2450.)/ak.firsts(fb['ph_pt']) < 0.1   # jet_faking_photon cut\n",
    "        fb = fb[mask1]\n",
    "        fb = fb[fb['n_ph_baseline'] == 1]\n",
    "\n",
    "    else: # MC\n",
    "        path = f\"/data/tmathew/ntups/mc23d/{ntuple_name}_y.root\" \n",
    "        path_BDT = f\"/data/fpiazza/ggHyyd/Ntuples/MC23d/withVertexBDT/mc23d_{ntuple_name}_y_BDT_score.root\" \n",
    "        print('processing file: ', path)\n",
    "        f = uproot.open(path)['nominal']\n",
    "        fb = f.arrays(variables, library=\"ak\")\n",
    "\n",
    "        # add BDT score to fb\n",
    "        f_BDT = uproot.open(path_BDT)['nominal']\n",
    "        fb_BDT = f_BDT.arrays([\"event\", \"BDTScore\"], library=\"ak\")\n",
    "        tmp = fb[\"event\"] == fb_BDT[\"event\"]\n",
    "        if np.all(tmp) == True:\n",
    "            fb[\"BDTScore\"] = fb_BDT[\"BDTScore\"]\n",
    "        else: \n",
    "            print(\"Something is wrong, need arranging\")\n",
    "\n",
    "        fb = fb[ak.num(fb['ph_eta']) > 0]     # for abs(ak.firsts(fb['ph_eta'])) to have value to the reweighting\n",
    "        fb = fb[fb['n_ph'] == 1]\n",
    "\n",
    "    \n",
    "\n",
    "    # Zjets and Wjets (rule out everything except for e->gamma)\n",
    "    if ntuple_name == 'Zjets' or ntuple_name == 'Wjets':\n",
    "        mask1 = ak.firsts(fb['ph_truth_type']) == 2\n",
    "        mask2 = ak.firsts(fb['ph_truth_type']) == 2\n",
    "        fb = fb[mask1 & mask2]\n",
    "    \n",
    "    print_cut(ntuple_name, fb, 'before cut')\n",
    "\n",
    "\n",
    "    fb = fb[fb['n_mu_baseline'] == 0]\n",
    "    fb = fb[fb['n_el_baseline'] == 0]\n",
    "    fb = fb[fb['n_tau_baseline'] == 0]\n",
    "    fb = fb[fb['trigger_HLT_g50_tight_xe40_cell_xe70_pfopufit_80mTAC_L1eEM26M']==1]\n",
    "    fb = fb[ak.num(fb['ph_pt']) > 0] # prevent none values in Tbranch\n",
    "    fb = fb[fb['met_tst_et'] >= 100000] # MET cut (basic cut)\n",
    "    fb = fb[ak.firsts(fb['ph_pt']) >= 50000] # ph_pt cut (basic cut)\n",
    "    fb = fb[fb['n_jet_central'] <= 4] # n_jet_central cut (basic cut)\n",
    "    # goodPV on signal only\n",
    "    if ntuple_name == 'ggHyyd':\n",
    "        fb = fb[ak.num(fb['pv_z']) > 0]\n",
    "        good_pv_tmp = (np.abs(ak.firsts(fb['pv_truth_z']) - ak.firsts(fb['pv_z'])) <= 0.5)\n",
    "        fb = fb[good_pv_tmp]\n",
    "\n",
    "    mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "                            (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    mask1 = mt_tmp >= 100 # trigger cut\n",
    "    fb = fb[mask1]\n",
    "\n",
    "    fb = fb[fb['BDTScore'] >= 0.1] # added cut 1\n",
    "\n",
    "    print_cut(ntuple_name, fb, 'after basic cut')\n",
    "\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # metsig_tmp = fb['met_tst_sig'] # added cut 2 \n",
    "    # mask1 = metsig_tmp >= 7\n",
    "    # fb = fb[mask1]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # dphi_met_phterm_tmp = np.arccos(np.cos(fb['met_tst_phi'] - fb['met_phterm_phi'])) # added cut 3\n",
    "    # fb = fb[dphi_met_phterm_tmp >= 1.35]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # dmet_tmp = fb['met_tst_noJVT_et'] - fb['met_tst_et'] # added cut 4\n",
    "    # mask1 = dmet_tmp >= -20000\n",
    "    # mask2 = dmet_tmp <= 50000\n",
    "    # fb = fb[mask1 * mask2]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # dphi_met_jetterm_tmp = np.where(fb['met_jetterm_et'] != 0,   # added cut 5\n",
    "    #                         np.arccos(np.cos(fb['met_tst_phi'] - fb['met_jetterm_phi'])),\n",
    "    #                         -999)\n",
    "    # fb = fb[dphi_met_jetterm_tmp <= 0.7]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # ph_eta_tmp = np.abs(ak.firsts(fb['ph_eta'])) # added cut 6\n",
    "    # fb = fb[ph_eta_tmp <= 1.75]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # phi1_tmp = ak.firsts(fb['jet_central_phi']) # added cut 7\n",
    "    # phi2_tmp = ak.mask(fb['jet_central_phi'], ak.num(fb['jet_central_phi']) >= 2)[:, 1] \n",
    "    # dphi_tmp = np.arccos(np.cos(phi1_tmp - phi2_tmp))\n",
    "    # dphi_jj_tmp = ak.fill_none(dphi_tmp, -999)\n",
    "    # fb = fb[dphi_jj_tmp <= 2.5]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    # jet_sum_tmp = ak.sum(fb['jet_central_pt'], axis=-1)\n",
    "    # expr = (fb['met_tst_et'] + ak.firsts(fb['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "    # balance_tmp = ak.where(jet_sum_tmp != 0, expr, 999) \n",
    "    # fb = fb[balance_tmp >= 0.65]\n",
    "    # ucut.append(len(fb))\n",
    "    # wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "    # mt_tmp = np.sqrt(2 * fb['met_tst_et'] * ak.firsts(fb['ph_pt']) * \n",
    "    #                     (1 - np.cos(fb['met_tst_phi'] - ak.firsts(fb['ph_phi'])))) / 1000\n",
    "    # mask1 = mt_tmp >= 95\n",
    "    # fb = fb[mask1]\n",
    "\n",
    "    # print_cut(ntuple_name, fb)\n",
    "    ucut.append(len(fb))\n",
    "    if ntuple_name == 'data23':\n",
    "        wcut.append(sum(getWeight(fb, ntuple_name, jet_faking=True)))\n",
    "    else: \n",
    "        wcut.append(sum(getWeight(fb, ntuple_name)))\n",
    "\n",
    "\n",
    "    unweighted_acut.append(ucut)\n",
    "    weighted_acut.append(wcut)\n",
    "    test(fb) # check for none value\n",
    "\n",
    "    print(f\"Reading Time for {ntuple_name}: {(time.time()-start_time)} seconds\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    tot.append(fb)\n",
    "\n",
    "    fb = 0\n",
    "    fb_BDT = 0\n",
    "    tmp = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7808011540031398)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "375.93835 / np.sqrt(124.29326 + 16750.656 + 15736.289 + 14099.505 + 59503.31 + 125606.7300000043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_BDTScore_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_balance_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_balance_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_dmet_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_dmet_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_dphi_jj_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_dphi_met_jetterm_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_dphi_met_jetterm_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_dphi_met_phterm_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_dphi_met_phterm_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_dphi_ph_centraljet1_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_dphi_ph_centraljet1_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_dphi_phterm_jetterm_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_dphi_phterm_jetterm_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_met_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_met_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_metsig_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_metsig_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_mt_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_mt_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_n_jet_central_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_ph_eta_uppercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_ph_pt_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_dphi_jjcut/significance_ph_pt_uppercut.png\n"
     ]
    }
   ],
   "source": [
    "def sel(tot):\n",
    "    tot2 = []\n",
    "    for i in range(len(tot)):\n",
    "        fb2 = tot[i]\n",
    "\n",
    "        jet_sum_tmp = ak.sum(fb2['jet_central_pt'], axis=-1)\n",
    "        expr = (fb2['met_tst_et'] + ak.firsts(fb2['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "        balance_tmp = ak.where(jet_sum_tmp != 0, expr, -999)\n",
    "        mask1 = balance_tmp >= 0.65\n",
    "        mask2 = balance_tmp == -999\n",
    "        fb2 = fb2[mask1 | mask2]\n",
    "        \n",
    "        metsig_tmp = fb2['met_tst_sig'] \n",
    "        mask1 = metsig_tmp >= 7\n",
    "        fb2 = fb2[mask1]\n",
    "\n",
    "        # mask2 = metsig_tmp <= 13\n",
    "        # fb2 = fb2[mask1 * mask2]\n",
    "        \n",
    "        ph_eta_tmp = np.abs(ak.firsts(fb2['ph_eta']))\n",
    "        fb2 = fb2[ph_eta_tmp <= 1.75]\n",
    "\n",
    "        dphi_met_phterm_tmp = np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_phterm_phi'])) # added cut 3\n",
    "        fb2 = fb2[dphi_met_phterm_tmp >= 1.55]\n",
    "\n",
    "        dmet_tmp = fb2['met_tst_noJVT_et'] - fb2['met_tst_et']\n",
    "        mask1 = dmet_tmp >= -20000\n",
    "        mask2 = dmet_tmp <= 40000\n",
    "        fb2 = fb2[mask1 * mask2]\n",
    "\n",
    "        dphi_jj_tmp = fb2['dphi_central_jj']\n",
    "        dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, -999, dphi_jj_tmp)\n",
    "        fb2 = fb2[dphi_jj_tmp <= 2.4]\n",
    "\n",
    "        dphi_met_jetterm_tmp = np.where(fb2['met_jetterm_et'] != 0,   # added cut 5\n",
    "                            np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_jetterm_phi'])),\n",
    "                            -999)\n",
    "        fb2 = fb2[dphi_met_jetterm_tmp <= 0.75]\n",
    "\n",
    "        dphi_ph_centraljet1_tmp = np.arccos(np.cos(ak.firsts(fb2['ph_phi']) - ak.firsts(fb2['jet_central_phi'])))\n",
    "        dphi_ph_centraljet1_tmp = ak.fill_none(dphi_ph_centraljet1_tmp, -999)\n",
    "        mask1 = dphi_ph_centraljet1_tmp >= 1.8\n",
    "        mask2 = dphi_ph_centraljet1_tmp == -999\n",
    "        fb2 = fb2[mask1 | mask2]\n",
    "        \n",
    "        tot2.append(fb2)\n",
    "    return tot2\n",
    "\n",
    "tot2 = sel(tot)\n",
    "# tot2 = tot\n",
    "\n",
    "signal_name = 'ggHyyd'\n",
    "cut_name = 'dphi_jj'\n",
    "\n",
    "def getCutDict():\n",
    "    cut_dict = {}\n",
    "\n",
    "    cut_dict['BDTScore'] = {\n",
    "        'lowercut': np.arange(0, 0.4+0.1, 0.1) # BDTScore > cut\n",
    "    }\n",
    "    cut_dict['balance'] = {\n",
    "        'lowercut': np.arange(0, 1.5 + 0.05, 0.05), # balance > cut\n",
    "        'uppercut': np.arange(5, 8 + 0.2, 0.2) # balance < cut\n",
    "    }\n",
    "    cut_dict['dmet'] = {\n",
    "        'lowercut': np.arange(-30000, 0 + 5000, 5000), # dmet > cut\n",
    "        'uppercut': np.arange(10000, 100000 + 5000, 5000), # -10000 < dmet < cut\n",
    "    }\n",
    "    cut_dict['dphi_jj'] = {\n",
    "        'uppercut': np.arange(1, 3.1 + 0.1, 0.1) # dphi_jj < cut\n",
    "    }\n",
    "    cut_dict['dphi_met_jetterm'] = {\n",
    "        'lowercut': np.arange(0, 1 + 0.05, 0.05), # dphi_met_jetterm > cut \n",
    "        'uppercut': np.arange(0.5, 2 + 0.05, 0.05), # dphi_met_jetterm < cut \n",
    "    }\n",
    "    cut_dict['dphi_met_phterm'] = {\n",
    "        'lowercut': np.arange(1, 2 + 0.05, 0.05), # dphi_met_phterm > cut\n",
    "        'uppercut': np.arange(2, 3.1 + 0.1, 0.1), # dphi_met_phterm < cut\n",
    "    }\n",
    "    cut_dict['dphi_ph_centraljet1'] = {\n",
    "        'lowercut': np.arange(0, 2.5 + 0.1, 0.1), # dphi_ph_centraljet1 > cut\n",
    "        'uppercut': np.arange(1.5, 3.1 + 0.1, 0.1) # dphi_ph_centraljet1 < cut\n",
    "    }\n",
    "    cut_dict['dphi_phterm_jetterm'] = {\n",
    "        'lowercut': np.arange(1, 2.5 + 0.05, 0.05), # dphi_phterm_jetterm > cut\n",
    "        'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "    }\n",
    "    cut_dict['met'] = {\n",
    "        'lowercut': np.arange(100000, 140000 + 5000, 5000),  # met > cut\n",
    "        'uppercut': np.arange(140000, 300000 + 5000, 5000),  # met < cut\n",
    "    }\n",
    "    cut_dict['metsig'] = {\n",
    "        'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "        'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "    }\n",
    "    cut_dict['mt'] = {\n",
    "        'lowercut': np.arange(80, 130+5, 5), # mt > cut\n",
    "        'uppercut': np.arange(120, 230+5, 5) # mt < cut\n",
    "    }\n",
    "    cut_dict['n_jet_central'] = {\n",
    "        'uppercut': np.arange(0, 8+1, 1) # njet < cut\n",
    "    }\n",
    "    cut_dict['ph_eta'] = {\n",
    "        'uppercut': np.arange(1, 2.5 + 0.05, 0.05), # ph_eta < cut\n",
    "    }\n",
    "    cut_dict['ph_pt'] = {\n",
    "        'lowercut': np.arange(50000, 100000 + 5000, 5000),  # ph_pt > cut\n",
    "        'uppercut': np.arange(100000, 300000 + 10000, 10000),  # ph_pt > cut\n",
    "    }\n",
    "\n",
    "    return cut_dict\n",
    "cut_config = getCutDict()\n",
    "\n",
    "def calculate_significance(cut_var, cut_type, cut_values):\n",
    "    sig_simple_list = []\n",
    "    sig_s_plus_b_list = []\n",
    "    sig_s_plus_1p3b_list = []\n",
    "    sig_binomial_list = []\n",
    "\n",
    "    sigacc_simple_list = []\n",
    "    sigacc_s_plus_b_list = []\n",
    "    sigacc_s_plus_1p3b_list = []\n",
    "    sigacc_binomial_list = []\n",
    "\n",
    "    acceptance_values = []  # Store acceptance percentages\n",
    "\n",
    "    for cut in cut_values:\n",
    "        sig_after_cut = 0\n",
    "        bkg_after_cut = []\n",
    "        sig_events = 0\n",
    "        \n",
    "        for i in range(len(ntuple_names)):\n",
    "            fb = tot2[i]\n",
    "            process = ntuple_names[i]\n",
    "            var_config = getVarDict(fb, process, var_name=cut_var)\n",
    "            x = var_config[cut_var]['var']\n",
    "            mask = x != -999 # Apply cut: Remove -999 values \n",
    "            x = x[mask]\n",
    "\n",
    "            if process == signal_name:\n",
    "                sig_events = getWeight(fb, process)\n",
    "                sig_events = sig_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                sig_after_cut = ak.sum(sig_events[mask])\n",
    "            \n",
    "            else:\n",
    "                bkg_events = getWeight(fb, process)\n",
    "                bkg_events = bkg_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                bkg_after_cut.append(ak.sum(bkg_events[mask]))\n",
    "\n",
    "       # Now compute different types of significance\n",
    "        total_bkg = sum(bkg_after_cut)\n",
    "        total_signal = sig_after_cut\n",
    "\n",
    "        # Avoid zero division carefully\n",
    "        if total_bkg > 0:\n",
    "            sig_simple = total_signal / np.sqrt(total_bkg)\n",
    "            sig_s_plus_b = total_signal / np.sqrt(total_signal + total_bkg) if (total_signal + total_bkg) > 0 else 0\n",
    "            sig_s_plus_1p3b = total_signal / np.sqrt(total_signal + 1.3 * total_bkg) if (total_signal + 1.3*total_bkg) > 0 else 0\n",
    "            sig_binomial = zbi(total_signal, total_bkg, sigma_b_frac=0.3)\n",
    "        else:\n",
    "            sig_simple = sig_s_plus_b = sig_s_plus_1p3b = sig_binomial = 0\n",
    "\n",
    "        # Acceptance\n",
    "        acceptance = total_signal / sum(sig_events) if sum(sig_events) > 0 else 0\n",
    "        acceptance_values.append(acceptance * 100)  # percentage\n",
    "\n",
    "        # Save significance\n",
    "        sig_simple_list.append(sig_simple)\n",
    "        sig_s_plus_b_list.append(sig_s_plus_b)\n",
    "        sig_s_plus_1p3b_list.append(sig_s_plus_1p3b)\n",
    "        sig_binomial_list.append(sig_binomial)\n",
    "\n",
    "        # Save significance × acceptance\n",
    "        sigacc_simple_list.append(sig_simple * acceptance)\n",
    "        sigacc_s_plus_b_list.append(sig_s_plus_b * acceptance)\n",
    "        sigacc_s_plus_1p3b_list.append(sig_s_plus_1p3b * acceptance)\n",
    "        sigacc_binomial_list.append(sig_binomial * acceptance)\n",
    "\n",
    "    return (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "            sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "            acceptance_values)\n",
    "\n",
    "# Compute significance for each variable dynamically\n",
    "for cut_var, cut_types in cut_config.items():\n",
    "    for cut_type, cut_values in cut_types.items():\n",
    "        (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "         sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "         acceptance_values) = calculate_significance(cut_var, cut_type, cut_values)\n",
    "\n",
    "        # Plot results\n",
    "        fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "\n",
    "        # Top plot: Significance vs. Cut\n",
    "        ax_top.plot(cut_values, sig_simple_list, marker='o', label='S/√B')\n",
    "        # ax_top.plot(cut_values, sig_s_plus_b_list, marker='s', label='S/√(S+B)')\n",
    "        # ax_top.plot(cut_values, sig_s_plus_1p3b_list, marker='^', label='S/√(S+1.3B)')\n",
    "        # ax_top.plot(cut_values, sig_binomial_list, marker='x', label='BinomialExpZ')\n",
    "        ax_top.set_ylabel('Significance')\n",
    "        ax_top.set_title(f'Significance vs. {cut_var} ({cut_type})')\n",
    "        ax_top.legend()\n",
    "        ax_top.grid(True)\n",
    "\n",
    "        # Bottom plot: Significance * Acceptance vs. Cut\n",
    "        ax_bot.plot(cut_values, sigacc_simple_list, marker='o', label='(S/√B) × Acceptance')\n",
    "        # ax_bot.plot(cut_values, sigacc_s_plus_b_list, marker='s', label='(S/√(S+B)) × Acceptance')\n",
    "        # ax_bot.plot(cut_values, sigacc_s_plus_1p3b_list, marker='^', label='(S/√(S+1.3B)) × Acceptance')\n",
    "        # ax_bot.plot(cut_values, sigacc_binomial_list, marker='x', label='BinomialExpZ × Acceptance')\n",
    "\n",
    "        for i, txt in enumerate(acceptance_values):\n",
    "            ax_bot.text(cut_values[i], sigacc_simple_list[i], f'{txt:.1f}%', \n",
    "                        fontsize=10, ha='right', va='bottom', color='purple')\n",
    "            \n",
    "        ax_bot.set_xlabel(f'{cut_var} Cut')\n",
    "        ax_bot.set_ylabel('Significance × Acceptance')\n",
    "        ax_bot.set_title(f'Significance × Acceptance vs. {cut_var} ({cut_type})')\n",
    "        \n",
    "        ax_bot.set_xticks(cut_values)\n",
    "        ax_bot.set_xticklabels(ax_bot.get_xticks(), rotation=45, ha='right')\n",
    "        ax_bot.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "        # ax_bot.xaxis.set_major_locator(ticker.MaxNLocator(nbins=15))  # Show at most 10 x-ticks\n",
    "        \n",
    "        var_configs_tmp = getVarDict(tot2[0], signal_name, cut_var)\n",
    "        ax_bot.set_xlabel(var_configs_tmp[cut_var]['title'])\n",
    "        ax_bot.legend()\n",
    "        ax_bot.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../jets_faking_photons/lumi135/mc23d_{cut_name}cut/significance_{cut_var}_{cut_type}.png\")\n",
    "        print(f\"Successfully saved to ../jets_faking_photons/lumi135/mc23d_{cut_name}cut/significance_{cut_var}_{cut_type}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_dphi_met_phterm_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_dphi_met_phterm_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/dphi_met_phterm_nodijet.png\n",
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/roc_curve_dphi_met_phterm.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_metsig_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_metsig_uppercut.png\n",
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/metsig_nodijet.png\n",
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/roc_curve_metsig.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_ph_eta_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/ph_eta_nodijet.png\n",
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/roc_curve_ph_eta.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_dmet_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_dmet_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/dmet_nodijet.png\n",
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/roc_curve_dmet.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_dphi_met_jetterm_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_dphi_met_jetterm_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/dphi_met_jetterm_nodijet.png\n",
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/roc_curve_dphi_met_jetterm.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_dphi_ph_centraljet1_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_dphi_ph_centraljet1_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/dphi_ph_centraljet1_nodijet.png\n",
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/roc_curve_dphi_ph_centraljet1.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_balance_lowercut.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_balance_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n",
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/balance_nodijet.png\n",
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/roc_curve_balance.png\n",
      "Successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/significance_dphi_jj_uppercut.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlai/.local/lib/python3.9/site-packages/awkward/_nplikes/array_module.py:251: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/dphi_jj_nodijet.png\n",
      "successfully saved to ../jets_faking_photons/lumi135/mc23d_n-1cut/roc_curve_dphi_jj.png\n"
     ]
    }
   ],
   "source": [
    "n_1_config = [\"dphi_met_phterm\", \"metsig\", \"ph_eta\", \"dmet\", \"dphi_met_jetterm\",  \"dphi_ph_centraljet1\", \"balance\", \"dphi_jj\"]\n",
    "\n",
    "def sel(tot, n_1_name=None):\n",
    "    tot2 = []\n",
    "    for i in range(len(tot)):\n",
    "        fb2 = tot[i]\n",
    "    \n",
    "        if n_1_name != \"dphi_met_phterm\":\n",
    "            dphi_met_phterm_tmp = np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_phterm_phi']))\n",
    "            fb2 = fb2[dphi_met_phterm_tmp >= 1.35]\n",
    "\n",
    "        if n_1_name != \"balance\":\n",
    "            jet_sum_tmp = ak.sum(fb2['jet_central_pt'], axis=-1)\n",
    "            expr = (fb2['met_tst_et'] + ak.firsts(fb2['ph_pt'])) / ak.where(jet_sum_tmp != 0, jet_sum_tmp, 1)\n",
    "            balance_tmp = ak.where(jet_sum_tmp != 0, expr, -999)\n",
    "            mask1 = balance_tmp >= 0.70\n",
    "            mask2 = balance_tmp == -999\n",
    "            fb2 = fb2[mask1 | mask2]\n",
    "\n",
    "        if n_1_name != \"metsig\":\n",
    "            metsig_tmp = fb2['met_tst_sig'] \n",
    "            mask1 = metsig_tmp >= 6\n",
    "            # fb2 = fb2[mask1]\n",
    "            mask2 = metsig_tmp <= 16\n",
    "            fb2 = fb2[mask1 * mask2]\n",
    "        \n",
    "        if n_1_name != \"ph_eta\":\n",
    "            ph_eta_tmp = np.abs(ak.firsts(fb2['ph_eta']))\n",
    "            fb2 = fb2[ph_eta_tmp <= 1.75]\n",
    "\n",
    "        if n_1_name != \"dmet\":\n",
    "            dmet_tmp = fb2['met_tst_noJVT_et'] - fb2['met_tst_et']\n",
    "            mask1 = dmet_tmp >= -20000\n",
    "            mask2 = dmet_tmp <= 40000\n",
    "            fb2 = fb2[mask1 * mask2]\n",
    "\n",
    "        if n_1_name != \"dphi_met_jetterm\":\n",
    "            dphi_met_jetterm_tmp = np.where(fb2['met_jetterm_et'] != 0,   # added cut 5\n",
    "                                    np.arccos(np.cos(fb2['met_tst_phi'] - fb2['met_jetterm_phi'])),\n",
    "                                    -999)\n",
    "            fb2 = fb2[dphi_met_jetterm_tmp <= 0.65]\n",
    "\n",
    "        if n_1_name != \"dphi_jj\":\n",
    "            dphi_jj_tmp = fb2['dphi_central_jj']\n",
    "            dphi_jj_tmp = ak.where(dphi_jj_tmp == -10, -999, dphi_jj_tmp)\n",
    "            fb2 = fb2[dphi_jj_tmp <= 2.4]\n",
    "\n",
    "        if n_1_name != \"dphi_ph_centraljet1\":\n",
    "            dphi_ph_centraljet1_tmp = np.arccos(np.cos(ak.firsts(fb2['ph_phi']) - ak.firsts(fb2['jet_central_phi'])))\n",
    "            dphi_ph_centraljet1_tmp = ak.fill_none(dphi_ph_centraljet1_tmp, -999)\n",
    "            mask1 = dphi_ph_centraljet1_tmp >= 1.7\n",
    "            mask2 = dphi_ph_centraljet1_tmp == -999\n",
    "            fb2 = fb2[mask1 | mask2]\n",
    "        \n",
    "        tot2.append(fb2)\n",
    "    return tot2\n",
    "\n",
    "tot2 = sel(tot)\n",
    "# tot2 = tot\n",
    "\n",
    "signal_name = 'ggHyyd'  # Define signal dataset\n",
    "cut_name = 'n-1'\n",
    "\n",
    "def getCutDict(n_1_name=None):\n",
    "    cut_dict = {}\n",
    "\n",
    "    if n_1_name is None or n_1_name == \"BDTScore\":\n",
    "        cut_dict['BDTScore'] = {\n",
    "            'lowercut': np.arange(0, 0.4+0.1, 0.1) # BDTScore > cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"balance\":\n",
    "        cut_dict['balance'] = {\n",
    "            'lowercut': np.arange(0, 1.5 + 0.05, 0.05), # balance > cut\n",
    "            'uppercut': np.arange(5, 8 + 0.2, 0.2) # balance < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dmet\":\n",
    "        cut_dict['dmet'] = {\n",
    "            'lowercut': np.arange(-30000, 0 + 5000, 5000), # dmet > cut\n",
    "            'uppercut': np.arange(10000, 100000 + 5000, 5000), # -10000 < dmet < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_jj\":\n",
    "        cut_dict['dphi_jj'] = {\n",
    "            'uppercut': np.arange(1, 3.1 + 0.1, 0.1) # dphi_jj < cut\n",
    "        }\n",
    "    # if n_1_name is None or n_1_name == \"dphi_met_phterm_minus_dphi_met_jetterm\":\n",
    "    #     cut_dict['dphi_met_phterm_minus_dphi_met_jetterm'] = {\n",
    "    #         'lowercut': np.arange(0, 1.5+0.05, 0.05),\n",
    "    #         'uppercut': np.arange(1.5, 3.1+0.05, 0.05)\n",
    "    #     }\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_jetterm\":\n",
    "        cut_dict['dphi_met_jetterm'] = {\n",
    "            'lowercut': np.arange(0, 1 + 0.05, 0.05), # dphi_met_jetterm > cut \n",
    "            'uppercut': np.arange(0.5, 2 + 0.05, 0.05), # dphi_met_jetterm < cut \n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_met_phterm\":\n",
    "        cut_dict['dphi_met_phterm'] = {\n",
    "            'lowercut': np.arange(1, 2 + 0.05, 0.05), # dphi_met_phterm > cut\n",
    "            'uppercut': np.arange(2, 3.1 + 0.1, 0.1), # dphi_met_phterm < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_ph_centraljet1\":\n",
    "        cut_dict['dphi_ph_centraljet1'] = {\n",
    "            'lowercut': np.arange(0, 2.5 + 0.1, 0.1), # dphi_ph_centraljet1 > cut\n",
    "            'uppercut': np.arange(1.5, 3.1 + 0.1, 0.1) # dphi_ph_centraljet1 < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"dphi_phterm_jetterm\":\n",
    "        cut_dict['dphi_phterm_jetterm'] = {\n",
    "            'lowercut': np.arange(1, 2.5 + 0.05, 0.05), # dphi_phterm_jetterm > cut\n",
    "            'uppercut': np.arange(2, 4 + 0.1, 0.1) # dphi_phterm_jetterm < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"met\":\n",
    "        cut_dict['met'] = {\n",
    "            'lowercut': np.arange(100000, 140000 + 5000, 5000),  # met > cut\n",
    "            'uppercut': np.arange(140000, 300000 + 5000, 5000),  # met < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"metsig\":\n",
    "        cut_dict['metsig'] = {\n",
    "            'lowercut': np.arange(0, 10 + 1, 1), # metsig > cut\n",
    "            'uppercut': np.arange(10, 30 + 1, 1), # metsig < cut \n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"mt\":\n",
    "        cut_dict['mt'] = {\n",
    "            'lowercut': np.arange(80, 130+5, 5), # mt > cut\n",
    "            'uppercut': np.arange(120, 230+5, 5) # mt < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"n_jet_central\":\n",
    "        cut_dict['n_jet_central'] = {\n",
    "            'uppercut': np.arange(0, 8+1, 1) # njet < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"ph_eta\":\n",
    "        cut_dict['ph_eta'] = {\n",
    "            'uppercut': np.arange(1, 2.5 + 0.05, 0.05), # ph_eta < cut\n",
    "        }\n",
    "    if n_1_name is None or n_1_name == \"ph_pt\":\n",
    "        cut_dict['ph_pt'] = {\n",
    "            'lowercut': np.arange(50000, 100000 + 5000, 5000),  # ph_pt > cut\n",
    "            'uppercut': np.arange(100000, 300000 + 10000, 10000),  # ph_pt > cut\n",
    "        }\n",
    "\n",
    "    return cut_dict\n",
    "\n",
    "\n",
    "def calculate_significance(cut_var, cut_type, cut_values):\n",
    "    sig_simple_list = []\n",
    "    sig_s_plus_b_list = []\n",
    "    sig_s_plus_1p3b_list = []\n",
    "    sig_binomial_list = []\n",
    "\n",
    "    sigacc_simple_list = []\n",
    "    sigacc_s_plus_b_list = []\n",
    "    sigacc_s_plus_1p3b_list = []\n",
    "    sigacc_binomial_list = []\n",
    "\n",
    "    acceptance_values = []  # Store acceptance percentages\n",
    "\n",
    "    for cut in cut_values:\n",
    "        sig_after_cut = 0\n",
    "        bkg_after_cut = []\n",
    "        sig_events = 0\n",
    "        \n",
    "        for i in range(len(ntuple_names)):\n",
    "            fb = tot2[i]\n",
    "            process = ntuple_names[i]\n",
    "            var_config = getVarDict(fb, process, var_name=cut_var)\n",
    "            x = var_config[cut_var]['var']\n",
    "            mask = x != -999 # Apply cut: Remove -999 values \n",
    "            x = x[mask]\n",
    "\n",
    "            if process == signal_name:\n",
    "                sig_events = getWeight(fb, process)\n",
    "                sig_events = sig_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                sig_after_cut = ak.sum(sig_events[mask])\n",
    "            \n",
    "            else:\n",
    "                bkg_events = getWeight(fb, process)\n",
    "                bkg_events = bkg_events[mask]\n",
    "                if cut_type == 'lowercut':\n",
    "                    mask = x >= cut\n",
    "                elif cut_type == 'uppercut':\n",
    "                    mask = x <= cut\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid cut type\")\n",
    "                bkg_after_cut.append(ak.sum(bkg_events[mask]))\n",
    "\n",
    "       # Now compute different types of significance\n",
    "        total_bkg = sum(bkg_after_cut)\n",
    "        total_signal = sig_after_cut\n",
    "\n",
    "        # Avoid zero division carefully\n",
    "        if total_bkg > 0:\n",
    "            sig_simple = total_signal / np.sqrt(total_bkg)\n",
    "            sig_s_plus_b = total_signal / np.sqrt(total_signal + total_bkg) if (total_signal + total_bkg) > 0 else 0\n",
    "            sig_s_plus_1p3b = total_signal / np.sqrt(total_signal + 1.3 * total_bkg) if (total_signal + 1.3*total_bkg) > 0 else 0\n",
    "            sig_binomial = zbi(total_signal, total_bkg, sigma_b_frac=0.3)\n",
    "        else:\n",
    "            sig_simple = sig_s_plus_b = sig_s_plus_1p3b = sig_binomial = 0\n",
    "\n",
    "        # Acceptance\n",
    "        acceptance = total_signal / sum(sig_events) if sum(sig_events) > 0 else 0\n",
    "        acceptance_values.append(acceptance * 100)  # percentage\n",
    "\n",
    "        # Save significance\n",
    "        sig_simple_list.append(sig_simple)\n",
    "        sig_s_plus_b_list.append(sig_s_plus_b)\n",
    "        sig_s_plus_1p3b_list.append(sig_s_plus_1p3b)\n",
    "        sig_binomial_list.append(sig_binomial)\n",
    "\n",
    "        # Save significance × acceptance\n",
    "        sigacc_simple_list.append(sig_simple * acceptance)\n",
    "        sigacc_s_plus_b_list.append(sig_s_plus_b * acceptance)\n",
    "        sigacc_s_plus_1p3b_list.append(sig_s_plus_1p3b * acceptance)\n",
    "        sigacc_binomial_list.append(sig_binomial * acceptance)\n",
    "\n",
    "    return (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "            sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "            acceptance_values)\n",
    "\n",
    "for cut_var_tmp in n_1_config:\n",
    "    cut_config = getCutDict(n_1_name=cut_var_tmp)\n",
    "    tot2 = sel(tot, n_1_name=cut_var_tmp)\n",
    "    for cut_var, cut_types in cut_config.items():\n",
    "        for cut_type, cut_values in cut_types.items():\n",
    "            (sig_simple_list, sig_s_plus_b_list, sig_s_plus_1p3b_list, sig_binomial_list,\n",
    "            sigacc_simple_list, sigacc_s_plus_b_list, sigacc_s_plus_1p3b_list, sigacc_binomial_list,\n",
    "            acceptance_values) = calculate_significance(cut_var, cut_type, cut_values)\n",
    "\n",
    "            # Plot results\n",
    "            fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "\n",
    "            # Top plot: Significance vs. Cut\n",
    "            ax_top.plot(cut_values, sig_simple_list, marker='o', label='S/√B')\n",
    "            # ax_top.plot(cut_values, sig_s_plus_b_list, marker='s', label='S/√(S+B)')\n",
    "            # ax_top.plot(cut_values, sig_s_plus_1p3b_list, marker='^', label='S/√(S+1.3B)')\n",
    "            # ax_top.plot(cut_values, sig_binomial_list, marker='x', label='BinomialExpZ')\n",
    "            ax_top.set_ylabel('Significance')\n",
    "            ax_top.set_title(f'Significance vs. {cut_var} ({cut_type})')\n",
    "            ax_top.legend()\n",
    "            ax_top.grid(True)\n",
    "\n",
    "            # Bottom plot: Significance * Acceptance vs. Cut\n",
    "            ax_bot.plot(cut_values, sigacc_simple_list, marker='o', label='(S/√B) × Acceptance')\n",
    "            # ax_bot.plot(cut_values, sigacc_s_plus_b_list, marker='s', label='(S/√(S+B)) × Acceptance')\n",
    "            # ax_bot.plot(cut_values, sigacc_s_plus_1p3b_list, marker='^', label='(S/√(S+1.3B)) × Acceptance')\n",
    "            # ax_bot.plot(cut_values, sigacc_binomial_list, marker='x', label='BinomialExpZ × Acceptance')\n",
    "\n",
    "            for i, txt in enumerate(acceptance_values):\n",
    "                ax_bot.text(cut_values[i], sigacc_simple_list[i], f'{txt:.1f}%', \n",
    "                            fontsize=10, ha='right', va='bottom', color='purple')\n",
    "                \n",
    "            ax_bot.set_xlabel(f'{cut_var} Cut')\n",
    "            ax_bot.set_ylabel('Significance × Acceptance')\n",
    "            ax_bot.set_title(f'Significance × Acceptance vs. {cut_var} ({cut_type})')\n",
    "            \n",
    "            ax_bot.set_xticks(cut_values)\n",
    "            ax_bot.set_xticklabels(ax_bot.get_xticks(), rotation=45, ha='right')\n",
    "            ax_bot.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            # ax_bot.xaxis.set_major_locator(ticker.MaxNLocator(nbins=15))  # Show at most 10 x-ticks\n",
    "            \n",
    "            var_configs_tmp = getVarDict(tot2[0], signal_name, cut_var)\n",
    "            ax_bot.set_xlabel(var_configs_tmp[cut_var]['title'])\n",
    "            ax_bot.legend()\n",
    "            ax_bot.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"../jets_faking_photons/lumi135/mc23d_{cut_name}cut/significance_{cut_var}_{cut_type}.png\")\n",
    "            print(f\"Successfully saved to ../jets_faking_photons/lumi135/mc23d_{cut_name}cut/significance_{cut_var}_{cut_type}.png\")\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    var_config = getVarDict(tot2[0], 'ggHyyd', var_name=cut_var_tmp)\n",
    "\n",
    "    for var in var_config:\n",
    "        # print(var)\n",
    "        bg_values = []     \n",
    "        bg_weights = []    \n",
    "        bg_colors = []     \n",
    "        bg_labels = []     \n",
    "\n",
    "        signal_values = [] \n",
    "        signal_weights = []\n",
    "        signal_color = None \n",
    "        signal_label = None\n",
    "\n",
    "        for j in range(len(ntuple_names)):\n",
    "            process = ntuple_names[j]\n",
    "            fb = tot2[j]  # TTree\n",
    "            var_config = getVarDict(fb, process, var_name=var)\n",
    "\n",
    "            x = var_config[var]['var'] # TBranch\n",
    "            bins = var_config[var]['bins'] \n",
    "\n",
    "            if 'weight' in var_config[var]:  # If weight is there\n",
    "                weights = var_config[var]['weight']\n",
    "            else:\n",
    "                weights = getWeight(fb, process)\n",
    "            \n",
    "            sample_info = sample_dict[process]\n",
    "            color = sample_info['color']\n",
    "            legend = sample_info['legend']\n",
    "\n",
    "            \n",
    "            if process == 'ggHyyd':  # signal\n",
    "                signal_values.append(x)\n",
    "                signal_weights.append(weights)\n",
    "                signal_color = color\n",
    "                signal_label = legend\n",
    "            else:   # background\n",
    "                bg_values.append(x)\n",
    "                bg_weights.append(weights)\n",
    "                bg_colors.append(color)\n",
    "                bg_labels.append(legend)\n",
    "\n",
    "        fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(12, 13), gridspec_kw={'height_ratios': [9, 4]})\n",
    "\n",
    "        ax_top.hist(bg_values, bins=bins, weights=bg_weights, color=bg_colors,\n",
    "                    label=bg_labels, stacked=True)\n",
    "\n",
    "        ax_top.hist(signal_values, bins=bins, weights=signal_weights, color=signal_color,\n",
    "                    label=signal_label, histtype='step', linewidth=2)\n",
    "\n",
    "        signal_all = np.concatenate(signal_values) if len(signal_values) > 0 else np.array([])\n",
    "        signal_weights_all = np.concatenate(signal_weights) if len(signal_weights) > 0 else np.array([])\n",
    "\n",
    "        # Add error bar for signal (top plot)\n",
    "        if len(signal_all) > 0:\n",
    "            signal_counts, bin_edges = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "            sum_weights_sq, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all**2)\n",
    "            bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "            signal_errors = np.sqrt(sum_weights_sq)  # Poisson error sqrt(N)\n",
    "\n",
    "            ax_top.errorbar(bin_centers, signal_counts, yerr=signal_errors, fmt='.', linewidth=2,\n",
    "                            color=signal_color, capsize=0)\n",
    "\n",
    "        ax_top.set_yscale('log')\n",
    "        ax_top.set_ylim(0.0001, 1e11)\n",
    "        ax_top.set_xlim(bins[0], bins[-1])\n",
    "        ax_top.minorticks_on()\n",
    "        ax_top.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        ax_top.set_ylabel(\"Events\")\n",
    "        ax_top.legend(ncol=2)\n",
    "        # ax_top.set_title(\"vtx_sumPt distribution\")\n",
    "\n",
    "        bg_all = np.concatenate(bg_values) if len(bg_values) > 0 else np.array([])\n",
    "        bg_weights_all = np.concatenate(bg_weights) if len(bg_weights) > 0 else np.array([])\n",
    "\n",
    "        # Compute the weighted histogram counts using np.histogram\n",
    "        S_counts, _ = np.histogram(signal_all, bins=bins, weights=signal_weights_all)\n",
    "        B_counts, _ = np.histogram(bg_all, bins=bins, weights=bg_weights_all)     \n",
    "\n",
    "        # Compute per-bin significance\n",
    "        sig_simple = np.zeros_like(S_counts, dtype=float)\n",
    "        sig_s_plus_b = np.zeros_like(S_counts, dtype=float)\n",
    "        sig_s_plus_1p3b = np.zeros_like(S_counts, dtype=float)\n",
    "\n",
    "        sqrt_B = np.sqrt(B_counts)\n",
    "        sqrt_SplusB = np.sqrt(S_counts + B_counts)\n",
    "        sqrt_Splus1p3B = np.sqrt(S_counts + 1.3 * B_counts)\n",
    "\n",
    "        # Avoid division by zero safely\n",
    "        sig_simple = np.where(B_counts > 0, S_counts / sqrt_B, 0)\n",
    "        sig_s_plus_b = np.where((S_counts + B_counts) > 0, S_counts / sqrt_SplusB, 0)\n",
    "        sig_s_plus_1p3b = np.where((S_counts + 1.3 * B_counts) > 0, S_counts / sqrt_Splus1p3B, 0)\n",
    "\n",
    "        # Add Binomial ExpZ per bin\n",
    "        zbi_per_bin = np.array([\n",
    "            zbi(S_counts[i], B_counts[i], sigma_b_frac=0.3)\n",
    "            for i in range(len(S_counts))\n",
    "        ])\n",
    "\n",
    "        # Compute the bin centers for plotting\n",
    "        bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "        # Compute the total significance: total S / sqrt(total B)\n",
    "        total_signal = np.sum(S_counts)\n",
    "        total_bkg = np.sum(B_counts)\n",
    "\n",
    "        if total_bkg > 0:\n",
    "            total_sig_simple = total_signal / np.sqrt(total_bkg)\n",
    "            total_sig_s_plus_b = total_signal / np.sqrt(total_signal + total_bkg)\n",
    "            total_sig_s_plus_1p3b = total_signal / np.sqrt(total_signal + 1.3 * total_bkg)\n",
    "            total_sig_binomial = zbi(total_signal, total_bkg, sigma_b_frac=0.3)\n",
    "        else:\n",
    "            total_sig_simple = total_sig_s_plus_b = total_sig_s_plus_1p3b = total_sig_binomial = 0\n",
    "\n",
    "        # --- Plot all significance curves ---\n",
    "        ax_bot.step(bin_centers, sig_simple, where='mid', color='chocolate', linewidth=2,\n",
    "                    label=f\"S/√B = {total_sig_simple:.4f}\")\n",
    "        ax_bot.step(bin_centers, sig_s_plus_b, where='mid', color='tomato', linewidth=2,\n",
    "                    label=f\"S/√(S+B) = {total_sig_s_plus_b:.4f}\")\n",
    "        ax_bot.step(bin_centers, sig_s_plus_1p3b, where='mid', color='orange', linewidth=2,\n",
    "                    label=f\"S/√(S+1.3B) = {total_sig_s_plus_1p3b:.4f}\")\n",
    "        ax_bot.step(bin_centers, zbi_per_bin, where='mid', color='plum', linewidth=2,\n",
    "                    label=f\"Binomial ExpZ = {total_sig_binomial:.4f}\")\n",
    "\n",
    "        ax_bot.set_xlabel(var_config[var]['title'])\n",
    "        # ax_bot.set_xticks(np.linspace(bins[0], bins[-1], 11))\n",
    "        ax_bot.set_ylabel(\"Significance\")\n",
    "        ax_bot.set_ylim(-0.8, 2)\n",
    "        ax_top.set_xlim(bins[0], bins[-1])\n",
    "\n",
    "        # Do not set a title on the bottom plot.\n",
    "        ax_bot.set_title(\"\")\n",
    "\n",
    "        # Draw a legend with purple text.\n",
    "        leg = ax_bot.legend()\n",
    "        for text in leg.get_texts():\n",
    "            text.set_color('purple')\n",
    "\n",
    "        plt.xlim(bins[0], bins[-1])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../jets_faking_photons/lumi135/mc23d_{cut_name}cut/{var}_nodijet.png\")\n",
    "        print(f\"successfully saved to ../jets_faking_photons/lumi135/mc23d_{cut_name}cut/{var}_nodijet.png\")\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "\n",
    "        y_true = np.concatenate([np.ones_like(signal_all), np.zeros_like(bg_all)])\n",
    "        # Use the vtx_sumPt values as the classifier output.\n",
    "        y_scores = np.concatenate([signal_all, bg_all])\n",
    "        # Combine the weights for all events.\n",
    "        y_weights = np.concatenate([signal_weights_all, bg_weights_all])\n",
    "\n",
    "        # Compute the weighted ROC curve.\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_scores, sample_weight=y_weights)\n",
    "        sorted_indices = np.argsort(fpr)\n",
    "        fpr_sorted = fpr[sorted_indices]\n",
    "        tpr_sorted = tpr[sorted_indices]\n",
    "\n",
    "        roc_auc = auc(fpr_sorted, tpr_sorted)\n",
    "\n",
    "        # Create a new figure for the ROC curve.\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(fpr, tpr, lw=2, color='red', label=f'ROC curve (AUC = {roc_auc:.5f})')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random chance')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"ROC Curve for {var}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        plt.tight_layout()    \n",
    "        plt.savefig(f\"../jets_faking_photons/lumi135/mc23d_{cut_name}cut/roc_curve_{var}.png\")\n",
    "        print(f\"successfully saved to ../jets_faking_photons/lumi135/mc23d_{cut_name}cut/roc_curve_{var}.png\")\n",
    "        plt.close()\n",
    "        # plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
