{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67d96b6-12a2-4ace-a55a-a54833951ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import uproot, os, logging, json, random, wandb, shap\n",
    "import awkward as ak\n",
    "# import torch\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score, log_loss, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupShuffleSplit, RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import randint, uniform, stats\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from collections import Counter\n",
    "\n",
    "# ML model\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, log_loss, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Config\n",
    "\n",
    "# Set up plot defaults\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 12.0,8.0  # Roughly 11 cm wde by 8 cm high\n",
    "mpl.rcParams['font.size'] = 14.0 # Use 14 point font\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "font_size = {\n",
    "    \"xlabel\": 17,\n",
    "    \"ylabel\": 17,\n",
    "    \"xticks\": 15,\n",
    "    \"yticks\": 15,\n",
    "    \"legend\": 14\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": font_size[\"xlabel\"],  # X and Y axis labels\n",
    "    \"xtick.labelsize\": font_size[\"xticks\"],  # X ticks\n",
    "    \"ytick.labelsize\": font_size[\"yticks\"],  # Y ticks\n",
    "    \"legend.fontsize\": font_size[\"legend\"]  # Legend\n",
    "})\n",
    "\n",
    "# Check for gpu\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff98c84-1bb2-466a-aa3f-4c2218aeb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/data/jlai/vertex/vertex_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e67d4f-081d-4aeb-b678-7d47eab80743",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m\n\u001b[1;32m     21\u001b[0m y_test_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     24\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m, StandardScaler()),\n\u001b[1;32m     25\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m, MLPClassifier(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[1;32m     26\u001b[0m ])\n\u001b[1;32m     28\u001b[0m param_dist \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp__hidden_layer_sizes\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;241m32\u001b[39m,), (\u001b[38;5;241m64\u001b[39m,), (\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m32\u001b[39m), (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m)],\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp__activation\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp__solver\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp__alpha\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mstats\u001b[49m\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m),\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp__learning_rate_init\u001b[39m\u001b[38;5;124m\"\u001b[39m: stats\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m),\n\u001b[1;32m     34\u001b[0m }\n\u001b[1;32m     36\u001b[0m search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     37\u001b[0m     pipeline, param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[1;32m     38\u001b[0m     n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(df, groups=df['event_id']))\n",
    "\n",
    "df_train = df.iloc[train_idx].reset_index(drop=True)\n",
    "df_test = df.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "X_train = df_train.drop(['label', 'event_id'], axis=1)\n",
    "y_train = df_train['label'].values\n",
    "X_test = df_test.drop(['label', 'event_id'], axis=1)\n",
    "y_test = df_test['label'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to tensors \n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"mlp\", MLPClassifier(max_iter=300, early_stopping=True, random_state=42))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    \"mlp__hidden_layer_sizes\": [(32,), (64,), (64, 32), (128, 64)],\n",
    "    \"mlp__activation\": [\"relu\", \"tanh\"],\n",
    "    \"mlp__solver\": [\"adam\", \"sgd\"],\n",
    "    \"mlp__alpha\": stats.loguniform(1e-5, 1e-2),\n",
    "    \"mlp__learning_rate_init\": stats.loguniform(1e-4, 1e-2),\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, param_distributions=param_dist,\n",
    "    n_iter=20, cv=5, verbose=2, n_jobs=-1, scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
